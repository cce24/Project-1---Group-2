{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Two-Letter</th>\n",
       "      <th>Annual mean wage(2)</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>var</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "      <th>State</th>\n",
       "      <th>costIndex</th>\n",
       "      <th>costRank</th>\n",
       "      <th>groceryCost</th>\n",
       "      <th>housingCost</th>\n",
       "      <th>utilitiesCost</th>\n",
       "      <th>transportationCost</th>\n",
       "      <th>miscCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>59290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>129.9</td>\n",
       "      <td>45.0</td>\n",
       "      <td>134.2</td>\n",
       "      <td>133.9</td>\n",
       "      <td>154.2</td>\n",
       "      <td>130.8</td>\n",
       "      <td>150.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>44930.0</td>\n",
       "      <td>2.529412</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.889706</td>\n",
       "      <td>0.943242</td>\n",
       "      <td>0.228770</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>89.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>97.4</td>\n",
       "      <td>71.5</td>\n",
       "      <td>103.3</td>\n",
       "      <td>88.6</td>\n",
       "      <td>90.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR</td>\n",
       "      <td>42690.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.470899</td>\n",
       "      <td>1.212806</td>\n",
       "      <td>0.229199</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>86.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>91.8</td>\n",
       "      <td>83.6</td>\n",
       "      <td>85.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AZ</td>\n",
       "      <td>50930.0</td>\n",
       "      <td>2.792453</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.206096</td>\n",
       "      <td>1.098224</td>\n",
       "      <td>0.150853</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>97.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>96.9</td>\n",
       "      <td>91.7</td>\n",
       "      <td>107.4</td>\n",
       "      <td>109.6</td>\n",
       "      <td>94.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>61290.0</td>\n",
       "      <td>3.969176</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.131761</td>\n",
       "      <td>1.460055</td>\n",
       "      <td>0.039091</td>\n",
       "      <td>California</td>\n",
       "      <td>151.7</td>\n",
       "      <td>49.0</td>\n",
       "      <td>121.4</td>\n",
       "      <td>227.3</td>\n",
       "      <td>117.7</td>\n",
       "      <td>138.9</td>\n",
       "      <td>114.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CO</td>\n",
       "      <td>57690.0</td>\n",
       "      <td>2.963303</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.350493</td>\n",
       "      <td>1.162107</td>\n",
       "      <td>0.111310</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>105.6</td>\n",
       "      <td>33.0</td>\n",
       "      <td>102.5</td>\n",
       "      <td>119.0</td>\n",
       "      <td>88.4</td>\n",
       "      <td>101.2</td>\n",
       "      <td>102.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CT</td>\n",
       "      <td>62350.0</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.927928</td>\n",
       "      <td>1.388498</td>\n",
       "      <td>0.160330</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>127.7</td>\n",
       "      <td>43.0</td>\n",
       "      <td>114.2</td>\n",
       "      <td>144.7</td>\n",
       "      <td>128.1</td>\n",
       "      <td>111.8</td>\n",
       "      <td>113.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DC</td>\n",
       "      <td>89800.0</td>\n",
       "      <td>3.107143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.549589</td>\n",
       "      <td>1.244825</td>\n",
       "      <td>0.105207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DE</td>\n",
       "      <td>54370.0</td>\n",
       "      <td>3.470588</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.639706</td>\n",
       "      <td>1.280510</td>\n",
       "      <td>0.310569</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>108.1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>113.4</td>\n",
       "      <td>98.2</td>\n",
       "      <td>96.5</td>\n",
       "      <td>107.0</td>\n",
       "      <td>101.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FL</td>\n",
       "      <td>47750.0</td>\n",
       "      <td>2.514563</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.546354</td>\n",
       "      <td>1.243525</td>\n",
       "      <td>0.122528</td>\n",
       "      <td>Florida</td>\n",
       "      <td>97.9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>95.4</td>\n",
       "      <td>102.2</td>\n",
       "      <td>96.7</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GA</td>\n",
       "      <td>49620.0</td>\n",
       "      <td>2.589928</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.678449</td>\n",
       "      <td>1.295550</td>\n",
       "      <td>0.109887</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>89.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>96.9</td>\n",
       "      <td>73.8</td>\n",
       "      <td>92.4</td>\n",
       "      <td>97.6</td>\n",
       "      <td>98.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HI</td>\n",
       "      <td>54930.0</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>1.329160</td>\n",
       "      <td>0.542627</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>192.9</td>\n",
       "      <td>51.0</td>\n",
       "      <td>169.3</td>\n",
       "      <td>318.6</td>\n",
       "      <td>172.7</td>\n",
       "      <td>148.6</td>\n",
       "      <td>116.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IA</td>\n",
       "      <td>47330.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.126437</td>\n",
       "      <td>1.061337</td>\n",
       "      <td>0.193773</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>90.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>95.9</td>\n",
       "      <td>79.6</td>\n",
       "      <td>95.3</td>\n",
       "      <td>95.5</td>\n",
       "      <td>97.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ID</td>\n",
       "      <td>44890.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.836660</td>\n",
       "      <td>0.341565</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>92.3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>92.2</td>\n",
       "      <td>87.1</td>\n",
       "      <td>82.9</td>\n",
       "      <td>106.7</td>\n",
       "      <td>97.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IL</td>\n",
       "      <td>55130.0</td>\n",
       "      <td>3.095833</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.358978</td>\n",
       "      <td>1.165752</td>\n",
       "      <td>0.075249</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>94.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>94.2</td>\n",
       "      <td>87.2</td>\n",
       "      <td>100.9</td>\n",
       "      <td>100.9</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IN</td>\n",
       "      <td>46770.0</td>\n",
       "      <td>2.521739</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.588406</td>\n",
       "      <td>1.260320</td>\n",
       "      <td>0.185824</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>90.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>93.3</td>\n",
       "      <td>77.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>93.1</td>\n",
       "      <td>94.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KS</td>\n",
       "      <td>46520.0</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.881917</td>\n",
       "      <td>0.293972</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>89.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>91.9</td>\n",
       "      <td>73.8</td>\n",
       "      <td>103.0</td>\n",
       "      <td>92.3</td>\n",
       "      <td>98.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KY</td>\n",
       "      <td>44020.0</td>\n",
       "      <td>2.230769</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.025641</td>\n",
       "      <td>1.423250</td>\n",
       "      <td>0.394739</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>90.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>89.9</td>\n",
       "      <td>77.4</td>\n",
       "      <td>97.6</td>\n",
       "      <td>92.8</td>\n",
       "      <td>89.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LA</td>\n",
       "      <td>44170.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.095445</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>93.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>86.6</td>\n",
       "      <td>89.3</td>\n",
       "      <td>98.5</td>\n",
       "      <td>98.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MA</td>\n",
       "      <td>65680.0</td>\n",
       "      <td>3.188192</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.064453</td>\n",
       "      <td>1.436820</td>\n",
       "      <td>0.087281</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>131.6</td>\n",
       "      <td>46.0</td>\n",
       "      <td>113.9</td>\n",
       "      <td>170.3</td>\n",
       "      <td>109.7</td>\n",
       "      <td>116.0</td>\n",
       "      <td>117.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MD</td>\n",
       "      <td>60230.0</td>\n",
       "      <td>3.047337</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.759651</td>\n",
       "      <td>1.326518</td>\n",
       "      <td>0.102040</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>129.7</td>\n",
       "      <td>44.0</td>\n",
       "      <td>108.5</td>\n",
       "      <td>184.5</td>\n",
       "      <td>107.3</td>\n",
       "      <td>116.7</td>\n",
       "      <td>89.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ME</td>\n",
       "      <td>48470.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.877058</td>\n",
       "      <td>0.234404</td>\n",
       "      <td>Maine</td>\n",
       "      <td>117.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>123.1</td>\n",
       "      <td>116.1</td>\n",
       "      <td>121.4</td>\n",
       "      <td>121.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MI</td>\n",
       "      <td>50780.0</td>\n",
       "      <td>2.482353</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.276471</td>\n",
       "      <td>1.129810</td>\n",
       "      <td>0.122545</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>88.9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>89.3</td>\n",
       "      <td>75.2</td>\n",
       "      <td>97.3</td>\n",
       "      <td>97.4</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MN</td>\n",
       "      <td>55890.0</td>\n",
       "      <td>2.409091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.445455</td>\n",
       "      <td>1.202271</td>\n",
       "      <td>0.147989</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>101.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>88.3</td>\n",
       "      <td>96.8</td>\n",
       "      <td>103.7</td>\n",
       "      <td>108.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MO</td>\n",
       "      <td>47820.0</td>\n",
       "      <td>2.467532</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.462748</td>\n",
       "      <td>1.209441</td>\n",
       "      <td>0.137829</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>87.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>96.6</td>\n",
       "      <td>70.6</td>\n",
       "      <td>99.6</td>\n",
       "      <td>87.3</td>\n",
       "      <td>95.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MS</td>\n",
       "      <td>40090.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>86.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.6</td>\n",
       "      <td>70.1</td>\n",
       "      <td>89.1</td>\n",
       "      <td>89.2</td>\n",
       "      <td>91.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MT</td>\n",
       "      <td>45370.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montana</td>\n",
       "      <td>106.9</td>\n",
       "      <td>34.0</td>\n",
       "      <td>105.1</td>\n",
       "      <td>111.6</td>\n",
       "      <td>83.9</td>\n",
       "      <td>125.0</td>\n",
       "      <td>98.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NC</td>\n",
       "      <td>48550.0</td>\n",
       "      <td>2.928058</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.444062</td>\n",
       "      <td>1.201691</td>\n",
       "      <td>0.101926</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>94.9</td>\n",
       "      <td>22.0</td>\n",
       "      <td>96.6</td>\n",
       "      <td>83.1</td>\n",
       "      <td>97.9</td>\n",
       "      <td>93.4</td>\n",
       "      <td>110.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ND</td>\n",
       "      <td>50430.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>98.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>108.1</td>\n",
       "      <td>90.3</td>\n",
       "      <td>93.6</td>\n",
       "      <td>104.3</td>\n",
       "      <td>111.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NE</td>\n",
       "      <td>48250.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.699206</td>\n",
       "      <td>0.221108</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>90.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>80.9</td>\n",
       "      <td>90.8</td>\n",
       "      <td>94.3</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NH</td>\n",
       "      <td>53950.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.238095</td>\n",
       "      <td>1.112697</td>\n",
       "      <td>0.420560</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>109.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>110.3</td>\n",
       "      <td>119.5</td>\n",
       "      <td>111.4</td>\n",
       "      <td>116.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NJ</td>\n",
       "      <td>59980.0</td>\n",
       "      <td>3.257812</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.287340</td>\n",
       "      <td>1.512395</td>\n",
       "      <td>0.133678</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>125.1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>109.5</td>\n",
       "      <td>163.1</td>\n",
       "      <td>101.6</td>\n",
       "      <td>111.1</td>\n",
       "      <td>101.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NM</td>\n",
       "      <td>47040.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>87.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.9</td>\n",
       "      <td>77.7</td>\n",
       "      <td>87.9</td>\n",
       "      <td>91.6</td>\n",
       "      <td>100.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NV</td>\n",
       "      <td>47210.0</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.892105</td>\n",
       "      <td>0.944513</td>\n",
       "      <td>0.211200</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>108.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>108.3</td>\n",
       "      <td>121.8</td>\n",
       "      <td>89.0</td>\n",
       "      <td>123.5</td>\n",
       "      <td>105.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NY</td>\n",
       "      <td>63970.0</td>\n",
       "      <td>3.725458</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.602834</td>\n",
       "      <td>1.613330</td>\n",
       "      <td>0.065809</td>\n",
       "      <td>New York</td>\n",
       "      <td>139.1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>114.8</td>\n",
       "      <td>204.4</td>\n",
       "      <td>108.7</td>\n",
       "      <td>116.6</td>\n",
       "      <td>104.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>OH</td>\n",
       "      <td>49430.0</td>\n",
       "      <td>2.712963</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.440204</td>\n",
       "      <td>1.200085</td>\n",
       "      <td>0.115478</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>90.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>73.6</td>\n",
       "      <td>91.8</td>\n",
       "      <td>96.7</td>\n",
       "      <td>97.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OK</td>\n",
       "      <td>45620.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.4</td>\n",
       "      <td>71.9</td>\n",
       "      <td>94.1</td>\n",
       "      <td>89.5</td>\n",
       "      <td>93.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>OR</td>\n",
       "      <td>53890.0</td>\n",
       "      <td>2.793651</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.940604</td>\n",
       "      <td>1.393056</td>\n",
       "      <td>0.175509</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>134.2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>110.3</td>\n",
       "      <td>181.8</td>\n",
       "      <td>88.0</td>\n",
       "      <td>136.7</td>\n",
       "      <td>113.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>PA</td>\n",
       "      <td>51340.0</td>\n",
       "      <td>2.539568</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.525597</td>\n",
       "      <td>1.235151</td>\n",
       "      <td>0.104764</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>101.7</td>\n",
       "      <td>32.0</td>\n",
       "      <td>106.9</td>\n",
       "      <td>100.8</td>\n",
       "      <td>106.0</td>\n",
       "      <td>109.5</td>\n",
       "      <td>91.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RI</td>\n",
       "      <td>57220.0</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.069045</td>\n",
       "      <td>0.404061</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>119.4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>106.2</td>\n",
       "      <td>129.4</td>\n",
       "      <td>123.5</td>\n",
       "      <td>124.0</td>\n",
       "      <td>109.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SC</td>\n",
       "      <td>44380.0</td>\n",
       "      <td>2.541667</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.476449</td>\n",
       "      <td>1.215092</td>\n",
       "      <td>0.248030</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>95.9</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.9</td>\n",
       "      <td>85.1</td>\n",
       "      <td>107.6</td>\n",
       "      <td>88.0</td>\n",
       "      <td>94.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SD</td>\n",
       "      <td>42920.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>99.8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>109.8</td>\n",
       "      <td>91.8</td>\n",
       "      <td>89.8</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TN</td>\n",
       "      <td>45650.0</td>\n",
       "      <td>2.545455</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.835095</td>\n",
       "      <td>1.354657</td>\n",
       "      <td>0.204222</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>88.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93.3</td>\n",
       "      <td>80.2</td>\n",
       "      <td>93.4</td>\n",
       "      <td>89.7</td>\n",
       "      <td>88.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>TX</td>\n",
       "      <td>50490.0</td>\n",
       "      <td>2.866261</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.664986</td>\n",
       "      <td>1.290343</td>\n",
       "      <td>0.071139</td>\n",
       "      <td>Texas</td>\n",
       "      <td>91.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>88.9</td>\n",
       "      <td>85.3</td>\n",
       "      <td>102.3</td>\n",
       "      <td>91.4</td>\n",
       "      <td>96.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>UT</td>\n",
       "      <td>49420.0</td>\n",
       "      <td>2.352941</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.629234</td>\n",
       "      <td>1.276414</td>\n",
       "      <td>0.218903</td>\n",
       "      <td>Utah</td>\n",
       "      <td>98.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>98.5</td>\n",
       "      <td>93.6</td>\n",
       "      <td>89.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>VA</td>\n",
       "      <td>56740.0</td>\n",
       "      <td>3.389222</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.781986</td>\n",
       "      <td>1.334910</td>\n",
       "      <td>0.073043</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>100.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>96.1</td>\n",
       "      <td>108.0</td>\n",
       "      <td>99.2</td>\n",
       "      <td>88.1</td>\n",
       "      <td>97.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>VT</td>\n",
       "      <td>51120.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>114.5</td>\n",
       "      <td>39.0</td>\n",
       "      <td>111.3</td>\n",
       "      <td>126.7</td>\n",
       "      <td>120.2</td>\n",
       "      <td>119.9</td>\n",
       "      <td>101.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>WA</td>\n",
       "      <td>62020.0</td>\n",
       "      <td>3.396396</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.869308</td>\n",
       "      <td>1.367226</td>\n",
       "      <td>0.091762</td>\n",
       "      <td>Washington</td>\n",
       "      <td>110.7</td>\n",
       "      <td>38.0</td>\n",
       "      <td>107.8</td>\n",
       "      <td>117.8</td>\n",
       "      <td>88.7</td>\n",
       "      <td>121.7</td>\n",
       "      <td>118.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>WI</td>\n",
       "      <td>48850.0</td>\n",
       "      <td>2.717949</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.102564</td>\n",
       "      <td>1.050031</td>\n",
       "      <td>0.168139</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>97.3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.7</td>\n",
       "      <td>91.4</td>\n",
       "      <td>98.9</td>\n",
       "      <td>98.1</td>\n",
       "      <td>115.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>WV</td>\n",
       "      <td>43420.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>91.1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>92.9</td>\n",
       "      <td>79.6</td>\n",
       "      <td>89.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>89.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>WY</td>\n",
       "      <td>49760.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>89.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>72.3</td>\n",
       "      <td>87.3</td>\n",
       "      <td>99.3</td>\n",
       "      <td>94.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State_Two-Letter  Annual mean wage(2)      mean  median       var  \\\n",
       "0                AK              59290.0       NaN     NaN       NaN   \n",
       "1                AL              44930.0  2.529412     2.0  0.889706   \n",
       "2                AR              42690.0  2.714286     3.0  1.470899   \n",
       "3                AZ              50930.0  2.792453     3.0  1.206096   \n",
       "4                CA              61290.0  3.969176     4.0  2.131761   \n",
       "5                CO              57690.0  2.963303     3.0  1.350493   \n",
       "6                CT              62350.0  2.933333     3.0  1.927928   \n",
       "7                DC              89800.0  3.107143     3.0  1.549589   \n",
       "8                DE              54370.0  3.470588     3.0  1.639706   \n",
       "9                FL              47750.0  2.514563     3.0  1.546354   \n",
       "10               GA              49620.0  2.589928     2.0  1.678449   \n",
       "11               HI              54930.0  2.833333     3.0  1.766667   \n",
       "12               IA              47330.0  2.666667     3.0  1.126437   \n",
       "13               ID              44890.0  2.500000     3.0  0.700000   \n",
       "14               IL              55130.0  3.095833     3.0  1.358978   \n",
       "15               IN              46770.0  2.521739     2.0  1.588406   \n",
       "16               KS              46520.0  2.444444     3.0  0.777778   \n",
       "17               KY              44020.0  2.230769     2.0  2.025641   \n",
       "18               LA              44170.0  2.000000     2.0  1.200000   \n",
       "19               MA              65680.0  3.188192     3.0  2.064453   \n",
       "20               MD              60230.0  3.047337     3.0  1.759651   \n",
       "21               ME              48470.0  2.000000     2.0  0.769231   \n",
       "22               MI              50780.0  2.482353     2.0  1.276471   \n",
       "23               MN              55890.0  2.409091     2.0  1.445455   \n",
       "24               MO              47820.0  2.467532     2.0  1.462748   \n",
       "25               MS              40090.0       NaN     NaN       NaN   \n",
       "26               MT              45370.0  3.000000     3.0       NaN   \n",
       "27               NC              48550.0  2.928058     3.0  1.444062   \n",
       "28               ND              50430.0  3.000000     3.0       NaN   \n",
       "29               NE              48250.0  2.400000     2.5  0.488889   \n",
       "30               NH              53950.0  2.714286     2.0  1.238095   \n",
       "31               NJ              59980.0  3.257812     3.0  2.287340   \n",
       "32               NM              47040.0  2.000000     2.0  1.000000   \n",
       "33               NV              47210.0  2.050000     2.0  0.892105   \n",
       "34               NY              63970.0  3.725458     4.0  2.602834   \n",
       "35               OH              49430.0  2.712963     3.0  1.440204   \n",
       "36               OK              45620.0  2.500000     3.0  1.000000   \n",
       "37               OR              53890.0  2.793651     3.0  1.940604   \n",
       "38               PA              51340.0  2.539568     2.0  1.525597   \n",
       "39               RI              57220.0  2.857143     3.0  1.142857   \n",
       "40               SC              44380.0  2.541667     2.5  1.476449   \n",
       "41               SD              42920.0  2.000000     2.0       NaN   \n",
       "42               TN              45650.0  2.545455     2.0  1.835095   \n",
       "43               TX              50490.0  2.866261     3.0  1.664986   \n",
       "44               UT              49420.0  2.352941     2.0  1.629234   \n",
       "45               VA              56740.0  3.389222     3.0  1.781986   \n",
       "46               VT              51120.0  1.000000     1.0  0.000000   \n",
       "47               WA              62020.0  3.396396     3.0  1.869308   \n",
       "48               WI              48850.0  2.717949     3.0  1.102564   \n",
       "49               WV              43420.0  2.333333     2.0  0.333333   \n",
       "50               WY              49760.0  2.500000     2.5  0.500000   \n",
       "\n",
       "         std       sem           State  costIndex  costRank  groceryCost  \\\n",
       "0        NaN       NaN          Alaska      129.9      45.0        134.2   \n",
       "1   0.943242  0.228770         Alabama       89.3      11.0         97.4   \n",
       "2   1.212806  0.229199        Arkansas       86.9       2.0         92.0   \n",
       "3   1.098224  0.150853         Arizona       97.0      24.0         96.9   \n",
       "4   1.460055  0.039091      California      151.7      49.0        121.4   \n",
       "5   1.162107  0.111310        Colorado      105.6      33.0        102.5   \n",
       "6   1.388498  0.160330     Connecticut      127.7      43.0        114.2   \n",
       "7   1.244825  0.105207             NaN        NaN       NaN          NaN   \n",
       "8   1.280510  0.310569        Delaware      108.1      35.0        113.4   \n",
       "9   1.243525  0.122528         Florida       97.9      26.0        104.0   \n",
       "10  1.295550  0.109887         Georgia       89.2       9.0         96.9   \n",
       "11  1.329160  0.542627          Hawaii      192.9      51.0        169.3   \n",
       "12  1.061337  0.193773            Iowa       90.1      13.0         95.9   \n",
       "13  0.836660  0.341565           Idaho       92.3      19.0         92.2   \n",
       "14  1.165752  0.075249        Illinois       94.5      21.0         94.2   \n",
       "15  1.260320  0.185824         Indiana       90.0      12.0         93.3   \n",
       "16  0.881917  0.293972          Kansas       89.0       8.0         91.9   \n",
       "17  1.423250  0.394739        Kentucky       90.9      16.0         89.9   \n",
       "18  1.095445  0.447214       Louisiana       93.9      20.0         99.9   \n",
       "19  1.436820  0.087281   Massachusetts      131.6      46.0        113.9   \n",
       "20  1.326518  0.102040        Maryland      129.7      44.0        108.5   \n",
       "21  0.877058  0.234404           Maine      117.5      40.0        107.0   \n",
       "22  1.129810  0.122545        Michigan       88.9       7.0         89.3   \n",
       "23  1.202271  0.147989       Minnesota      101.6      31.0        106.7   \n",
       "24  1.209441  0.137829        Missouri       87.1       4.0         96.6   \n",
       "25       NaN       NaN     Mississippi       86.1       1.0         91.6   \n",
       "26       NaN       NaN         Montana      106.9      34.0        105.1   \n",
       "27  1.201691  0.101926  North Carolina       94.9      22.0         96.6   \n",
       "28       NaN       NaN    North Dakota       98.8      28.0        108.1   \n",
       "29  0.699206  0.221108        Nebraska       90.8      14.0         95.5   \n",
       "30  1.112697  0.420560   New Hampshire      109.7      37.0        100.4   \n",
       "31  1.512395  0.133678      New Jersey      125.1      42.0        109.5   \n",
       "32  1.000000  0.447214      New Mexico       87.5       5.0        100.9   \n",
       "33  0.944513  0.211200          Nevada      108.5      36.0        108.3   \n",
       "34  1.613330  0.065809        New York      139.1      48.0        114.8   \n",
       "35  1.200085  0.115478            Ohio       90.8      15.0         98.7   \n",
       "36  1.000000  0.500000        Oklahoma       87.0       3.0         95.4   \n",
       "37  1.393056  0.175509          Oregon      134.2      47.0        110.3   \n",
       "38  1.235151  0.104764    Pennsylvania      101.7      32.0        106.9   \n",
       "39  1.069045  0.404061    Rhode Island      119.4      41.0        106.2   \n",
       "40  1.215092  0.248030  South Carolina       95.9      23.0        101.9   \n",
       "41       NaN       NaN    South Dakota       99.8      29.0        107.0   \n",
       "42  1.354657  0.204222       Tennessee       88.7       6.0         93.3   \n",
       "43  1.290343  0.071139           Texas       91.5      18.0         88.9   \n",
       "44  1.276414  0.218903            Utah       98.4      27.0         98.5   \n",
       "45  1.334910  0.073043        Virginia      100.7      30.0         96.1   \n",
       "46  0.000000  0.000000         Vermont      114.5      39.0        111.3   \n",
       "47  1.367226  0.091762      Washington      110.7      38.0        107.8   \n",
       "48  1.050031  0.168139       Wisconsin       97.3      25.0        100.7   \n",
       "49  0.577350  0.333333   West Virginia       91.1      17.0         92.9   \n",
       "50  0.707107  0.500000         Wyoming       89.3      10.0         98.7   \n",
       "\n",
       "    housingCost  utilitiesCost  transportationCost  miscCost  \n",
       "0         133.9          154.2               130.8     150.9  \n",
       "1          71.5          103.3                88.6      90.8  \n",
       "2          73.9           91.8                83.6      85.6  \n",
       "3          91.7          107.4               109.6      94.7  \n",
       "4         227.3          117.7               138.9     114.5  \n",
       "5         119.0           88.4               101.2     102.9  \n",
       "6         144.7          128.1               111.8     113.7  \n",
       "7           NaN            NaN                 NaN       NaN  \n",
       "8          98.2           96.5               107.0     101.6  \n",
       "9          95.4          102.2                96.7      96.9  \n",
       "10         73.8           92.4                97.6      98.5  \n",
       "11        318.6          172.7               148.6     116.8  \n",
       "12         79.6           95.3                95.5      97.8  \n",
       "13         87.1           82.9               106.7      97.3  \n",
       "14         87.2          100.9               100.9      99.0  \n",
       "15         77.3           97.0                93.1      94.3  \n",
       "16         73.8          103.0                92.3      98.9  \n",
       "17         77.4           97.6                92.8      89.2  \n",
       "18         86.6           89.3                98.5      98.8  \n",
       "19        170.3          109.7               116.0     117.6  \n",
       "20        184.5          107.3               116.7      89.2  \n",
       "21        123.1          116.1               121.4     121.8  \n",
       "22         75.2           97.3                97.4      93.0  \n",
       "23         88.3           96.8               103.7     108.6  \n",
       "24         70.6           99.6                87.3      95.7  \n",
       "25         70.1           89.1                89.2      91.4  \n",
       "26        111.6           83.9               125.0      98.4  \n",
       "27         83.1           97.9                93.4     110.6  \n",
       "28         90.3           93.6               104.3     111.7  \n",
       "29         80.9           90.8                94.3      99.9  \n",
       "30        110.3          119.5               111.4     116.1  \n",
       "31        163.1          101.6               111.1     101.7  \n",
       "32         77.7           87.9                91.6     100.1  \n",
       "33        121.8           89.0               123.5     105.7  \n",
       "34        204.4          108.7               116.6     104.8  \n",
       "35         73.6           91.8                96.7      97.6  \n",
       "36         71.9           94.1                89.5      93.2  \n",
       "37        181.8           88.0               136.7     113.2  \n",
       "38        100.8          106.0               109.5      91.9  \n",
       "39        129.4          123.5               124.0     109.3  \n",
       "40         85.1          107.6                88.0      94.2  \n",
       "41        109.8           91.8                89.8     103.0  \n",
       "42         80.2           93.4                89.7      88.5  \n",
       "43         85.3          102.3                91.4      96.2  \n",
       "44         93.6           89.4               108.6      96.0  \n",
       "45        108.0           99.2                88.1      97.2  \n",
       "46        126.7          120.2               119.9     101.2  \n",
       "47        117.8           88.7               121.7     118.9  \n",
       "48         91.4           98.9                98.1     115.2  \n",
       "49         79.6           89.0                93.5      89.1  \n",
       "50         72.3           87.3                99.3      94.9  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gmaps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.stats as st\n",
    "from scipy.stats import chi2_contingency\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg') \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import researchpy\n",
    "from scipy.stats import chisquare\n",
    "from scipy.stats import linregress\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    " \n",
    "\n",
    "# # Google developer API key\n",
    "# from config import gkey\n",
    "\n",
    "# # Configure gmaps\n",
    "# gmaps.configure(api_key=gkey)\n",
    "\n",
    "#This is the general/common section\n",
    "path = pd.read_csv('../01._Prospective_Project_Data/1._72199_158097_compressed_indeed_job_dataset.csv/indeed_job_dataset_V3_CSV.csv')\n",
    "df = pd.DataFrame(path)\n",
    "df\n",
    "\n",
    "df.fillna(0) \n",
    "# df\n",
    "\n",
    "path2 = pd.read_csv('../01._Prospective_Project_Data/BLS_Data/OES_Report-V2.csv')\n",
    "BLS_df = pd.DataFrame(path2)\n",
    "BLS_df\n",
    "BLS_df[\"Annual mean wage(2)\"] = BLS_df[\"Annual mean wage(2)\"].str.replace(\",\",\"\")\n",
    "BLS_df[\"Annual mean wage(2)\"] = BLS_df[\"Annual mean wage(2)\"].astype(\"float64\")\n",
    "BLS_df = BLS_df.groupby('State_Two-Letter').agg({\"Annual mean wage(2)\":\"mean\"}).reset_index()\n",
    "# # BLS_df\n",
    "# # BLS_df = pd.DataFrame(BLS_df).mean()\n",
    "BLS_df\n",
    "\n",
    "path3 = pd.read_csv('../01._Prospective_Project_Data/Consumer_Price_Data/CPI_Data_V2_No_DC.csv')\n",
    "CPI_df = pd.DataFrame(path3)\n",
    "CPI_df\n",
    "\n",
    "df_grouped= df.groupby('Location')['Salary_Index'].agg(['mean','median', 'var', 'std', 'sem']).reset_index()\n",
    "df_grouped = pd.DataFrame(df_grouped)\n",
    "df_grouped\n",
    "df_grouped\n",
    "\n",
    "df_grouped = df_grouped.rename(columns={'Location':'State_Two-Letter'})\n",
    "df_grouped\n",
    "\n",
    "merge_df = pd.merge(BLS_df, df_grouped, how='left', on='State_Two-Letter')      \n",
    "merge_df\n",
    "merge_df = pd.merge(merge_df, CPI_df, how='left', on='State_Two-Letter')      \n",
    "merge_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop observations/rows with \"0\" values for \"Number of Skills\" column \n",
    "df_cleaned = df.dropna(subset=['No_of_Skills'])\n",
    "\n",
    "# Examine df\n",
    "# df_cleaned.head()\n",
    "# df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select Columns to keep in df copy\n",
    "df_cleaned.dtypes\n",
    "df1 = df_cleaned.drop(columns=\"Link\")\n",
    "# df1 = df1.drop(columns=\"Description\")\n",
    "df1 = df1.drop(columns=\"Index_No\")\n",
    "# df1\n",
    "                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Make DataFrame with just Salary_Index of 1, top income bracket\n",
    "# df1_6 = df1[df['Salary_Index']==1]\n",
    "# len(df1_6['Salary_Index'])\n",
    "# # df1_6\n",
    "\n",
    "# # Make DataFrame with just Salary_Index of 6, top income bracket\n",
    "# df1_6 = df1[df1['Salary_Index']==6]\n",
    "# len(df1_6['Salary_Index'])\n",
    "# # df1_6\n",
    "\n",
    "# # Make DataFrame with just Salary_Index of 6, top income bracket\n",
    "# df1_6 = df1[df1['Salary_Index']==6]\n",
    "# len(df1_6['Salary_Index'])\n",
    "# # df1_6\n",
    "\n",
    "# # Make DataFrame with just Salary_Index of 6, top income bracket\n",
    "# df1_6 = df1[df1['Salary_Index']==6]\n",
    "# len(df1_6['Salary_Index'])\n",
    "# # df1_6\n",
    "\n",
    "# # Make DataFrame with just Salary_Index of 6, top income bracket\n",
    "# df1_6 = df1[df1['Salary_Index']==6]\n",
    "# len(df1_6['Salary_Index'])\n",
    "# # df1_6\n",
    "\n",
    "# # Make DataFrame with just Salary_Index of 6, top income bracket\n",
    "# df1_6 = df1[df1['Salary_Index']==6]\n",
    "# len(df1_6['Salary_Index'])\n",
    "# # df1_6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Make DataFrame with just Salary_Index of 6, top income bracket\n",
    "df1_6 = df1[df1['Salary_Index']==6]\n",
    "len(df1_6['Salary_Index'])\n",
    "# df1_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind = df1_6.loc[:,['Queried_Salary', 'Company_Industry']]\n",
    "df_ind \n",
    "\n",
    "df_ind = df_ind.replace('', np.NaN)\n",
    "df_ind\n",
    "\n",
    "df_ind=df_ind.replace({'Insurance' : 'Other'})\n",
    "df_ind=df_ind.replace({'Health Care' : 'Other'})\n",
    "df_ind=df_ind.replace({'Media, News and Publishing' : 'Other'})\n",
    "df_ind=df_ind.replace({'Telecommunications' : 'Other'})\n",
    "df_ind=df_ind.replace({'Industrial Manufacturing' : 'Other'})\n",
    "df_ind=df_ind.replace({'Pharmaceuticals' : 'Other'})\n",
    "df_ind=df_ind.replace({'Retail' : 'Other'})\n",
    "df_ind=df_ind.replace({'Aerospace and Defense' : 'Other'})\n",
    "df_ind=df_ind.replace({'Auto' : 'Other'})\n",
    "df_ind=df_ind.replace({'Consumer Goods and Services' : 'Other'})\n",
    "df_ind=df_ind.replace({'Real Estate' : 'Other'})\n",
    "df_ind=df_ind.replace({'Construction' : 'Other'})\n",
    "df_ind=df_ind.replace({'Energy and Utilities' : 'Other'})\n",
    "df_ind=df_ind.replace({'Restaurants, Travel and LeisureConsulting and Business Services' : 'Other'})\n",
    "df_ind=df_ind.replace({'Transport and Freight' : 'Other'})\n",
    "# df_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Consulting and Business Services</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Internet and Software</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Banks and Financial Services</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Human Resources and Staffing</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computers and Electronics</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Industry\n",
       "Consulting and Business Services        80\n",
       "Internet and Software                   50\n",
       "Other                                   43\n",
       "Banks and Financial Services            41\n",
       "Human Resources and Staffing            30\n",
       "Computers and Electronics               10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind = df_ind['Company_Industry'].value_counts()\n",
    "df_ind\n",
    "df_ind_sum = pd.DataFrame ({\"Industry\": df_ind})\n",
    "df_ind_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2338ddd9988>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind.plot(kind = 'pie', autopct = '%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top skills by industry\n",
    "df1['Company_Industry'].value_counts()\n",
    "# Top five industries are: \n",
    "# Consulting and Business Services                                   712\n",
    "# Internet and Software                                              620\n",
    "# Banks and Financial Services                                       455\n",
    "# Health Care                                                        306\n",
    "# Insurance                                                          214\n",
    "\n",
    "df_ind2 = df1.loc[:,['Queried_Salary', 'Company_Industry']]\n",
    "len(df_ind2 )\n",
    "\n",
    "df_ind2 = df_ind2.replace('', np.NaN)\n",
    "len(df_ind2)\n",
    "sum(df_ind2['Company_Industry'].value_counts())\n",
    "# 3,675 + 1,809 blanks = 5,484 total\n",
    "\n",
    "# # df_ind2=df_ind2.replace({'Health Care' : 'Other'})\n",
    "# # df_ind2=df_ind2.replace({'Insurance' : 'Other'})\n",
    "\n",
    "df_ind2=df_ind2.replace({'Industrial Manufacturing' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Aerospace and Defense' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Retail' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Education and Schools' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Computers and Electronics' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Consumer Goods and Services' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Media, News and Publishing' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Human Resources and Staffing' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Telecommunications' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Government' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Pharmaceuticals' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Energy and Utilities' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Restaurants, Travel and Leisure' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Restaurants, Travel and LeisureConsulting and Business Services' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Auto' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Transport and Freight' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'InsuranceHealth Care' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Real Estate' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Organization' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Agriculture and Extraction' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Food and Beverages' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Construction' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'RetailConsumer Goods and Services' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Real EstateReal Estate' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Industrial ManufacturingConsumer Goods and Services' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Industrial ManufacturingConstruction' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Food and BeveragesConsulting and Business Services' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Industrial ManufacturingAgriculture and Extraction' : 'Other'})\n",
    "# sum(df_ind2['Company_Industry'].value_counts())\n",
    "# 3,675 is count, none lost in process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consulting and Business Services</th>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Internet and Software</th>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Banks and Financial Services</th>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health Care</th>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insurance</th>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Industry\n",
       "Other                                 1368\n",
       "Consulting and Business Services       712\n",
       "Internet and Software                  620\n",
       "Banks and Financial Services           455\n",
       "Health Care                            306\n",
       "Insurance                              214"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind2 = df_ind2['Company_Industry'].value_counts()\n",
    "df_ind2\n",
    "df_ind2_sum = pd.DataFrame ({\"Industry\": df_ind2})\n",
    "df_ind2_sum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x233837ba348>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind2.plot(kind = 'pie', autopct = '%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Dataset for just Industry = Consulting and Business Services\n",
    "df1_CBS = df1[df1['Company_Industry']=='Consulting and Business Services']\n",
    "df1_CBS\n",
    "\n",
    "CBS_sum_Py = sum(df1_CBS['python'])\n",
    "CBS_sum_Py\n",
    "CBS_sum_SQL = sum(df1_CBS['sql'])\n",
    "CBS_sum_ML = sum(df1_CBS['machine learning'])\n",
    "CBS_sum_R = sum(df1_CBS['r'])\n",
    "CBS_sum_Had = sum(df1_CBS['hadoop'])\n",
    "CBS_sum_Tab = sum(df1_CBS['tableau'])\n",
    "CBS_sum_SAS = sum(df1_CBS['sas'])\n",
    "CBS_sum_Spark = sum(df1_CBS['spark'])\n",
    "CBS_sum_Java = sum(df1_CBS['java'])\n",
    "CBS_sum_Others = sum(df1_CBS['Others'])\n",
    "\n",
    "# Make Dataset for just Industry = Consulting and Business Services\n",
    "df1_CBS = df1[df1['Company_Industry']=='Consulting and Business Services']\n",
    "df1_CBS\n",
    "CBS_sum_Total = len(df1_CBS)\n",
    "\n",
    "CBS_sum_Py = sum(df1_CBS['python'])\n",
    "CBS_sum_Py\n",
    "CBS_sum_SQL = sum(df1_CBS['sql'])\n",
    "CBS_sum_ML = sum(df1_CBS['machine learning'])\n",
    "CBS_sum_R = sum(df1_CBS['r'])\n",
    "CBS_sum_Had = sum(df1_CBS['hadoop'])\n",
    "CBS_sum_Tab = sum(df1_CBS['tableau'])\n",
    "CBS_sum_SAS = sum(df1_CBS['sas'])\n",
    "CBS_sum_Spark = sum(df1_CBS['spark'])\n",
    "CBS_sum_Java = sum(df1_CBS['java'])\n",
    "CBS_sum_Others = sum(df1_CBS['Others'])\n",
    "\n",
    "# Make Dataset for just Industry = Internet and Software\n",
    "df1_IS = df1[df1['Company_Industry']=='Internet and Software']\n",
    "df1_IS\n",
    "IS_sum_Total = len(df1_IS)\n",
    "\n",
    "IS_sum_Py = sum(df1_IS['python'])\n",
    "IS_sum_Py\n",
    "IS_sum_SQL = sum(df1_IS['sql'])\n",
    "IS_sum_ML = sum(df1_IS['machine learning'])\n",
    "IS_sum_R = sum(df1_IS['r'])\n",
    "IS_sum_Had = sum(df1_IS['hadoop'])\n",
    "IS_sum_Tab = sum(df1_IS['tableau'])\n",
    "IS_sum_SAS = sum(df1_IS['sas'])\n",
    "IS_sum_Spark = sum(df1_IS['spark'])\n",
    "IS_sum_Java = sum(df1_IS['java'])\n",
    "IS_sum_Others = sum(df1_IS['Others'])\n",
    "\n",
    "# Make Dataset for just Industry = Banks and Financial Services\n",
    "df1_BFS = df1[df1['Company_Industry']=='Banks and Financial Services']\n",
    "df1_BFS\n",
    "BFS_sum_Total = len(df1_BFS)\n",
    "\n",
    "BFS_sum_Py = sum(df1_BFS['python'])\n",
    "BFS_sum_Py\n",
    "BFS_sum_SQL = sum(df1_BFS['sql'])\n",
    "BFS_sum_ML = sum(df1_BFS['machine learning'])\n",
    "BFS_sum_R = sum(df1_BFS['r'])\n",
    "BFS_sum_Had = sum(df1_BFS['hadoop'])\n",
    "BFS_sum_Tab = sum(df1_BFS['tableau'])\n",
    "BFS_sum_SAS = sum(df1_BFS['sas'])\n",
    "BFS_sum_Spark = sum(df1_BFS['spark'])\n",
    "BFS_sum_Java = sum(df1_BFS['java'])\n",
    "BFS_sum_Others = sum(df1_BFS['Others'])\n",
    "\n",
    "# Make Dataset for just Industry = Health Care\n",
    "df1_HC = df1[df1['Company_Industry']== 'Health Care']\n",
    "df1_HC\n",
    "HC_sum_Total = len(df1_HC)\n",
    "\n",
    "HC_sum_Py = sum(df1_HC['python'])\n",
    "HC_sum_Py\n",
    "HC_sum_SQL = sum(df1_HC['sql'])\n",
    "HC_sum_ML = sum(df1_HC['machine learning'])\n",
    "HC_sum_R = sum(df1_HC['r'])\n",
    "HC_sum_Had = sum(df1_HC['hadoop'])\n",
    "HC_sum_Tab = sum(df1_HC['tableau'])\n",
    "HC_sum_SAS = sum(df1_HC['sas'])\n",
    "HC_sum_Spark = sum(df1_HC['spark'])\n",
    "HC_sum_Java = sum(df1_HC['java'])\n",
    "HC_sum_Others = sum(df1_HC['Others'])\n",
    "\n",
    "# Make Dataset for just Industry = Insurance\n",
    "df1_I = df1[df1['Company_Industry']== 'Insurance']\n",
    "df1_I\n",
    "I_sum_Total = len(df1_I)\n",
    "\n",
    "I_sum_Py = sum(df1_I['python'])\n",
    "I_sum_Py\n",
    "I_sum_SQL = sum(df1_I['sql'])\n",
    "I_sum_ML = sum(df1_I['machine learning'])\n",
    "I_sum_R = sum(df1_I['r'])\n",
    "I_sum_Had = sum(df1_I['hadoop'])\n",
    "I_sum_Tab = sum(df1_I['tableau'])\n",
    "I_sum_SAS = sum(df1_I['sas'])\n",
    "I_sum_Spark = sum(df1_I['spark'])\n",
    "I_sum_Java = sum(df1_I['java'])\n",
    "I_sum_Others = sum(df1_I['Others'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill</th>\n",
       "      <th>Consulting and Business Services</th>\n",
       "      <th>Internet and Software</th>\n",
       "      <th>Banks and Financial Services</th>\n",
       "      <th>Health Care</th>\n",
       "      <th>Insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>426.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "      <td>377.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>340.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r</td>\n",
       "      <td>275.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hadoop</td>\n",
       "      <td>270.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tableau</td>\n",
       "      <td>200.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sas</td>\n",
       "      <td>121.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spark</td>\n",
       "      <td>235.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>java</td>\n",
       "      <td>182.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Others</td>\n",
       "      <td>658.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Total</td>\n",
       "      <td>712.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Skill  Consulting and Business Services  Internet and Software  \\\n",
       "0             python                             426.0                  432.0   \n",
       "1                sql                             377.0                  411.0   \n",
       "2   machine learning                             340.0                  291.0   \n",
       "3                  r                             275.0                  266.0   \n",
       "4             hadoop                             270.0                  242.0   \n",
       "5            tableau                             200.0                  105.0   \n",
       "6                sas                             121.0                   82.0   \n",
       "7              spark                             235.0                  212.0   \n",
       "8               java                             182.0                  215.0   \n",
       "9             Others                             658.0                  583.0   \n",
       "10             Total                             712.0                  620.0   \n",
       "\n",
       "    Banks and Financial Services  Health Care  Insurance  \n",
       "0                          264.0        126.0      124.0  \n",
       "1                          310.0        204.0      143.0  \n",
       "2                          187.0         86.0       85.0  \n",
       "3                          171.0        112.0      103.0  \n",
       "4                          165.0         56.0       93.0  \n",
       "5                          105.0         82.0       49.0  \n",
       "6                           96.0         92.0       59.0  \n",
       "7                          160.0         51.0       35.0  \n",
       "8                          163.0         63.0       71.0  \n",
       "9                          436.0        290.0      194.0  \n",
       "10                         455.0        306.0      214.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Skill= ['python', 'sql','machine learning', 'r', 'hadoop', 'tableau', 'sas', 'spark', 'java', 'Others', 'Total']\n",
    "CBS = [CBS_sum_Py, CBS_sum_SQL, CBS_sum_ML, CBS_sum_R, CBS_sum_Had, CBS_sum_Tab, CBS_sum_SAS, CBS_sum_Spark, CBS_sum_Java, CBS_sum_Others, CBS_sum_Total]\n",
    "IS = [IS_sum_Py, IS_sum_SQL, IS_sum_ML, IS_sum_R, IS_sum_Had, IS_sum_Tab, IS_sum_SAS, IS_sum_Spark, IS_sum_Java, IS_sum_Others, IS_sum_Total]\n",
    "BFS = [BFS_sum_Py, BFS_sum_SQL, BFS_sum_ML, BFS_sum_R, BFS_sum_Had, BFS_sum_Tab, BFS_sum_SAS, BFS_sum_Spark, BFS_sum_Java, BFS_sum_Others, BFS_sum_Total]\n",
    "HC = [HC_sum_Py, HC_sum_SQL, HC_sum_ML, HC_sum_R, HC_sum_Had, HC_sum_Tab, HC_sum_SAS, HC_sum_Spark, HC_sum_Java, HC_sum_Others, HC_sum_Total]\n",
    "I = [I_sum_Py, I_sum_SQL, I_sum_ML, I_sum_R, I_sum_Had, I_sum_Tab, I_sum_SAS, I_sum_Spark, I_sum_Java, I_sum_Others, I_sum_Total]\n",
    "\n",
    "industry_sum = pd.DataFrame({\n",
    "    'Skill':Skill,\n",
    "    'Consulting and Business Services': CBS,\n",
    "    'Internet and Software': IS,\n",
    "    'Banks and Financial Services': BFS,\n",
    "    'Health Care': HC,\n",
    "    'Insurance': I\n",
    "})\n",
    "industry_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Dataset for just Industry = Consulting and Business Services\n",
    "df1_CBS = df1[df1['Company_Industry']=='Consulting and Business Services']\n",
    "df1_CBS\n",
    "CBS_sum_Total = len(df1_CBS)\n",
    "\n",
    "CBS_sum_Py_p = sum(df1_CBS['python'])/CBS_sum_Total\n",
    "CBS_sum_Py_p\n",
    "CBS_sum_SQL_p = sum(df1_CBS['sql'])/CBS_sum_Total\n",
    "CBS_sum_ML_p = sum(df1_CBS['machine learning'])/CBS_sum_Total\n",
    "CBS_sum_R_p = sum(df1_CBS['r'])/CBS_sum_Total\n",
    "CBS_sum_Had_p = sum(df1_CBS['hadoop'])/CBS_sum_Total\n",
    "CBS_sum_Tab_p = sum(df1_CBS['tableau'])/CBS_sum_Total\n",
    "CBS_sum_SAS_p = sum(df1_CBS['sas'])/CBS_sum_Total\n",
    "CBS_sum_Spark_p = sum(df1_CBS['spark'])/CBS_sum_Total\n",
    "CBS_sum_Java_p = sum(df1_CBS['java'])/CBS_sum_Total\n",
    "CBS_sum_Others_p = sum(df1_CBS['Others'])/CBS_sum_Total\n",
    "\n",
    "# Make Dataset for just Industry = Internet and Software\n",
    "df1_IS = df1[df1['Company_Industry']=='Internet and Software']\n",
    "df1_IS\n",
    "IS_sum_Total = len(df1_IS)\n",
    "\n",
    "IS_sum_Py_p = sum(df1_IS['python'])/IS_sum_Total\n",
    "IS_sum_Py_p\n",
    "IS_sum_SQL_p = sum(df1_IS['sql'])/IS_sum_Total\n",
    "IS_sum_ML_p = sum(df1_IS['machine learning'])/IS_sum_Total\n",
    "IS_sum_R_p = sum(df1_IS['r'])/IS_sum_Total\n",
    "IS_sum_Had_p = sum(df1_IS['hadoop'])/IS_sum_Total\n",
    "IS_sum_Tab_p = sum(df1_IS['tableau'])/IS_sum_Total\n",
    "IS_sum_SAS_p = sum(df1_IS['sas'])/IS_sum_Total\n",
    "IS_sum_Spark_p = sum(df1_IS['spark'])/IS_sum_Total\n",
    "IS_sum_Java_p = sum(df1_IS['java'])/IS_sum_Total\n",
    "IS_sum_Others_p = sum(df1_IS['Others'])/IS_sum_Total\n",
    "\n",
    "# Make Dataset for just Industry = Banks and Financial Services\n",
    "df1_BFS = df1[df1['Company_Industry']=='Banks and Financial Services']\n",
    "df1_BFS\n",
    "BFS_sum_Total = len(df1_BFS)\n",
    "\n",
    "BFS_sum_Py_p = sum(df1_BFS['python'])/BFS_sum_Total\n",
    "BFS_sum_Py_p\n",
    "BFS_sum_SQL_p = sum(df1_BFS['sql'])/BFS_sum_Total\n",
    "BFS_sum_ML_p = sum(df1_BFS['machine learning'])/BFS_sum_Total\n",
    "BFS_sum_R_p = sum(df1_BFS['r'])/BFS_sum_Total\n",
    "BFS_sum_Had_p = sum(df1_BFS['hadoop'])/BFS_sum_Total\n",
    "BFS_sum_Tab_p = sum(df1_BFS['tableau'])/BFS_sum_Total\n",
    "BFS_sum_SAS_p = sum(df1_BFS['sas'])/BFS_sum_Total\n",
    "BFS_sum_Spark_p = sum(df1_BFS['spark'])/BFS_sum_Total\n",
    "BFS_sum_Java_p = sum(df1_BFS['java'])/BFS_sum_Total\n",
    "BFS_sum_Others_p = sum(df1_BFS['Others'])/BFS_sum_Total\n",
    "\n",
    "# Make Dataset for just Industry = Health Care\n",
    "df1_HC = df1[df1['Company_Industry']== 'Health Care']\n",
    "df1_HC\n",
    "HC_sum_Total = len(df1_HC)\n",
    "\n",
    "HC_sum_Py_p = sum(df1_HC['python'])/HC_sum_Total\n",
    "HC_sum_Py_p\n",
    "HC_sum_SQL_p = sum(df1_HC['sql'])/HC_sum_Total\n",
    "HC_sum_ML_p = sum(df1_HC['machine learning'])/HC_sum_Total\n",
    "HC_sum_R_p = sum(df1_HC['r'])/HC_sum_Total\n",
    "HC_sum_Had_p = sum(df1_HC['hadoop'])/HC_sum_Total\n",
    "HC_sum_Tab_p = sum(df1_HC['tableau'])/HC_sum_Total\n",
    "HC_sum_SAS_p = sum(df1_HC['sas'])/HC_sum_Total\n",
    "HC_sum_Spark_p = sum(df1_HC['spark'])/HC_sum_Total\n",
    "HC_sum_Java_p = sum(df1_HC['java'])/HC_sum_Total\n",
    "HC_sum_Others_p = sum(df1_HC['Others'])/HC_sum_Total\n",
    "\n",
    "# Make Dataset for just Industry = Insurance\n",
    "df1_I = df1[df1['Company_Industry']== 'Insurance']\n",
    "df1_I\n",
    "I_sum_Total = len(df1_I)\n",
    "\n",
    "I_sum_Py_p = sum(df1_I['python'])/I_sum_Total\n",
    "I_sum_Py_p\n",
    "I_sum_SQL_p = sum(df1_I['sql'])/I_sum_Total\n",
    "I_sum_ML_p = sum(df1_I['machine learning'])/I_sum_Total\n",
    "I_sum_R_p = sum(df1_I['r'])/I_sum_Total\n",
    "I_sum_Had_p = sum(df1_I['hadoop'])/I_sum_Total\n",
    "I_sum_Tab_p = sum(df1_I['tableau'])/I_sum_Total\n",
    "I_sum_SAS_p = sum(df1_I['sas'])/I_sum_Total\n",
    "I_sum_Spark_p = sum(df1_I['spark'])/I_sum_Total\n",
    "I_sum_Java_p = sum(df1_I['java'])/I_sum_Total\n",
    "I_sum_Others_p = sum(df1_I['Others'])/I_sum_Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill</th>\n",
       "      <th>Consulting and Business Services</th>\n",
       "      <th>Internet and Software</th>\n",
       "      <th>Banks and Financial Services</th>\n",
       "      <th>Health Care</th>\n",
       "      <th>Insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>59.83%</td>\n",
       "      <td>69.68%</td>\n",
       "      <td>58.02%</td>\n",
       "      <td>41.18%</td>\n",
       "      <td>57.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "      <td>52.95%</td>\n",
       "      <td>66.29%</td>\n",
       "      <td>68.13%</td>\n",
       "      <td>66.67%</td>\n",
       "      <td>66.82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>47.75%</td>\n",
       "      <td>46.94%</td>\n",
       "      <td>41.10%</td>\n",
       "      <td>28.10%</td>\n",
       "      <td>39.72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r</td>\n",
       "      <td>38.62%</td>\n",
       "      <td>42.90%</td>\n",
       "      <td>37.58%</td>\n",
       "      <td>36.60%</td>\n",
       "      <td>48.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hadoop</td>\n",
       "      <td>37.92%</td>\n",
       "      <td>39.03%</td>\n",
       "      <td>36.26%</td>\n",
       "      <td>18.30%</td>\n",
       "      <td>43.46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tableau</td>\n",
       "      <td>28.09%</td>\n",
       "      <td>16.94%</td>\n",
       "      <td>23.08%</td>\n",
       "      <td>26.80%</td>\n",
       "      <td>22.90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sas</td>\n",
       "      <td>16.99%</td>\n",
       "      <td>13.23%</td>\n",
       "      <td>21.10%</td>\n",
       "      <td>30.07%</td>\n",
       "      <td>27.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spark</td>\n",
       "      <td>33.01%</td>\n",
       "      <td>34.19%</td>\n",
       "      <td>35.16%</td>\n",
       "      <td>16.67%</td>\n",
       "      <td>16.36%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>java</td>\n",
       "      <td>25.56%</td>\n",
       "      <td>34.68%</td>\n",
       "      <td>35.82%</td>\n",
       "      <td>20.59%</td>\n",
       "      <td>33.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Others</td>\n",
       "      <td>92.42%</td>\n",
       "      <td>94.03%</td>\n",
       "      <td>95.82%</td>\n",
       "      <td>94.77%</td>\n",
       "      <td>90.65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Total</td>\n",
       "      <td>712</td>\n",
       "      <td>620</td>\n",
       "      <td>455</td>\n",
       "      <td>306</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Skill Consulting and Business Services Internet and Software  \\\n",
       "0             python                           59.83%                69.68%   \n",
       "1                sql                           52.95%                66.29%   \n",
       "2   machine learning                           47.75%                46.94%   \n",
       "3                  r                           38.62%                42.90%   \n",
       "4             hadoop                           37.92%                39.03%   \n",
       "5            tableau                           28.09%                16.94%   \n",
       "6                sas                           16.99%                13.23%   \n",
       "7              spark                           33.01%                34.19%   \n",
       "8               java                           25.56%                34.68%   \n",
       "9             Others                           92.42%                94.03%   \n",
       "10             Total                              712                   620   \n",
       "\n",
       "   Banks and Financial Services Health Care Insurance  \n",
       "0                        58.02%      41.18%    57.94%  \n",
       "1                        68.13%      66.67%    66.82%  \n",
       "2                        41.10%      28.10%    39.72%  \n",
       "3                        37.58%      36.60%    48.13%  \n",
       "4                        36.26%      18.30%    43.46%  \n",
       "5                        23.08%      26.80%    22.90%  \n",
       "6                        21.10%      30.07%    27.57%  \n",
       "7                        35.16%      16.67%    16.36%  \n",
       "8                        35.82%      20.59%    33.18%  \n",
       "9                        95.82%      94.77%    90.65%  \n",
       "10                          455         306       214  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### Proportions, not Percentages. With Others and Total\n",
    "\n",
    "\n",
    "Skill= ['python', 'sql','machine learning', 'r', 'hadoop', 'tableau', 'sas', 'spark', 'java', 'Others', 'Total']\n",
    "CBS = [\"{:.2%}\".format(CBS_sum_Py_p), \n",
    "       \"{:.2%}\".format(CBS_sum_SQL_p), \n",
    "       \"{:.2%}\".format(CBS_sum_ML_p), \n",
    "       \"{:.2%}\".format(CBS_sum_R_p), \n",
    "       \"{:.2%}\".format(CBS_sum_Had_p), \n",
    "       \"{:.2%}\".format(CBS_sum_Tab_p), \n",
    "       \"{:.2%}\".format(CBS_sum_SAS_p), \n",
    "       \"{:.2%}\".format(CBS_sum_Spark_p), \n",
    "       \"{:.2%}\".format(CBS_sum_Java_p), \n",
    "       \"{:.2%}\".format(CBS_sum_Others_p), \n",
    "       CBS_sum_Total]\n",
    "IS = [\"{:.2%}\".format(IS_sum_Py_p), \n",
    "      \"{:.2%}\".format(IS_sum_SQL_p), \n",
    "      \"{:.2%}\".format(IS_sum_ML_p), \n",
    "      \"{:.2%}\".format(IS_sum_R_p), \n",
    "      \"{:.2%}\".format(IS_sum_Had_p), \n",
    "      \"{:.2%}\".format(IS_sum_Tab_p), \n",
    "      \"{:.2%}\".format(IS_sum_SAS_p), \n",
    "      \"{:.2%}\".format(IS_sum_Spark_p), \n",
    "      \"{:.2%}\".format(IS_sum_Java_p), \n",
    "      \"{:.2%}\".format(IS_sum_Others_p), \n",
    "      IS_sum_Total]\n",
    "BFS = [\"{:.2%}\".format(BFS_sum_Py_p), \n",
    "       \"{:.2%}\".format(BFS_sum_SQL_p), \n",
    "       \"{:.2%}\".format(BFS_sum_ML_p), \n",
    "       \"{:.2%}\".format(BFS_sum_R_p), \n",
    "       \"{:.2%}\".format(BFS_sum_Had_p), \n",
    "       \"{:.2%}\".format(BFS_sum_Tab_p), \n",
    "       \"{:.2%}\".format(BFS_sum_SAS_p), \n",
    "       \"{:.2%}\".format(BFS_sum_Spark_p), \n",
    "       \"{:.2%}\".format(BFS_sum_Java_p), \n",
    "       \"{:.2%}\".format(BFS_sum_Others_p), \n",
    "       BFS_sum_Total]\n",
    "HC = [\"{:.2%}\".format(HC_sum_Py_p), \n",
    "      \"{:.2%}\".format(HC_sum_SQL_p), \n",
    "      \"{:.2%}\".format(HC_sum_ML_p), \n",
    "      \"{:.2%}\".format(HC_sum_R_p), \n",
    "      \"{:.2%}\".format(HC_sum_Had_p), \n",
    "      \"{:.2%}\".format(HC_sum_Tab_p), \n",
    "      \"{:.2%}\".format(HC_sum_SAS_p), \n",
    "      \"{:.2%}\".format(HC_sum_Spark_p), \n",
    "      \"{:.2%}\".format(HC_sum_Java_p), \n",
    "      \"{:.2%}\".format(HC_sum_Others_p), \n",
    "      HC_sum_Total]\n",
    "I = [\"{:.2%}\".format(I_sum_Py_p),\n",
    "     \"{:.2%}\".format(I_sum_SQL_p),\n",
    "     \"{:.2%}\".format(I_sum_ML_p),\n",
    "     \"{:.2%}\".format(I_sum_R_p),\n",
    "     \"{:.2%}\".format(I_sum_Had_p),\n",
    "     \"{:.2%}\".format(I_sum_Tab_p),\n",
    "     \"{:.2%}\".format(I_sum_SAS_p),\n",
    "     \"{:.2%}\".format(I_sum_Spark_p),\n",
    "     \"{:.2%}\".format(I_sum_Java_p),\n",
    "     \"{:.2%}\".format(I_sum_Others_p),\n",
    "     I_sum_Total]\n",
    "\n",
    "industry_sum_p = pd.DataFrame({\n",
    "    'Skill':Skill,\n",
    "    'Consulting and Business Services': CBS,\n",
    "    'Internet and Software': IS,\n",
    "    'Banks and Financial Services': BFS,\n",
    "    'Health Care': HC,\n",
    "    'Insurance': I\n",
    "})\n",
    "industry_sum_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill</th>\n",
       "      <th>Consulting and Business Services</th>\n",
       "      <th>Internet and Software</th>\n",
       "      <th>Banks and Financial Services</th>\n",
       "      <th>Health Care</th>\n",
       "      <th>Insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>0.598315</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.580220</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.579439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "      <td>0.529494</td>\n",
       "      <td>0.662903</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.668224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>0.477528</td>\n",
       "      <td>0.469355</td>\n",
       "      <td>0.410989</td>\n",
       "      <td>0.281046</td>\n",
       "      <td>0.397196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r</td>\n",
       "      <td>0.386236</td>\n",
       "      <td>0.429032</td>\n",
       "      <td>0.375824</td>\n",
       "      <td>0.366013</td>\n",
       "      <td>0.481308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hadoop</td>\n",
       "      <td>0.379213</td>\n",
       "      <td>0.390323</td>\n",
       "      <td>0.362637</td>\n",
       "      <td>0.183007</td>\n",
       "      <td>0.434579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tableau</td>\n",
       "      <td>0.280899</td>\n",
       "      <td>0.169355</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.267974</td>\n",
       "      <td>0.228972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sas</td>\n",
       "      <td>0.169944</td>\n",
       "      <td>0.132258</td>\n",
       "      <td>0.210989</td>\n",
       "      <td>0.300654</td>\n",
       "      <td>0.275701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spark</td>\n",
       "      <td>0.330056</td>\n",
       "      <td>0.341935</td>\n",
       "      <td>0.351648</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.163551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>java</td>\n",
       "      <td>0.255618</td>\n",
       "      <td>0.346774</td>\n",
       "      <td>0.358242</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.331776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Others</td>\n",
       "      <td>0.924157</td>\n",
       "      <td>0.940323</td>\n",
       "      <td>0.958242</td>\n",
       "      <td>0.947712</td>\n",
       "      <td>0.906542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Skill  Consulting and Business Services  Internet and Software  \\\n",
       "0            python                          0.598315               0.696774   \n",
       "1               sql                          0.529494               0.662903   \n",
       "2  machine learning                          0.477528               0.469355   \n",
       "3                 r                          0.386236               0.429032   \n",
       "4            hadoop                          0.379213               0.390323   \n",
       "5           tableau                          0.280899               0.169355   \n",
       "6               sas                          0.169944               0.132258   \n",
       "7             spark                          0.330056               0.341935   \n",
       "8              java                          0.255618               0.346774   \n",
       "9            Others                          0.924157               0.940323   \n",
       "\n",
       "   Banks and Financial Services  Health Care  Insurance  \n",
       "0                      0.580220     0.411765   0.579439  \n",
       "1                      0.681319     0.666667   0.668224  \n",
       "2                      0.410989     0.281046   0.397196  \n",
       "3                      0.375824     0.366013   0.481308  \n",
       "4                      0.362637     0.183007   0.434579  \n",
       "5                      0.230769     0.267974   0.228972  \n",
       "6                      0.210989     0.300654   0.275701  \n",
       "7                      0.351648     0.166667   0.163551  \n",
       "8                      0.358242     0.205882   0.331776  \n",
       "9                      0.958242     0.947712   0.906542  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### Proportions, not Percentages. With Others\n",
    "\n",
    "Skill= ['python', 'sql','machine learning', 'r', 'hadoop', 'tableau', 'sas', 'spark', 'java', 'Others']\n",
    "CBS = [CBS_sum_Py_p, \n",
    "       CBS_sum_SQL_p, \n",
    "       CBS_sum_ML_p, \n",
    "       CBS_sum_R_p, \n",
    "       CBS_sum_Had_p, \n",
    "       CBS_sum_Tab_p, \n",
    "       CBS_sum_SAS_p, \n",
    "       CBS_sum_Spark_p, \n",
    "       CBS_sum_Java_p, \n",
    "       CBS_sum_Others_p]\n",
    "IS = [IS_sum_Py_p, \n",
    "      IS_sum_SQL_p, \n",
    "      IS_sum_ML_p, \n",
    "      IS_sum_R_p, \n",
    "      IS_sum_Had_p, \n",
    "      IS_sum_Tab_p, \n",
    "      IS_sum_SAS_p, \n",
    "      IS_sum_Spark_p, \n",
    "      IS_sum_Java_p, \n",
    "      IS_sum_Others_p]\n",
    "BFS = [BFS_sum_Py_p, \n",
    "       BFS_sum_SQL_p, \n",
    "       BFS_sum_ML_p, \n",
    "       BFS_sum_R_p, \n",
    "       BFS_sum_Had_p, \n",
    "       BFS_sum_Tab_p, \n",
    "       BFS_sum_SAS_p, \n",
    "       BFS_sum_Spark_p, \n",
    "       BFS_sum_Java_p, \n",
    "       BFS_sum_Others_p]\n",
    "HC = [HC_sum_Py_p, \n",
    "      HC_sum_SQL_p, \n",
    "      HC_sum_ML_p, \n",
    "      HC_sum_R_p, \n",
    "      HC_sum_Had_p, \n",
    "      HC_sum_Tab_p, \n",
    "      HC_sum_SAS_p, \n",
    "      HC_sum_Spark_p, \n",
    "      HC_sum_Java_p, \n",
    "      HC_sum_Others_p]\n",
    "I = [I_sum_Py_p,\n",
    "     I_sum_SQL_p,\n",
    "     I_sum_ML_p,\n",
    "     I_sum_R_p,\n",
    "     I_sum_Had_p,\n",
    "     I_sum_Tab_p,\n",
    "     I_sum_SAS_p,\n",
    "     I_sum_Spark_p,\n",
    "     I_sum_Java_p,\n",
    "     I_sum_Others_p]\n",
    "\n",
    "industry_sum_no_p = pd.DataFrame({\n",
    "    'Skill':Skill,\n",
    "    'Consulting and Business Services': CBS,\n",
    "    'Internet and Software': IS,\n",
    "    'Banks and Financial Services': BFS,\n",
    "    'Health Care': HC,\n",
    "    'Insurance': I\n",
    "})\n",
    "industry_sum_no_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Presence of Skill in Job Description\\n (Percentage)')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBSbar = industry_sum_no_p.loc[:, ['Skill', 'Consulting and Business Services']]\n",
    "CBSbar = CBSbar.set_index(['Skill'])\n",
    "CBSbar \n",
    "\n",
    "x_axis = CBSbar['Consulting and Business Services']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Consulting and Business Services\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Presence of Skill in Job Description\\n (Percentage)')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ISbar = industry_sum_no_p.loc[:, ['Skill', 'Internet and Software']]\n",
    "ISbar = ISbar.set_index(['Skill'])\n",
    "ISbar \n",
    "\n",
    "x_axis = ISbar['Internet and Software']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Internet and Software\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Presence of Skill in Job Description\\n (Percentage)')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BFSbar = industry_sum_no_p.loc[:, ['Skill', 'Banks and Financial Services']]\n",
    "BFSbar = BFSbar.set_index(['Skill'])\n",
    "BFSbar \n",
    "\n",
    "x_axis = BFSbar['Banks and Financial Services']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Banks and Financial Services\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Presence of Skill in Job Description\\n (Percentage)')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HCbar = industry_sum_no_p.loc[:, ['Skill', 'Health Care']]\n",
    "HCbar = HCbar.set_index(['Skill'])\n",
    "HCbar \n",
    "\n",
    "x_axis = HCbar['Health Care']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Health Care\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Presence of Skill in Job Description\\n (Percentage)')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ibar = industry_sum_no_p.loc[:, ['Skill', 'Insurance']]\n",
    "Ibar = Ibar.set_index(['Skill'])\n",
    "Ibar \n",
    "\n",
    "x_axis = Ibar['Insurance']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Insurance\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill</th>\n",
       "      <th>Consulting and Business Services</th>\n",
       "      <th>Internet and Software</th>\n",
       "      <th>Banks and Financial Services</th>\n",
       "      <th>Health Care</th>\n",
       "      <th>Insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>0.598315</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.580220</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.579439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "      <td>0.529494</td>\n",
       "      <td>0.662903</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.668224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>0.477528</td>\n",
       "      <td>0.469355</td>\n",
       "      <td>0.410989</td>\n",
       "      <td>0.281046</td>\n",
       "      <td>0.397196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r</td>\n",
       "      <td>0.386236</td>\n",
       "      <td>0.429032</td>\n",
       "      <td>0.375824</td>\n",
       "      <td>0.366013</td>\n",
       "      <td>0.481308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hadoop</td>\n",
       "      <td>0.379213</td>\n",
       "      <td>0.390323</td>\n",
       "      <td>0.362637</td>\n",
       "      <td>0.183007</td>\n",
       "      <td>0.434579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tableau</td>\n",
       "      <td>0.280899</td>\n",
       "      <td>0.169355</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.267974</td>\n",
       "      <td>0.228972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sas</td>\n",
       "      <td>0.169944</td>\n",
       "      <td>0.132258</td>\n",
       "      <td>0.210989</td>\n",
       "      <td>0.300654</td>\n",
       "      <td>0.275701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spark</td>\n",
       "      <td>0.330056</td>\n",
       "      <td>0.341935</td>\n",
       "      <td>0.351648</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.163551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>java</td>\n",
       "      <td>0.255618</td>\n",
       "      <td>0.346774</td>\n",
       "      <td>0.358242</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.331776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Skill  Consulting and Business Services  Internet and Software  \\\n",
       "0            python                          0.598315               0.696774   \n",
       "1               sql                          0.529494               0.662903   \n",
       "2  machine learning                          0.477528               0.469355   \n",
       "3                 r                          0.386236               0.429032   \n",
       "4            hadoop                          0.379213               0.390323   \n",
       "5           tableau                          0.280899               0.169355   \n",
       "6               sas                          0.169944               0.132258   \n",
       "7             spark                          0.330056               0.341935   \n",
       "8              java                          0.255618               0.346774   \n",
       "\n",
       "   Banks and Financial Services  Health Care  Insurance  \n",
       "0                      0.580220     0.411765   0.579439  \n",
       "1                      0.681319     0.666667   0.668224  \n",
       "2                      0.410989     0.281046   0.397196  \n",
       "3                      0.375824     0.366013   0.481308  \n",
       "4                      0.362637     0.183007   0.434579  \n",
       "5                      0.230769     0.267974   0.228972  \n",
       "6                      0.210989     0.300654   0.275701  \n",
       "7                      0.351648     0.166667   0.163551  \n",
       "8                      0.358242     0.205882   0.331776  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### No Others\n",
    "Skill= ['python', 'sql','machine learning', 'r', 'hadoop', 'tableau', 'sas', 'spark', 'java']\n",
    "CBS = [CBS_sum_Py_p, \n",
    "       CBS_sum_SQL_p, \n",
    "       CBS_sum_ML_p, \n",
    "       CBS_sum_R_p, \n",
    "       CBS_sum_Had_p, \n",
    "       CBS_sum_Tab_p, \n",
    "       CBS_sum_SAS_p, \n",
    "       CBS_sum_Spark_p, \n",
    "       CBS_sum_Java_p]\n",
    "IS = [IS_sum_Py_p, \n",
    "      IS_sum_SQL_p, \n",
    "      IS_sum_ML_p, \n",
    "      IS_sum_R_p, \n",
    "      IS_sum_Had_p, \n",
    "      IS_sum_Tab_p, \n",
    "      IS_sum_SAS_p, \n",
    "      IS_sum_Spark_p, \n",
    "      IS_sum_Java_p]\n",
    "BFS = [BFS_sum_Py_p, \n",
    "       BFS_sum_SQL_p, \n",
    "       BFS_sum_ML_p, \n",
    "       BFS_sum_R_p, \n",
    "       BFS_sum_Had_p, \n",
    "       BFS_sum_Tab_p, \n",
    "       BFS_sum_SAS_p, \n",
    "       BFS_sum_Spark_p, \n",
    "       BFS_sum_Java_p]\n",
    "HC = [HC_sum_Py_p, \n",
    "      HC_sum_SQL_p, \n",
    "      HC_sum_ML_p, \n",
    "      HC_sum_R_p, \n",
    "      HC_sum_Had_p, \n",
    "      HC_sum_Tab_p, \n",
    "      HC_sum_SAS_p, \n",
    "      HC_sum_Spark_p, \n",
    "      HC_sum_Java_p]\n",
    "I = [I_sum_Py_p,\n",
    "     I_sum_SQL_p,\n",
    "     I_sum_ML_p,\n",
    "     I_sum_R_p,\n",
    "     I_sum_Had_p,\n",
    "     I_sum_Tab_p,\n",
    "     I_sum_SAS_p,\n",
    "     I_sum_Spark_p,\n",
    "     I_sum_Java_p]\n",
    "\n",
    "industry_sum_no_p_no_o = pd.DataFrame({\n",
    "    'Skill':Skill,\n",
    "    'Consulting and Business Services': CBS,\n",
    "    'Internet and Software': IS,\n",
    "    'Banks and Financial Services': BFS,\n",
    "    'Health Care': HC,\n",
    "    'Insurance': I\n",
    "})\n",
    "industry_sum_no_p_no_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CBSbar = industry_sum_no_p_no_o.loc[:, ['Skill', 'Consulting and Business Services']]\n",
    "CBSbar = CBSbar.set_index(['Skill'])\n",
    "CBSbar \n",
    "\n",
    "x_axis = CBSbar['Consulting and Business Services']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Consulting and Business Services\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")\n",
    "\n",
    "# Save Plot\n",
    "plt.savefig('../04._Output/CBSbar_no_others.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISbar = industry_sum_no_p_no_o.loc[:, ['Skill', 'Internet and Software']]\n",
    "ISbar = ISbar.set_index(['Skill'])\n",
    "ISbar \n",
    "\n",
    "x_axis = ISbar['Internet and Software']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Internet and Software\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")\n",
    "\n",
    "# Save Plot\n",
    "plt.savefig('../04._Output/ISbar_no_others.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BFSbar = industry_sum_no_p_no_o.loc[:, ['Skill', 'Banks and Financial Services']]\n",
    "BFSbar = BFSbar.set_index(['Skill'])\n",
    "BFSbar \n",
    "\n",
    "x_axis = BFSbar['Banks and Financial Services']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Banks and Financial Services\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")\n",
    "\n",
    "\n",
    "# Save Plot\n",
    "plt.savefig('../04._Output/BFSbar_no_others.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCbar = industry_sum_no_p_no_o.loc[:, ['Skill', 'Health Care']]\n",
    "HCbar = HCbar.set_index(['Skill'])\n",
    "HCbar \n",
    "\n",
    "x_axis = HCbar['Health Care']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Health Care\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")\n",
    "\n",
    "# Save Plot\n",
    "plt.savefig('../04._Output/HCbar_no_others.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ibar = industry_sum_no_p_no_o.loc[:, ['Skill', 'Insurance']]\n",
    "Ibar = Ibar.set_index(['Skill'])\n",
    "Ibar \n",
    "\n",
    "x_axis = Ibar['Insurance']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Insurance\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")\n",
    "\n",
    "# Save Plot\n",
    "plt.savefig('../04._Output/Ibar_no_others.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&gt;160000</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&gt;160000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         >160000  python\n",
       ">160000      1.0     0.0\n",
       "python       0.0     1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cram = df1.loc[:,['>160000', \\\n",
    "                     'python']]\n",
    "df_cram\n",
    "# , \n",
    "def cramers_V(var1,var2):\n",
    "  # Cross table building\n",
    "  crosstab =np.array(pd.crosstab(var1,var2, rownames=None, colnames=None)) \n",
    "  # Keeping of the test statistic of the Chi2 test\n",
    "  stat = chi2_contingency(crosstab)[0] \n",
    "  obs = np.sum(crosstab) # Number of observations\n",
    "  # Take the minimum value between the columns and the rows of the cross table\n",
    "  mini = min(crosstab.shape)-1 \n",
    "  return (stat/(obs*mini))\n",
    "\n",
    "rows= []\n",
    "\n",
    "for var1 in df_cram:\n",
    "  col = []\n",
    "  for var2 in df_cram :\n",
    "    cramers =cramers_V(df_cram[var1], df_cram[var2]) # Cramer's V test\n",
    "    col.append(round(cramers,2)) # Keeping of the rounded value of the Cramer's V  \n",
    "  rows.append(col)\n",
    "  \n",
    "cramers_results = np.array(rows)\n",
    "df_cram_sum = pd.DataFrame(cramers_results, columns = df_cram.columns, index =df_cram.columns)\n",
    "df_cram_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;80000</th>\n",
       "      <th>80000-99999</th>\n",
       "      <th>100000-119999</th>\n",
       "      <th>120000-139999</th>\n",
       "      <th>140000-159999</th>\n",
       "      <th>&gt;160000</th>\n",
       "      <th>python</th>\n",
       "      <th>sql</th>\n",
       "      <th>machine learning</th>\n",
       "      <th>r</th>\n",
       "      <th>...</th>\n",
       "      <th>java</th>\n",
       "      <th>tableau</th>\n",
       "      <th>datamining</th>\n",
       "      <th>hive</th>\n",
       "      <th>sas</th>\n",
       "      <th>bigdata</th>\n",
       "      <th>aws</th>\n",
       "      <th>scala</th>\n",
       "      <th>nosql</th>\n",
       "      <th>c/c++</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;80000</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80000-99999</th>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000-119999</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120000-139999</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140000-159999</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;160000</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sql</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine learning</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hadoop</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spark</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>java</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tableau</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datamining</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hive</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sas</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigdata</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aws</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scala</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosql</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c/c++</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  <80000  80000-99999  100000-119999  120000-139999  \\\n",
       "<80000              1.00         0.03           0.05           0.04   \n",
       "80000-99999         0.03         1.00           0.06           0.06   \n",
       "100000-119999       0.05         0.06           1.00           0.10   \n",
       "120000-139999       0.04         0.06           0.10           1.00   \n",
       "140000-159999       0.03         0.04           0.06           0.06   \n",
       ">160000             0.01         0.02           0.03           0.02   \n",
       "python              0.09         0.02           0.00           0.03   \n",
       "sql                 0.00         0.01           0.00           0.00   \n",
       "machine learning    0.06         0.03           0.00           0.02   \n",
       "r                   0.02         0.00           0.01           0.01   \n",
       "hadoop              0.06         0.04           0.00           0.03   \n",
       "spark               0.05         0.04           0.00           0.03   \n",
       "java                0.03         0.02           0.00           0.01   \n",
       "tableau             0.00         0.01           0.00           0.00   \n",
       "datamining          0.00         0.00           0.00           0.00   \n",
       "hive                0.03         0.02           0.00           0.02   \n",
       "sas                 0.00         0.00           0.00           0.00   \n",
       "bigdata             0.02         0.02           0.00           0.02   \n",
       "aws                 0.02         0.01           0.00           0.01   \n",
       "scala               0.02         0.02           0.00           0.01   \n",
       "nosql               0.01         0.01           0.00           0.01   \n",
       "c/c++               0.01         0.00           0.00           0.01   \n",
       "\n",
       "                  140000-159999  >160000  python   sql  machine learning  \\\n",
       "<80000                     0.03     0.01    0.09  0.00              0.06   \n",
       "80000-99999                0.04     0.02    0.02  0.01              0.03   \n",
       "100000-119999              0.06     0.03    0.00  0.00              0.00   \n",
       "120000-139999              0.06     0.02    0.03  0.00              0.02   \n",
       "140000-159999              1.00     0.01    0.02  0.01              0.03   \n",
       ">160000                    0.01     1.00    0.00  0.01              0.01   \n",
       "python                     0.02     0.00    1.00  0.02              0.10   \n",
       "sql                        0.01     0.01    0.02  1.00              0.02   \n",
       "machine learning           0.03     0.01    0.10  0.02              1.00   \n",
       "r                          0.00     0.00    0.19  0.01              0.09   \n",
       "hadoop                     0.03     0.01    0.05  0.02              0.02   \n",
       "spark                      0.03     0.01    0.07  0.01              0.02   \n",
       "java                       0.02     0.00    0.07  0.01              0.01   \n",
       "tableau                    0.00     0.01    0.00  0.03              0.01   \n",
       "datamining                 0.00     0.00    0.00  0.00              0.04   \n",
       "hive                       0.01     0.00    0.03  0.03              0.00   \n",
       "sas                        0.00     0.00    0.00  0.01              0.00   \n",
       "bigdata                    0.01     0.00    0.01  0.01              0.01   \n",
       "aws                        0.01     0.00    0.04  0.01              0.00   \n",
       "scala                      0.02     0.00    0.03  0.01              0.00   \n",
       "nosql                      0.00     0.00    0.01  0.07              0.00   \n",
       "c/c++                      0.00     0.00    0.03  0.00              0.04   \n",
       "\n",
       "                     r  ...  java  tableau  datamining  hive   sas  bigdata  \\\n",
       "<80000            0.02  ...  0.03     0.00        0.00  0.03  0.00     0.02   \n",
       "80000-99999       0.00  ...  0.02     0.01        0.00  0.02  0.00     0.02   \n",
       "100000-119999     0.01  ...  0.00     0.00        0.00  0.00  0.00     0.00   \n",
       "120000-139999     0.01  ...  0.01     0.00        0.00  0.02  0.00     0.02   \n",
       "140000-159999     0.00  ...  0.02     0.00        0.00  0.01  0.00     0.01   \n",
       ">160000           0.00  ...  0.00     0.01        0.00  0.00  0.00     0.00   \n",
       "python            0.19  ...  0.07     0.00        0.00  0.03  0.00     0.01   \n",
       "sql               0.01  ...  0.01     0.03        0.00  0.03  0.01     0.01   \n",
       "machine learning  0.09  ...  0.01     0.01        0.04  0.00  0.00     0.01   \n",
       "r                 1.00  ...  0.00     0.02        0.04  0.01  0.12     0.00   \n",
       "hadoop            0.01  ...  0.10     0.00        0.00  0.26  0.00     0.16   \n",
       "spark             0.00  ...  0.08     0.01        0.00  0.16  0.01     0.13   \n",
       "java              0.00  ...  1.00     0.00        0.00  0.04  0.01     0.03   \n",
       "tableau           0.02  ...  0.00     1.00        0.00  0.00  0.02     0.00   \n",
       "datamining        0.04  ...  0.00     0.00        1.00  0.00  0.04     0.00   \n",
       "hive              0.01  ...  0.04     0.00        0.00  1.00  0.00     0.09   \n",
       "sas               0.12  ...  0.01     0.02        0.04  0.00  1.00     0.00   \n",
       "bigdata           0.00  ...  0.03     0.00        0.00  0.09  0.00     1.00   \n",
       "aws               0.01  ...  0.03     0.00        0.01  0.01  0.01     0.02   \n",
       "scala             0.00  ...  0.18     0.00        0.00  0.08  0.01     0.06   \n",
       "nosql             0.00  ...  0.06     0.00        0.00  0.02  0.01     0.04   \n",
       "c/c++             0.01  ...  0.14     0.00        0.01  0.00  0.00     0.00   \n",
       "\n",
       "                   aws  scala  nosql  c/c++  \n",
       "<80000            0.02   0.02   0.01   0.01  \n",
       "80000-99999       0.01   0.02   0.01   0.00  \n",
       "100000-119999     0.00   0.00   0.00   0.00  \n",
       "120000-139999     0.01   0.01   0.01   0.01  \n",
       "140000-159999     0.01   0.02   0.00   0.00  \n",
       ">160000           0.00   0.00   0.00   0.00  \n",
       "python            0.04   0.03   0.01   0.03  \n",
       "sql               0.01   0.01   0.07   0.00  \n",
       "machine learning  0.00   0.00   0.00   0.04  \n",
       "r                 0.01   0.00   0.00   0.01  \n",
       "hadoop            0.04   0.14   0.09   0.01  \n",
       "spark             0.10   0.22   0.08   0.01  \n",
       "java              0.03   0.18   0.06   0.14  \n",
       "tableau           0.00   0.00   0.00   0.00  \n",
       "datamining        0.01   0.00   0.00   0.01  \n",
       "hive              0.01   0.08   0.02   0.00  \n",
       "sas               0.01   0.01   0.01   0.00  \n",
       "bigdata           0.02   0.06   0.04   0.00  \n",
       "aws               1.00   0.06   0.05   0.00  \n",
       "scala             0.06   1.00   0.07   0.02  \n",
       "nosql             0.05   0.07   1.00   0.01  \n",
       "c/c++             0.00   0.02   0.01   1.00  \n",
       "\n",
       "[22 rows x 22 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cram_1 = df1.loc[:,['<80000', '80000-99999','100000-119999',\\\n",
    "                     '120000-139999','140000-159999','>160000', \\\n",
    "                     'python', 'sql', 'machine learning', 'r', \\\n",
    "                      'hadoop', 'spark', 'java', 'tableau', \\\n",
    "                       'datamining', 'hive', 'sas', 'bigdata',\\\n",
    "                       'aws', 'scala', 'nosql', 'c/c++'\n",
    "                      ]]\n",
    "df_cram_1\n",
    "\n",
    "def cramers_V(var1,var2):\n",
    "  # Cross table building\n",
    "  crosstab =np.array(pd.crosstab(var1,var2, rownames=None, colnames=None)) \n",
    "  # Keeping of the test statistic of the Chi2 test\n",
    "  stat = chi2_contingency(crosstab)[0] \n",
    "  obs = np.sum(crosstab) # Number of observations\n",
    "  # Take the minimum value between the columns and the rows of the cross table\n",
    "  mini = min(crosstab.shape)-1 \n",
    "  return (stat/(obs*mini))\n",
    "\n",
    "rows= []\n",
    "\n",
    "for var1 in df_cram_1:\n",
    "  col = []\n",
    "  for var2 in df_cram_1 :\n",
    "    cramers =cramers_V(df_cram_1[var1], df_cram_1[var2]) # Cramer's V test\n",
    "    col.append(round(cramers,2)) # Keeping of the rounded value of the Cramer's V  \n",
    "  rows.append(col)\n",
    "  \n",
    "cramers_results_1 = np.array(rows)\n",
    "df_cram_sum_1 = pd.DataFrame(cramers_results_1, columns = df_cram_1.columns, \\\n",
    "                           index =df_cram_1.columns)\n",
    "df_cram_sum_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(df_cram_sum_1, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "  ax = sns.heatmap(df_cram_sum_1, mask=mask,vmin=0., vmax=1, square=True)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Regressions\n",
    "def lin_reg_plot(x_values,y_values, text_coordinates):\n",
    "    (slope, intercept, rvalue, pvalue, stderr) = linregress(x_values, y_values)\n",
    "    regress_values = x_values * slope + intercept  \n",
    "    line_eq = 'y = ' + str(round(slope,2)) + 'x + ' + str(round(intercept,2))\n",
    "\n",
    "    # New Scatter plot with regression line\n",
    "    plt.scatter(x_values,y_values,edgecolors='black')\n",
    "    plt.plot(x_values,regress_values,'r-')\n",
    "    plt.annotate(line_eq,text_coordinates,fontsize=14,color=\"red\")\n",
    "    \n",
    "    # Add R-squared annotation\n",
    "    print(f'The r-squared is: {rvalue}')\n",
    "    print(line_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r-squared is: 0.042078194975562665\n",
      "y = 0.02x + 0.06\n"
     ]
    }
   ],
   "source": [
    "x_values = df_cram_1['python']\n",
    "y_values = df_cram_1['>160000']\n",
    "\n",
    "lin_reg_plot(x_values,y_values, (.2, .2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                >160000   R-squared (uncentered):                   0.110\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.102\n",
      "Method:                 Least Squares   F-statistic:                              13.23\n",
      "Date:                Fri, 14 Aug 2020   Prob (F-statistic):                   1.55e-102\n",
      "Time:                        11:49:47   Log-Likelihood:                         -336.28\n",
      "No. Observations:                5483   AIC:                                      774.6\n",
      "Df Residuals:                    5432   BIC:                                      1112.\n",
      "Df Model:                          51                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "====================================================================================================\n",
      "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Consulting and Business Services     0.0818      0.011      7.514      0.000       0.060       0.103\n",
      "python                               0.0237      0.009      2.642      0.008       0.006       0.041\n",
      "sql                                  0.0156      0.008      1.980      0.048       0.000       0.031\n",
      "machine learning                     0.0546      0.009      6.399      0.000       0.038       0.071\n",
      "r                                   -0.0151      0.009     -1.637      0.102      -0.033       0.003\n",
      "hadoop                               0.0390      0.011      3.671      0.000       0.018       0.060\n",
      "spark                                0.0276      0.011      2.553      0.011       0.006       0.049\n",
      "java                                -0.0010      0.011     -0.091      0.927      -0.022       0.020\n",
      "tableau                             -0.0199      0.009     -2.201      0.028      -0.038      -0.002\n",
      "datamining                          -0.0286      0.009     -3.017      0.003      -0.047      -0.010\n",
      "hive                                -0.0029      0.012     -0.238      0.812      -0.027       0.021\n",
      "sas                                  0.0169      0.011      1.515      0.130      -0.005       0.039\n",
      "bigdata                             -0.0178      0.011     -1.665      0.096      -0.039       0.003\n",
      "aws                                  0.0536      0.012      4.632      0.000       0.031       0.076\n",
      "scala                                0.0205      0.012      1.653      0.098      -0.004       0.045\n",
      "nosql                               -0.0079      0.013     -0.594      0.553      -0.034       0.018\n",
      "c/c++                                0.0302      0.013      2.298      0.022       0.004       0.056\n",
      "naturallanguageprocessing            0.0012      0.013      0.097      0.923      -0.024       0.026\n",
      "oracle                              -0.0063      0.013     -0.485      0.628      -0.032       0.019\n",
      "datawarehouse                       -0.0079      0.013     -0.633      0.527      -0.033       0.017\n",
      "linux                               -0.0424      0.014     -3.023      0.003      -0.070      -0.015\n",
      "ai                                   0.0032      0.013      0.237      0.813      -0.023       0.029\n",
      "microsoftsqlserver                  -0.0141      0.014     -1.023      0.306      -0.041       0.013\n",
      "tensorflow                           0.0271      0.014      1.955      0.051   -7.73e-05       0.054\n",
      "kafka                                0.0524      0.015      3.540      0.000       0.023       0.081\n",
      "dataanalysis                        -0.0008      0.013     -0.063      0.950      -0.026       0.025\n",
      "azure                               -0.0670      0.015     -4.574      0.000      -0.096      -0.038\n",
      "matlab                               0.0185      0.015      1.272      0.203      -0.010       0.047\n",
      "microsoftoffice                     -0.0172      0.015     -1.152      0.249      -0.047       0.012\n",
      "scripting                           -0.0199      0.017     -1.167      0.243      -0.053       0.013\n",
      "pig                                 -0.0579      0.017     -3.354      0.001      -0.092      -0.024\n",
      "git                                 -0.0338      0.015     -2.272      0.023      -0.063      -0.005\n",
      "microsoftpowerpoint                  0.0177      0.016      1.104      0.270      -0.014       0.049\n",
      "excel                               -0.0085      0.015     -0.557      0.578      -0.038       0.021\n",
      "designexperience                    -0.0139      0.016     -0.873      0.383      -0.045       0.017\n",
      "javascript                           0.0003      0.017      0.018      0.986      -0.033       0.034\n",
      "hbase                                0.0204      0.018      1.126      0.260      -0.015       0.056\n",
      "cassandra                           -0.0185      0.019     -0.954      0.340      -0.057       0.020\n",
      "postgresql                           0.0079      0.018      0.441      0.659      -0.027       0.043\n",
      "mysql                                0.0037      0.017      0.212      0.832      -0.031       0.038\n",
      "perl                                 0.0127      0.017      0.727      0.467      -0.021       0.047\n",
      "spss                                -0.0242      0.018     -1.352      0.176      -0.059       0.011\n",
      "softwaredevelopment                  0.0380      0.017      2.282      0.023       0.005       0.071\n",
      "shellscripting                       0.0357      0.023      1.531      0.126      -0.010       0.081\n",
      "datascience                         -0.0043      0.017     -0.251      0.802      -0.038       0.030\n",
      "docker                              -0.0862      0.019     -4.642      0.000      -0.123      -0.050\n",
      "mongodb                             -0.0252      0.020     -1.283      0.199      -0.064       0.013\n",
      ".net                                -0.0222      0.019     -1.160      0.246      -0.060       0.015\n",
      "projectmanagement                    0.0195      0.018      1.090      0.276      -0.016       0.055\n",
      "businessintelligence                 0.0231      0.019      1.205      0.228      -0.015       0.061\n",
      "s3                                  -0.0343      0.020     -1.685      0.092      -0.074       0.006\n",
      "==============================================================================\n",
      "Omnibus:                     3235.629   Durbin-Watson:                   0.114\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            20751.096\n",
      "Skew:                           2.931   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.514   Cond. No.                         11.8\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X = df1[[\n",
    "    'Consulting and Business Services', \\\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'r', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'java', \\\n",
    "    'tableau', \\\n",
    "    'datamining', \\\n",
    "    'hive', 'sas', \\\n",
    "    'bigdata',\\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'nosql',  \\\n",
    "    'c/c++',  \\\n",
    "    'naturallanguageprocessing', \\\n",
    "    'oracle', \\\n",
    "    'datawarehouse', \\\n",
    "    'linux', \\\n",
    "    'ai', \\\n",
    "    'microsoftsqlserver', \\\n",
    "    'tensorflow', \\\n",
    "    'kafka', \\\n",
    "    'dataanalysis', \\\n",
    "    'azure', \\\n",
    "    'matlab', \\\n",
    "    'microsoftoffice', \\\n",
    "    'scripting', \\\n",
    "    'pig', \\\n",
    "    'git', \\\n",
    "    'microsoftpowerpoint', \\\n",
    "    'excel', \\\n",
    "    'designexperience', \\\n",
    "    'javascript', \\\n",
    "    'hbase', \\\n",
    "    'cassandra', \\\n",
    "    'postgresql', \\\n",
    "    'mysql', \\\n",
    "    'perl', \\\n",
    "    'spss', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'shellscripting', \\\n",
    "    'datascience', \\\n",
    "    'docker', \\\n",
    "    'mongodb', \\\n",
    "    '.net', \\\n",
    "    'projectmanagement', \\\n",
    "    'businessintelligence', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['>160000']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "# X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                >160000   R-squared (uncentered):                   0.107\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.103\n",
      "Method:                 Least Squares   F-statistic:                              31.06\n",
      "Date:                Fri, 14 Aug 2020   Prob (F-statistic):                   3.77e-117\n",
      "Time:                        11:49:47   Log-Likelihood:                         -347.96\n",
      "No. Observations:                5483   AIC:                                      737.9\n",
      "Df Residuals:                    5462   BIC:                                      876.7\n",
      "Df Model:                          21                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "====================================================================================================\n",
      "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Consulting and Business Services     0.0791      0.011      7.389      0.000       0.058       0.100\n",
      "python                               0.0194      0.008      2.488      0.013       0.004       0.035\n",
      "sql                                  0.0101      0.007      1.526      0.127      -0.003       0.023\n",
      "machine learning                     0.0555      0.008      6.993      0.000       0.040       0.071\n",
      "hadoop                               0.0381      0.010      3.818      0.000       0.019       0.058\n",
      "spark                                0.0273      0.011      2.579      0.010       0.007       0.048\n",
      "tableau                             -0.0202      0.009     -2.340      0.019      -0.037      -0.003\n",
      "datamining                          -0.0287      0.009     -3.147      0.002      -0.047      -0.011\n",
      "bigdata                             -0.0207      0.011     -1.956      0.051      -0.041    5.06e-05\n",
      "aws                                  0.0544      0.011      4.835      0.000       0.032       0.076\n",
      "scala                                0.0180      0.012      1.554      0.120      -0.005       0.041\n",
      "c/c++                                0.0307      0.012      2.558      0.011       0.007       0.054\n",
      "linux                               -0.0390      0.013     -3.022      0.003      -0.064      -0.014\n",
      "tensorflow                           0.0266      0.013      1.980      0.048       0.000       0.053\n",
      "kafka                                0.0497      0.014      3.499      0.000       0.022       0.077\n",
      "azure                               -0.0745      0.014     -5.260      0.000      -0.102      -0.047\n",
      "pig                                 -0.0570      0.015     -3.710      0.000      -0.087      -0.027\n",
      "git                                 -0.0330      0.015     -2.239      0.025      -0.062      -0.004\n",
      "softwaredevelopment                  0.0368      0.016      2.251      0.024       0.005       0.069\n",
      "docker                              -0.0892      0.018     -4.885      0.000      -0.125      -0.053\n",
      "s3                                  -0.0311      0.020     -1.552      0.121      -0.070       0.008\n",
      "==============================================================================\n",
      "Omnibus:                     3255.896   Durbin-Watson:                   0.106\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            21085.020\n",
      "Skew:                           2.951   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.580   Cond. No.                         7.89\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# '>160000', 'Consulting and Business Services' - Short\n",
    "X = df1[[\n",
    "    'Consulting and Business Services', \\\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'tableau', \\\n",
    "    'datamining', \\\n",
    "    'bigdata',\\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'c/c++',  \\\n",
    "    'linux', \\\n",
    "    'tensorflow', \\\n",
    "    'kafka', \\\n",
    "    'azure', \\\n",
    "    'pig', \\\n",
    "    'git', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'docker', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['>160000']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "# X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:       Sal_Ind_Cat4-5-6   R-squared (uncentered):                   0.612\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.610\n",
      "Method:                 Least Squares   F-statistic:                              331.5\n",
      "Date:                Fri, 14 Aug 2020   Prob (F-statistic):                        0.00\n",
      "Time:                        11:49:47   Log-Likelihood:                         -3074.7\n",
      "No. Observations:                5483   AIC:                                      6201.\n",
      "Df Residuals:                    5457   BIC:                                      6373.\n",
      "Df Model:                          26                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "====================================================================================================\n",
      "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "CA                                   0.3380      0.014     24.410      0.000       0.311       0.365\n",
      "NY                                   0.2651      0.019     13.930      0.000       0.228       0.302\n",
      "MA                                   0.1868      0.028      6.698      0.000       0.132       0.241\n",
      "VA                                   0.1718      0.025      6.827      0.000       0.122       0.221\n",
      "DC                                   0.1328      0.038      3.521      0.000       0.059       0.207\n",
      "Consulting and Business Services     0.0681      0.018      3.799      0.000       0.033       0.103\n",
      "python                               0.1615      0.013     12.373      0.000       0.136       0.187\n",
      "sql                                 -0.0166      0.011     -1.493      0.136      -0.038       0.005\n",
      "machine learning                     0.2028      0.013     15.317      0.000       0.177       0.229\n",
      "hadoop                               0.1769      0.016     10.757      0.000       0.145       0.209\n",
      "spark                                0.0871      0.017      4.989      0.000       0.053       0.121\n",
      "tableau                             -0.0727      0.014     -5.103      0.000      -0.101      -0.045\n",
      "datamining                          -0.0215      0.015     -1.432      0.152      -0.051       0.008\n",
      "bigdata                              0.0572      0.017      3.283      0.001       0.023       0.091\n",
      "aws                                  0.0927      0.019      5.003      0.000       0.056       0.129\n",
      "scala                                0.1157      0.019      6.065      0.000       0.078       0.153\n",
      "c/c++                                0.0490      0.020      2.477      0.013       0.010       0.088\n",
      "linux                               -0.0203      0.021     -0.957      0.338      -0.062       0.021\n",
      "tensorflow                          -0.0081      0.022     -0.365      0.715      -0.052       0.035\n",
      "kafka                                0.0177      0.023      0.758      0.448      -0.028       0.064\n",
      "azure                               -0.0419      0.024     -1.784      0.074      -0.088       0.004\n",
      "pig                                  0.0548      0.025      2.166      0.030       0.005       0.104\n",
      "git                                 -0.0325      0.024     -1.340      0.180      -0.080       0.015\n",
      "softwaredevelopment                  0.0438      0.027      1.625      0.104      -0.009       0.097\n",
      "docker                               0.1727      0.030      5.695      0.000       0.113       0.232\n",
      "s3                                   0.1540      0.033      4.668      0.000       0.089       0.219\n",
      "==============================================================================\n",
      "Omnibus:                      131.258   Durbin-Watson:                   0.588\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               70.257\n",
      "Skew:                           0.071   Prob(JB):                     5.54e-16\n",
      "Kurtosis:                       2.464   Cond. No.                         9.07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# 'Sal_Ind_Cat4-5-6', 'Consulting and Business Services' - Short\n",
    "X = df1[[\n",
    "    'CA', \\\n",
    "    'NY', \\\n",
    "    'MA', \\\n",
    "    'VA', \\\n",
    "    'DC', \\\n",
    "    'Consulting and Business Services', \\\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'tableau', \\\n",
    "    'datamining', \\\n",
    "    'bigdata',\\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'c/c++',  \\\n",
    "    'linux', \\\n",
    "    'tensorflow', \\\n",
    "    'kafka', \\\n",
    "    'azure', \\\n",
    "    'pig', \\\n",
    "    'git', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'docker', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['Sal_Ind_Cat4-5-6']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "# X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                >160000   R-squared (uncentered):                   0.057\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.056\n",
      "Method:                 Least Squares   F-statistic:                              328.6\n",
      "Date:                Fri, 14 Aug 2020   Prob (F-statistic):                    2.22e-71\n",
      "Time:                        11:49:47   Log-Likelihood:                         -497.62\n",
      "No. Observations:                5483   AIC:                                      997.2\n",
      "Df Residuals:                    5482   BIC:                                      1004.\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "python         0.0833      0.005     18.129      0.000       0.074       0.092\n",
      "==============================================================================\n",
      "Omnibus:                     3431.267   Durbin-Watson:                   0.050\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            23963.659\n",
      "Skew:                           3.128   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.108   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# 'Sal_Ind_Cat4-5-6', 'Consulting and Business Services' - Short\n",
    "X = df1[[\n",
    "    'python'\n",
    "       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['>160000']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "# X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:       Sal_Ind_Cat4-5-6   R-squared (uncentered):                   0.572\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.570\n",
      "Method:                 Least Squares   F-statistic:                              291.5\n",
      "Date:                Fri, 14 Aug 2020   Prob (F-statistic):                        0.00\n",
      "Time:                        11:49:47   Log-Likelihood:                         -3347.8\n",
      "No. Observations:                5483   AIC:                                      6746.\n",
      "Df Residuals:                    5458   BIC:                                      6911.\n",
      "Df Model:                          25                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "====================================================================================================\n",
      "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Consulting and Business Services     0.1245      0.019      6.630      0.000       0.088       0.161\n",
      "Internet and Software                0.1915      0.019      9.860      0.000       0.153       0.230\n",
      "Banks and Financial Services         0.1156      0.022      5.224      0.000       0.072       0.159\n",
      "Health Care                         -0.0022      0.026     -0.085      0.932      -0.054       0.049\n",
      "Insurance                            0.0716      0.032      2.259      0.024       0.009       0.134\n",
      "python                               0.2044      0.014     15.030      0.000       0.178       0.231\n",
      "sql                                  0.0264      0.012      2.255      0.024       0.003       0.049\n",
      "machine learning                     0.2481      0.014     18.021      0.000       0.221       0.275\n",
      "hadoop                               0.1736      0.017     10.008      0.000       0.140       0.208\n",
      "spark                                0.1034      0.018      5.611      0.000       0.067       0.140\n",
      "tableau                             -0.0547      0.015     -3.657      0.000      -0.084      -0.025\n",
      "datamining                          -0.0265      0.016     -1.680      0.093      -0.058       0.004\n",
      "bigdata                              0.0289      0.018      1.577      0.115      -0.007       0.065\n",
      "aws                                  0.1206      0.020      6.184      0.000       0.082       0.159\n",
      "scala                                0.1149      0.020      5.726      0.000       0.076       0.154\n",
      "c/c++                                0.0671      0.021      3.223      0.001       0.026       0.108\n",
      "linux                               -0.0394      0.022     -1.769      0.077      -0.083       0.004\n",
      "tensorflow                           0.0055      0.023      0.235      0.814      -0.040       0.051\n",
      "kafka                                0.0294      0.025      1.197      0.231      -0.019       0.078\n",
      "azure                               -0.1080      0.025     -4.405      0.000      -0.156      -0.060\n",
      "pig                                  0.0545      0.027      2.051      0.040       0.002       0.107\n",
      "git                                 -0.0367      0.026     -1.436      0.151      -0.087       0.013\n",
      "softwaredevelopment                  0.0651      0.028      2.305      0.021       0.010       0.121\n",
      "docker                               0.1502      0.032      4.757      0.000       0.088       0.212\n",
      "s3                                   0.1452      0.035      4.188      0.000       0.077       0.213\n",
      "==============================================================================\n",
      "Omnibus:                      146.998   Durbin-Watson:                   0.530\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               72.902\n",
      "Skew:                          -0.014   Prob(JB):                     1.48e-16\n",
      "Kurtosis:                       2.436   Cond. No.                         7.94\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# 'Sal_Ind_Cat4-5-6',     \n",
    "# 'Consulting and Business Services', \\\n",
    "# 'Internet and Software', \\\n",
    "#     'Banks and Financial Services', \\\n",
    "#     'Health Care', \\\n",
    "#     'Insurance', \n",
    "# - Short\n",
    "\n",
    "X = df1[[\n",
    "    'Consulting and Business Services', \\\n",
    "    'Internet and Software', \\\n",
    "    'Banks and Financial Services', \\\n",
    "    'Health Care', \\\n",
    "    'Insurance',\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'tableau', \\\n",
    "    'datamining', \\\n",
    "    'bigdata',\\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'c/c++',  \\\n",
    "    'linux', \\\n",
    "    'tensorflow', \\\n",
    "    'kafka', \\\n",
    "    'azure', \\\n",
    "    'pig', \\\n",
    "    'git', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'docker', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['Sal_Ind_Cat4-5-6']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "# X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:       Sal_Ind_Cat4-5-6   R-squared (uncentered):                   0.571\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.570\n",
      "Method:                 Least Squares   F-statistic:                              346.9\n",
      "Date:                Fri, 14 Aug 2020   Prob (F-statistic):                        0.00\n",
      "Time:                        11:49:47   Log-Likelihood:                         -3349.4\n",
      "No. Observations:                5483   AIC:                                      6741.\n",
      "Df Residuals:                    5462   BIC:                                      6880.\n",
      "Df Model:                          21                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "====================================================================================================\n",
      "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Consulting and Business Services     0.1242      0.019      6.635      0.000       0.088       0.161\n",
      "Internet and Software                0.1926      0.019      9.957      0.000       0.155       0.231\n",
      "Banks and Financial Services         0.1156      0.022      5.236      0.000       0.072       0.159\n",
      "Insurance                            0.0708      0.032      2.245      0.025       0.009       0.133\n",
      "python                               0.2033      0.014     14.971      0.000       0.177       0.230\n",
      "sql                                  0.0251      0.012      2.174      0.030       0.002       0.048\n",
      "machine learning                     0.2475      0.013     18.716      0.000       0.222       0.273\n",
      "hadoop                               0.1756      0.017     10.172      0.000       0.142       0.209\n",
      "spark                                0.1067      0.018      5.843      0.000       0.071       0.142\n",
      "tableau                             -0.0539      0.015     -3.615      0.000      -0.083      -0.025\n",
      "datamining                          -0.0267      0.016     -1.703      0.089      -0.058       0.004\n",
      "bigdata                              0.0310      0.018      1.700      0.089      -0.005       0.067\n",
      "aws                                  0.1204      0.019      6.194      0.000       0.082       0.158\n",
      "scala                                0.1195      0.020      6.086      0.000       0.081       0.158\n",
      "c/c++                                0.0667      0.021      3.215      0.001       0.026       0.107\n",
      "linux                               -0.0438      0.022     -1.996      0.046      -0.087      -0.001\n",
      "azure                               -0.1103      0.024     -4.509      0.000      -0.158      -0.062\n",
      "pig                                  0.0547      0.027      2.059      0.039       0.003       0.107\n",
      "softwaredevelopment                  0.0639      0.028      2.265      0.024       0.009       0.119\n",
      "docker                               0.1489      0.031      4.762      0.000       0.088       0.210\n",
      "s3                                   0.1453      0.035      4.195      0.000       0.077       0.213\n",
      "==============================================================================\n",
      "Omnibus:                      146.243   Durbin-Watson:                   0.529\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               72.659\n",
      "Skew:                          -0.015   Prob(JB):                     1.67e-16\n",
      "Kurtosis:                       2.437   Cond. No.                         7.87\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# 'Sal_Ind_Cat4-5-6',     \n",
    "# 'Consulting and Business Services', \\\n",
    "# 'Internet and Software', \\\n",
    "#     'Banks and Financial Services', \\\n",
    "#     'Health Care', \\\n",
    "#     'Insurance', \n",
    "# - Short\n",
    "\n",
    "X = df1[[\n",
    "    'Consulting and Business Services', \\\n",
    "    'Internet and Software', \\\n",
    "    'Banks and Financial Services', \\\n",
    "    'Insurance',\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'tableau', \\\n",
    "    'datamining', \\\n",
    "    'bigdata',\\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'c/c++',  \\\n",
    "    'linux', \\\n",
    "    'azure', \\\n",
    "    'pig', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'docker', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['Sal_Ind_Cat4-5-6']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "# X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:       Sal_Ind_Cat4-5-6   R-squared (uncentered):                   0.581\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.577\n",
      "Method:                 Least Squares   F-statistic:                              136.9\n",
      "Date:                Fri, 14 Aug 2020   Prob (F-statistic):                        0.00\n",
      "Time:                        11:49:47   Log-Likelihood:                         -3287.1\n",
      "No. Observations:                5483   AIC:                                      6684.\n",
      "Df Residuals:                    5428   BIC:                                      7048.\n",
      "Df Model:                          55                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "====================================================================================================\n",
      "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Consulting and Business Services     0.1234      0.019      6.502      0.000       0.086       0.161\n",
      "Internet and Software                0.1863      0.020      9.527      0.000       0.148       0.225\n",
      "Banks and Financial Services         0.0961      0.022      4.274      0.000       0.052       0.140\n",
      "Health Care                         -0.0069      0.027     -0.258      0.797      -0.059       0.045\n",
      "Insurance                            0.0840      0.032      2.643      0.008       0.022       0.146\n",
      "python                               0.2016      0.015     13.064      0.000       0.171       0.232\n",
      "sql                                  0.0290      0.014      2.115      0.034       0.002       0.056\n",
      "machine learning                     0.2307      0.015     15.722      0.000       0.202       0.259\n",
      "r                                   -0.0368      0.016     -2.330      0.020      -0.068      -0.006\n",
      "hadoop                               0.1538      0.018      8.431      0.000       0.118       0.190\n",
      "spark                                0.1074      0.019      5.762      0.000       0.071       0.144\n",
      "java                                 0.0251      0.018      1.365      0.172      -0.011       0.061\n",
      "tableau                             -0.0422      0.015     -2.727      0.006      -0.073      -0.012\n",
      "datamining                          -0.0277      0.016     -1.708      0.088      -0.060       0.004\n",
      "hive                                 0.0016      0.021      0.074      0.941      -0.040       0.043\n",
      "sas                                  0.0015      0.019      0.076      0.939      -0.036       0.039\n",
      "bigdata                              0.0320      0.018      1.741      0.082      -0.004       0.068\n",
      "aws                                  0.1090      0.020      5.483      0.000       0.070       0.148\n",
      "scala                                0.0988      0.021      4.644      0.000       0.057       0.140\n",
      "nosql                               -0.0082      0.023     -0.361      0.718      -0.053       0.036\n",
      "c/c++                                0.0197      0.023      0.871      0.384      -0.025       0.064\n",
      "naturallanguageprocessing            0.0806      0.022      3.656      0.000       0.037       0.124\n",
      "oracle                               0.0117      0.022      0.521      0.602      -0.032       0.056\n",
      "datawarehouse                        0.0604      0.022      2.802      0.005       0.018       0.103\n",
      "linux                               -0.0446      0.024     -1.855      0.064      -0.092       0.003\n",
      "ai                                   0.0370      0.023      1.608      0.108      -0.008       0.082\n",
      "microsoftsqlserver                  -0.0500      0.024     -2.116      0.034      -0.096      -0.004\n",
      "tensorflow                          -0.0056      0.024     -0.234      0.815      -0.052       0.041\n",
      "kafka                                0.0295      0.025      1.159      0.247      -0.020       0.079\n",
      "dataanalysis                         0.0238      0.022      1.070      0.285      -0.020       0.067\n",
      "azure                               -0.1280      0.025     -5.098      0.000      -0.177      -0.079\n",
      "matlab                               0.1308      0.025      5.243      0.000       0.082       0.180\n",
      "microsoftoffice                     -0.0727      0.026     -2.831      0.005      -0.123      -0.022\n",
      "scripting                           -0.0082      0.029     -0.282      0.778      -0.066       0.049\n",
      "pig                                  0.0246      0.030      0.829      0.407      -0.034       0.083\n",
      "git                                 -0.0391      0.026     -1.526      0.127      -0.089       0.011\n",
      "microsoftpowerpoint                  0.0061      0.028      0.221      0.825      -0.048       0.060\n",
      "excel                               -0.0363      0.026     -1.391      0.164      -0.088       0.015\n",
      "designexperience                     0.1210      0.027      4.424      0.000       0.067       0.175\n",
      "javascript                           0.0150      0.029      0.511      0.609      -0.042       0.072\n",
      "hbase                                0.0176      0.031      0.568      0.570      -0.043       0.078\n",
      "cassandra                            0.0099      0.033      0.297      0.767      -0.055       0.075\n",
      "postgresql                           0.0133      0.031      0.435      0.663      -0.047       0.073\n",
      "mysql                                0.0502      0.030      1.671      0.095      -0.009       0.109\n",
      "perl                                 0.0487      0.030      1.628      0.104      -0.010       0.107\n",
      "spss                                -0.0152      0.031     -0.493      0.622      -0.076       0.045\n",
      "softwaredevelopment                  0.0485      0.029      1.701      0.089      -0.007       0.104\n",
      "shellscripting                      -0.0038      0.040     -0.095      0.924      -0.082       0.075\n",
      "datascience                          0.0045      0.030      0.150      0.880      -0.054       0.062\n",
      "docker                               0.1362      0.032      4.276      0.000       0.074       0.199\n",
      "mongodb                             -0.0650      0.034     -1.932      0.053      -0.131       0.001\n",
      ".net                                 0.0360      0.033      1.097      0.273      -0.028       0.100\n",
      "projectmanagement                    0.0903      0.031      2.938      0.003       0.030       0.151\n",
      "businessintelligence                 0.0180      0.033      0.545      0.586      -0.047       0.083\n",
      "s3                                   0.1453      0.035      4.161      0.000       0.077       0.214\n",
      "==============================================================================\n",
      "Omnibus:                      130.611   Durbin-Watson:                   0.542\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               68.003\n",
      "Skew:                          -0.040   Prob(JB):                     1.71e-15\n",
      "Kurtosis:                       2.460   Cond. No.                         11.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# 'Sal_Ind_Cat4-5-6',     \n",
    "# 'Consulting and Business Services', \\\n",
    "# 'Internet and Software', \\\n",
    "#     'Banks and Financial Services', \\\n",
    "#     'Health Care', \\\n",
    "#     'Insurance', \n",
    "# - Long\n",
    "\n",
    "X = df1[[\n",
    "    'Consulting and Business Services', \\\n",
    "    'Internet and Software', \\\n",
    "    'Banks and Financial Services', \\\n",
    "    'Health Care', \\\n",
    "    'Insurance',\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'r', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'java', \\\n",
    "    'tableau', \\\n",
    "    'datamining', \\\n",
    "    'hive', 'sas', \\\n",
    "    'bigdata',\\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'nosql',  \\\n",
    "    'c/c++',  \\\n",
    "    'naturallanguageprocessing', \\\n",
    "    'oracle', \\\n",
    "    'datawarehouse', \\\n",
    "    'linux', \\\n",
    "    'ai', \\\n",
    "    'microsoftsqlserver', \\\n",
    "    'tensorflow', \\\n",
    "    'kafka', \\\n",
    "    'dataanalysis', \\\n",
    "    'azure', \\\n",
    "    'matlab', \\\n",
    "    'microsoftoffice', \\\n",
    "    'scripting', \\\n",
    "    'pig', \\\n",
    "    'git', \\\n",
    "    'microsoftpowerpoint', \\\n",
    "    'excel', \\\n",
    "    'designexperience', \\\n",
    "    'javascript', \\\n",
    "    'hbase', \\\n",
    "    'cassandra', \\\n",
    "    'postgresql', \\\n",
    "    'mysql', \\\n",
    "    'perl', \\\n",
    "    'spss', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'shellscripting', \\\n",
    "    'datascience', \\\n",
    "    'docker', \\\n",
    "    'mongodb', \\\n",
    "    '.net', \\\n",
    "    'projectmanagement', \\\n",
    "    'businessintelligence', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['Sal_Ind_Cat4-5-6']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "# X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:       Sal_Ind_Cat4-5-6   R-squared (uncentered):                   0.581\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.577\n",
      "Method:                 Least Squares   F-statistic:                              136.9\n",
      "Date:                Fri, 14 Aug 2020   Prob (F-statistic):                        0.00\n",
      "Time:                        11:49:47   Log-Likelihood:                         -3287.1\n",
      "No. Observations:                5483   AIC:                                      6684.\n",
      "Df Residuals:                    5428   BIC:                                      7048.\n",
      "Df Model:                          55                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "====================================================================================================\n",
      "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Consulting and Business Services     0.1234      0.019      6.502      0.000       0.086       0.161\n",
      "Internet and Software                0.1863      0.020      9.527      0.000       0.148       0.225\n",
      "Banks and Financial Services         0.0961      0.022      4.274      0.000       0.052       0.140\n",
      "Health Care                         -0.0069      0.027     -0.258      0.797      -0.059       0.045\n",
      "Insurance                            0.0840      0.032      2.643      0.008       0.022       0.146\n",
      "python                               0.2016      0.015     13.064      0.000       0.171       0.232\n",
      "sql                                  0.0290      0.014      2.115      0.034       0.002       0.056\n",
      "machine learning                     0.2307      0.015     15.722      0.000       0.202       0.259\n",
      "r                                   -0.0368      0.016     -2.330      0.020      -0.068      -0.006\n",
      "hadoop                               0.1538      0.018      8.431      0.000       0.118       0.190\n",
      "spark                                0.1074      0.019      5.762      0.000       0.071       0.144\n",
      "java                                 0.0251      0.018      1.365      0.172      -0.011       0.061\n",
      "tableau                             -0.0422      0.015     -2.727      0.006      -0.073      -0.012\n",
      "datamining                          -0.0277      0.016     -1.708      0.088      -0.060       0.004\n",
      "hive                                 0.0016      0.021      0.074      0.941      -0.040       0.043\n",
      "sas                                  0.0015      0.019      0.076      0.939      -0.036       0.039\n",
      "bigdata                              0.0320      0.018      1.741      0.082      -0.004       0.068\n",
      "aws                                  0.1090      0.020      5.483      0.000       0.070       0.148\n",
      "scala                                0.0988      0.021      4.644      0.000       0.057       0.140\n",
      "nosql                               -0.0082      0.023     -0.361      0.718      -0.053       0.036\n",
      "c/c++                                0.0197      0.023      0.871      0.384      -0.025       0.064\n",
      "naturallanguageprocessing            0.0806      0.022      3.656      0.000       0.037       0.124\n",
      "oracle                               0.0117      0.022      0.521      0.602      -0.032       0.056\n",
      "datawarehouse                        0.0604      0.022      2.802      0.005       0.018       0.103\n",
      "linux                               -0.0446      0.024     -1.855      0.064      -0.092       0.003\n",
      "ai                                   0.0370      0.023      1.608      0.108      -0.008       0.082\n",
      "microsoftsqlserver                  -0.0500      0.024     -2.116      0.034      -0.096      -0.004\n",
      "tensorflow                          -0.0056      0.024     -0.234      0.815      -0.052       0.041\n",
      "kafka                                0.0295      0.025      1.159      0.247      -0.020       0.079\n",
      "dataanalysis                         0.0238      0.022      1.070      0.285      -0.020       0.067\n",
      "azure                               -0.1280      0.025     -5.098      0.000      -0.177      -0.079\n",
      "matlab                               0.1308      0.025      5.243      0.000       0.082       0.180\n",
      "microsoftoffice                     -0.0727      0.026     -2.831      0.005      -0.123      -0.022\n",
      "scripting                           -0.0082      0.029     -0.282      0.778      -0.066       0.049\n",
      "pig                                  0.0246      0.030      0.829      0.407      -0.034       0.083\n",
      "git                                 -0.0391      0.026     -1.526      0.127      -0.089       0.011\n",
      "microsoftpowerpoint                  0.0061      0.028      0.221      0.825      -0.048       0.060\n",
      "excel                               -0.0363      0.026     -1.391      0.164      -0.088       0.015\n",
      "designexperience                     0.1210      0.027      4.424      0.000       0.067       0.175\n",
      "javascript                           0.0150      0.029      0.511      0.609      -0.042       0.072\n",
      "hbase                                0.0176      0.031      0.568      0.570      -0.043       0.078\n",
      "cassandra                            0.0099      0.033      0.297      0.767      -0.055       0.075\n",
      "postgresql                           0.0133      0.031      0.435      0.663      -0.047       0.073\n",
      "mysql                                0.0502      0.030      1.671      0.095      -0.009       0.109\n",
      "perl                                 0.0487      0.030      1.628      0.104      -0.010       0.107\n",
      "spss                                -0.0152      0.031     -0.493      0.622      -0.076       0.045\n",
      "softwaredevelopment                  0.0485      0.029      1.701      0.089      -0.007       0.104\n",
      "shellscripting                      -0.0038      0.040     -0.095      0.924      -0.082       0.075\n",
      "datascience                          0.0045      0.030      0.150      0.880      -0.054       0.062\n",
      "docker                               0.1362      0.032      4.276      0.000       0.074       0.199\n",
      "mongodb                             -0.0650      0.034     -1.932      0.053      -0.131       0.001\n",
      ".net                                 0.0360      0.033      1.097      0.273      -0.028       0.100\n",
      "projectmanagement                    0.0903      0.031      2.938      0.003       0.030       0.151\n",
      "businessintelligence                 0.0180      0.033      0.545      0.586      -0.047       0.083\n",
      "s3                                   0.1453      0.035      4.161      0.000       0.077       0.214\n",
      "==============================================================================\n",
      "Omnibus:                      130.611   Durbin-Watson:                   0.542\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               68.003\n",
      "Skew:                          -0.040   Prob(JB):                     1.71e-15\n",
      "Kurtosis:                       2.460   Cond. No.                         11.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# 'Sal_Ind_Cat4-5-6',     \n",
    "# 'Consulting and Business Services', \\\n",
    "# 'Internet and Software', \\\n",
    "#     'Banks and Financial Services', \\\n",
    "#     'Health Care', \\\n",
    "#     'Insurance', \n",
    "# - Long\n",
    "\n",
    "X = df1[[\n",
    "    'Consulting and Business Services', \\\n",
    "    'Internet and Software', \\\n",
    "    'Banks and Financial Services', \\\n",
    "    'Health Care', \\\n",
    "    'Insurance',\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'r', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'java', \\\n",
    "    'tableau', \\\n",
    "    'datamining', \\\n",
    "    'hive', 'sas', \\\n",
    "    'bigdata',\\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'nosql',  \\\n",
    "    'c/c++',  \\\n",
    "    'naturallanguageprocessing', \\\n",
    "    'oracle', \\\n",
    "    'datawarehouse', \\\n",
    "    'linux', \\\n",
    "    'ai', \\\n",
    "    'microsoftsqlserver', \\\n",
    "    'tensorflow', \\\n",
    "    'kafka', \\\n",
    "    'dataanalysis', \\\n",
    "    'azure', \\\n",
    "    'matlab', \\\n",
    "    'microsoftoffice', \\\n",
    "    'scripting', \\\n",
    "    'pig', \\\n",
    "    'git', \\\n",
    "    'microsoftpowerpoint', \\\n",
    "    'excel', \\\n",
    "    'designexperience', \\\n",
    "    'javascript', \\\n",
    "    'hbase', \\\n",
    "    'cassandra', \\\n",
    "    'postgresql', \\\n",
    "    'mysql', \\\n",
    "    'perl', \\\n",
    "    'spss', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'shellscripting', \\\n",
    "    'datascience', \\\n",
    "    'docker', \\\n",
    "    'mongodb', \\\n",
    "    '.net', \\\n",
    "    'projectmanagement', \\\n",
    "    'businessintelligence', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['Sal_Ind_Cat4-5-6']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "# X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:           Salary_Index   R-squared (uncentered):                   0.807\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.806\n",
      "Method:                 Least Squares   F-statistic:                              670.9\n",
      "Date:                Fri, 14 Aug 2020   Prob (F-statistic):                        0.00\n",
      "Time:                        11:49:48   Log-Likelihood:                         -10368.\n",
      "No. Observations:                5483   AIC:                                  2.080e+04\n",
      "Df Residuals:                    5449   BIC:                                  2.103e+04\n",
      "Df Model:                          34                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "====================================================================================================\n",
      "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Consulting and Business Services     1.0546      0.067     15.854      0.000       0.924       1.185\n",
      "Internet and Software                1.0789      0.070     15.347      0.000       0.941       1.217\n",
      "Banks and Financial Services         0.7918      0.081      9.786      0.000       0.633       0.950\n",
      "Health Care                          0.4789      0.096      5.006      0.000       0.291       0.666\n",
      "Insurance                            0.7759      0.114      6.797      0.000       0.552       1.000\n",
      "python                               1.1709      0.050     23.426      0.000       1.073       1.269\n",
      "sql                                  0.7871      0.046     17.071      0.000       0.697       0.877\n",
      "machine learning                     1.2526      0.051     24.570      0.000       1.153       1.353\n",
      "hadoop                               0.4868      0.062      7.800      0.000       0.364       0.609\n",
      "spark                                0.3791      0.066      5.759      0.000       0.250       0.508\n",
      "java                                 0.2871      0.057      5.063      0.000       0.176       0.398\n",
      "datamining                           0.1620      0.057      2.836      0.005       0.050       0.274\n",
      "aws                                  0.5781      0.070      8.234      0.000       0.440       0.716\n",
      "scala                                0.2618      0.076      3.443      0.001       0.113       0.411\n",
      "nosql                               -0.1954      0.080     -2.434      0.015      -0.353      -0.038\n",
      "naturallanguageprocessing            0.2593      0.079      3.297      0.001       0.105       0.413\n",
      "oracle                               0.2631      0.080      3.293      0.001       0.106       0.420\n",
      "datawarehouse                        0.3253      0.077      4.200      0.000       0.173       0.477\n",
      "ai                                   0.1692      0.082      2.062      0.039       0.008       0.330\n",
      "microsoftsqlserver                   0.2049      0.085      2.417      0.016       0.039       0.371\n",
      "kafka                                0.3300      0.091      3.643      0.000       0.152       0.508\n",
      "dataanalysis                         0.3695      0.080      4.627      0.000       0.213       0.526\n",
      "azure                               -0.5420      0.089     -6.062      0.000      -0.717      -0.367\n",
      "matlab                               0.4795      0.086      5.564      0.000       0.311       0.648\n",
      "microsoftoffice                      0.2589      0.093      2.795      0.005       0.077       0.440\n",
      "pig                                 -0.2499      0.098     -2.562      0.010      -0.441      -0.059\n",
      "microsoftpowerpoint                  0.2737      0.099      2.776      0.006       0.080       0.467\n",
      "designexperience                     0.5828      0.098      5.956      0.000       0.391       0.775\n",
      "cassandra                            0.2719      0.111      2.443      0.015       0.054       0.490\n",
      "perl                                 0.2559      0.103      2.478      0.013       0.053       0.458\n",
      "softwaredevelopment                  0.5046      0.102      4.936      0.000       0.304       0.705\n",
      "projectmanagement                    0.7171      0.110      6.492      0.000       0.501       0.934\n",
      "businessintelligence                 0.3891      0.118      3.292      0.001       0.157       0.621\n",
      "s3                                   0.2568      0.125      2.053      0.040       0.012       0.502\n",
      "==============================================================================\n",
      "Omnibus:                      136.957   Durbin-Watson:                   1.150\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              152.792\n",
      "Skew:                           0.361   Prob(JB):                     6.63e-34\n",
      "Kurtosis:                       3.383   Cond. No.                         8.23\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# 'Sal_Ind_Cat4-5-6',     \n",
    "# 'Consulting and Business Services', \\\n",
    "# 'Internet and Software', \\\n",
    "#     'Banks and Financial Services', \\\n",
    "#     'Health Care', \\\n",
    "#     'Insurance', \n",
    "# - Long\n",
    "\n",
    "X = df1[[\n",
    "    'Consulting and Business Services', \\\n",
    "    'Internet and Software', \\\n",
    "    'Banks and Financial Services', \\\n",
    "    'Health Care', \\\n",
    "    'Insurance',\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'java', \\\n",
    "    'datamining', \\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'nosql',  \\\n",
    "    'naturallanguageprocessing', \\\n",
    "    'oracle', \\\n",
    "    'datawarehouse', \\\n",
    "    'ai', \\\n",
    "    'microsoftsqlserver', \\\n",
    "    'kafka', \\\n",
    "    'dataanalysis', \\\n",
    "    'azure', \\\n",
    "    'matlab', \\\n",
    "    'microsoftoffice', \\\n",
    "    'pig', \\\n",
    "    'microsoftpowerpoint', \\\n",
    "    'designexperience', \\\n",
    "    'cassandra', \\\n",
    "    'perl', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'projectmanagement', \\\n",
    "    'businessintelligence', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['Salary_Index']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "# X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cramers_V(var1,var2):\n",
    "#   # Cross table building\n",
    "#   crosstab =np.array(pd.crosstab(var1,var2, rownames=None, colnames=None)) \n",
    "#   # Keeping of the test statistic of the Chi2 test\n",
    "#   stat = chi2_contingency(crosstab)[0] \n",
    "#   obs = np.sum(crosstab) # Number of observations\n",
    "#   # Take the minimum value between the columns and the rows of the cross table\n",
    "#   mini = min(crosstab.shape)-1 \n",
    "#   return (stat/(obs*mini))\n",
    "\n",
    "# rows= []\n",
    "\n",
    "# for var1 in data_encoded:\n",
    "#   col = []\n",
    "#   for var2 in data_encoded :\n",
    "#     cramers =cramers_V(data_encoded[var1], data_encoded[var2]) # Cramer's V test\n",
    "#     col.append(round(cramers,2)) # Keeping of the rounded value of the Cramer's V  \n",
    "#   rows.append(col)\n",
    "  \n",
    "# cramers_results = np.array(rows)\n",
    "# df = pd.DataFrame(cramers_results, columns = data_encoded.columns, index =data_encoded.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cramers_v(x, y):\n",
    "#     confusion_matrix = pd.crosstab(x,y)\n",
    "#     chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "#     n = confusion_matrix.sum().sum()\n",
    "#     phi2 = chi2/n\n",
    "#     r,k = confusion_matrix.shape\n",
    "#     phi2corr = max(0, phi2-((k-1)*(r-1))/(n-1))\n",
    "#     rcorr = r-((r-1)**2)/(n-1)\n",
    "#     kcorr = k-((k-1)**2)/(n-1)\n",
    "#     return np.sqrt(phi2corr/min((kcorr-1),(rcorr-1)))\n",
    "\n",
    "# def correlation_ratio(categories, measurements):\n",
    "#     fcat, _ = pd.factorize(categories)\n",
    "#     cat_num = np.max(fcat)+1\n",
    "#     y_avg_array = np.zeros(cat_num)\n",
    "#     n_array = np.zeros(cat_num)\n",
    "#     for i in range(0,cat_num):\n",
    "#         cat_measures = measurements[np.argwhere(fcat == i).flatten()]\n",
    "#         n_array[i] = len(cat_measures)\n",
    "#         y_avg_array[i] = np.average(cat_measures)\n",
    "#     y_total_avg = np.sum(np.multiply(y_avg_array,n_array))/np.sum(n_array)\n",
    "#     numerator = np.sum(np.multiply(n_array,np.power(np.subtract(y_avg_array,y_total_avg),2)))\n",
    "#     denominator = np.sum(np.power(np.subtract(measurements,y_total_avg),2))\n",
    "#     if numerator == 0:\n",
    "#         eta = 0.0\n",
    "#     else:\n",
    "#         eta = np.sqrt(numerator/denominator)\n",
    "#     return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock_Market = {'Year': [2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016],\n",
    "#                 'Month': [12, 11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1],\n",
    "#                 'Interest_Rate': [2.75,2.5,2.5,2.5,2.5,2.5,2.5,2.25,2.25,2.25,2,2,2,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75],\n",
    "#                 'Unemployment_Rate': [5.3,5.3,5.3,5.3,5.4,5.6,5.5,5.5,5.5,5.6,5.7,5.9,6,5.9,5.8,6.1,6.2,6.1,6.1,6.1,5.9,6.2,6.2,6.1],\n",
    "#                 'Stock_Index_Price': [1464,1394,1357,1293,1256,1254,1234,1195,1159,1167,1130,1075,1047,965,943,958,971,949,884,866,876,822,704,719]        \n",
    "#                 }\n",
    "\n",
    "# df = pd.DataFrame(Stock_Market,columns=['Year','Month','Interest_Rate','Unemployment_Rate','Stock_Index_Price'])\n",
    "\n",
    "# X = df[['Interest_Rate','Unemployment_Rate']] # here we have 2 variables for multiple regression. If you just want to use one variable for simple linear regression, then use X = df['Interest_Rate'] for example.Alternatively, you may add additional variables within the brackets\n",
    "# Y = df['Stock_Index_Price']\n",
    " \n",
    "# # with sklearn\n",
    "# regr = linear_model.LinearRegression()\n",
    "# regr.fit(X, Y)\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "# # prediction with sklearn\n",
    "# New_Interest_Rate = 2.75\n",
    "# New_Unemployment_Rate = 5.3\n",
    "# print ('Predicted Stock Index Price: \\n', regr.predict([[New_Interest_Rate ,New_Unemployment_Rate]]))\n",
    "\n",
    "# # with statsmodels\n",
    "# X = sm.add_constant(X) # adding a constant\n",
    " \n",
    "# model = sm.OLS(Y, X).fit()\n",
    "# predictions = model.predict(X) \n",
    " \n",
    "# print_model = model.summary()\n",
    "# print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ mcnemar test\n",
    "# dfx = pd.DataFrame(np.random.randint(2, size= (90, 2)),\n",
    "#                   columns= ['time1', 'time2'])\n",
    "\n",
    "# crosstab, res = researchpy.crosstab(dfx['time1'], dfx['time2'], test= \"mcnemar\")\n",
    "\n",
    "# crosstab\n",
    "# res\n",
    "\n",
    "#############\n",
    "# crosstab1, res1 = researchpy.crosstab(df_cram_1['python'],df_cram_1['>160000'],  test= \"mcnemar\")\n",
    "\n",
    "# crosstab1\n",
    "# res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# replacement_list = ['Insurance',\n",
    "# 'Health Care',\n",
    "# 'Media, News and Publishing',\n",
    "# 'Telecommunications',\n",
    "# 'Industrial Manufacturing',\n",
    "# 'Pharmaceuticals',\n",
    "# 'Retail',\n",
    "# 'Aerospace and Defense',\n",
    "# 'Auto',\n",
    "# 'Consumer Goods and Services',\n",
    "# 'Real Estate',\n",
    "# 'Construction',\n",
    "# 'Energy and Utilities',\n",
    "# 'Restaurants, Travel and LeisureConsulting and Business Services',\n",
    "# 'Transport and Freight']\n",
    "\n",
    "# for i in replacement_list:\n",
    "#     df_ind1=df_ind.replace({i : 'Other'})\n",
    "# df_ind1\n",
    "\n",
    "# for index, row in df_ind1.iterrows():\n",
    "#     row['1'] = \"I am working!\"\n",
    "\n",
    "\n",
    "# for i, row in df_ind.iterrows():\n",
    "#     df_ind1=df_ind.loc[i,'price_new']  = i \n",
    "\n",
    "# for i in replacement_list:\n",
    "#     df_ind1=df_ind.replace(i : 'Other')\n",
    "# df_ind1\n",
    "\n",
    "#######\n",
    "# Salary_Index = df.iloc[:,4]\n",
    "# No_of_Skills = df.iloc[:,7]\n",
    "# correlation = st.pearsonr(Salary_Index,No_of_Skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_v1 = df_ind2.to_csv(r'../04._Output/output_data_v1.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

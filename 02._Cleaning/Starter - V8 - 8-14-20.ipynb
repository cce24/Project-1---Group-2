{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Two-Letter</th>\n",
       "      <th>Annual mean wage(2)</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>var</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "      <th>State</th>\n",
       "      <th>costIndex</th>\n",
       "      <th>costRank</th>\n",
       "      <th>groceryCost</th>\n",
       "      <th>housingCost</th>\n",
       "      <th>utilitiesCost</th>\n",
       "      <th>transportationCost</th>\n",
       "      <th>miscCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>59290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>129.9</td>\n",
       "      <td>45.0</td>\n",
       "      <td>134.2</td>\n",
       "      <td>133.9</td>\n",
       "      <td>154.2</td>\n",
       "      <td>130.8</td>\n",
       "      <td>150.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>44930.0</td>\n",
       "      <td>2.529412</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.889706</td>\n",
       "      <td>0.943242</td>\n",
       "      <td>0.228770</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>89.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>97.4</td>\n",
       "      <td>71.5</td>\n",
       "      <td>103.3</td>\n",
       "      <td>88.6</td>\n",
       "      <td>90.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR</td>\n",
       "      <td>42690.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.470899</td>\n",
       "      <td>1.212806</td>\n",
       "      <td>0.229199</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>86.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>91.8</td>\n",
       "      <td>83.6</td>\n",
       "      <td>85.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AZ</td>\n",
       "      <td>50930.0</td>\n",
       "      <td>2.792453</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.206096</td>\n",
       "      <td>1.098224</td>\n",
       "      <td>0.150853</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>97.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>96.9</td>\n",
       "      <td>91.7</td>\n",
       "      <td>107.4</td>\n",
       "      <td>109.6</td>\n",
       "      <td>94.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>61290.0</td>\n",
       "      <td>3.969176</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.131761</td>\n",
       "      <td>1.460055</td>\n",
       "      <td>0.039091</td>\n",
       "      <td>California</td>\n",
       "      <td>151.7</td>\n",
       "      <td>49.0</td>\n",
       "      <td>121.4</td>\n",
       "      <td>227.3</td>\n",
       "      <td>117.7</td>\n",
       "      <td>138.9</td>\n",
       "      <td>114.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CO</td>\n",
       "      <td>57690.0</td>\n",
       "      <td>2.963303</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.350493</td>\n",
       "      <td>1.162107</td>\n",
       "      <td>0.111310</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>105.6</td>\n",
       "      <td>33.0</td>\n",
       "      <td>102.5</td>\n",
       "      <td>119.0</td>\n",
       "      <td>88.4</td>\n",
       "      <td>101.2</td>\n",
       "      <td>102.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CT</td>\n",
       "      <td>62350.0</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.927928</td>\n",
       "      <td>1.388498</td>\n",
       "      <td>0.160330</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>127.7</td>\n",
       "      <td>43.0</td>\n",
       "      <td>114.2</td>\n",
       "      <td>144.7</td>\n",
       "      <td>128.1</td>\n",
       "      <td>111.8</td>\n",
       "      <td>113.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DC</td>\n",
       "      <td>89800.0</td>\n",
       "      <td>3.107143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.549589</td>\n",
       "      <td>1.244825</td>\n",
       "      <td>0.105207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DE</td>\n",
       "      <td>54370.0</td>\n",
       "      <td>3.470588</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.639706</td>\n",
       "      <td>1.280510</td>\n",
       "      <td>0.310569</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>108.1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>113.4</td>\n",
       "      <td>98.2</td>\n",
       "      <td>96.5</td>\n",
       "      <td>107.0</td>\n",
       "      <td>101.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FL</td>\n",
       "      <td>47750.0</td>\n",
       "      <td>2.514563</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.546354</td>\n",
       "      <td>1.243525</td>\n",
       "      <td>0.122528</td>\n",
       "      <td>Florida</td>\n",
       "      <td>97.9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>95.4</td>\n",
       "      <td>102.2</td>\n",
       "      <td>96.7</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GA</td>\n",
       "      <td>49620.0</td>\n",
       "      <td>2.589928</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.678449</td>\n",
       "      <td>1.295550</td>\n",
       "      <td>0.109887</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>89.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>96.9</td>\n",
       "      <td>73.8</td>\n",
       "      <td>92.4</td>\n",
       "      <td>97.6</td>\n",
       "      <td>98.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HI</td>\n",
       "      <td>54930.0</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>1.329160</td>\n",
       "      <td>0.542627</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>192.9</td>\n",
       "      <td>51.0</td>\n",
       "      <td>169.3</td>\n",
       "      <td>318.6</td>\n",
       "      <td>172.7</td>\n",
       "      <td>148.6</td>\n",
       "      <td>116.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IA</td>\n",
       "      <td>47330.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.126437</td>\n",
       "      <td>1.061337</td>\n",
       "      <td>0.193773</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>90.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>95.9</td>\n",
       "      <td>79.6</td>\n",
       "      <td>95.3</td>\n",
       "      <td>95.5</td>\n",
       "      <td>97.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ID</td>\n",
       "      <td>44890.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.836660</td>\n",
       "      <td>0.341565</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>92.3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>92.2</td>\n",
       "      <td>87.1</td>\n",
       "      <td>82.9</td>\n",
       "      <td>106.7</td>\n",
       "      <td>97.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IL</td>\n",
       "      <td>55130.0</td>\n",
       "      <td>3.095833</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.358978</td>\n",
       "      <td>1.165752</td>\n",
       "      <td>0.075249</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>94.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>94.2</td>\n",
       "      <td>87.2</td>\n",
       "      <td>100.9</td>\n",
       "      <td>100.9</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IN</td>\n",
       "      <td>46770.0</td>\n",
       "      <td>2.521739</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.588406</td>\n",
       "      <td>1.260320</td>\n",
       "      <td>0.185824</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>90.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>93.3</td>\n",
       "      <td>77.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>93.1</td>\n",
       "      <td>94.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KS</td>\n",
       "      <td>46520.0</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.881917</td>\n",
       "      <td>0.293972</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>89.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>91.9</td>\n",
       "      <td>73.8</td>\n",
       "      <td>103.0</td>\n",
       "      <td>92.3</td>\n",
       "      <td>98.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KY</td>\n",
       "      <td>44020.0</td>\n",
       "      <td>2.230769</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.025641</td>\n",
       "      <td>1.423250</td>\n",
       "      <td>0.394739</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>90.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>89.9</td>\n",
       "      <td>77.4</td>\n",
       "      <td>97.6</td>\n",
       "      <td>92.8</td>\n",
       "      <td>89.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LA</td>\n",
       "      <td>44170.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.095445</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>93.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>86.6</td>\n",
       "      <td>89.3</td>\n",
       "      <td>98.5</td>\n",
       "      <td>98.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MA</td>\n",
       "      <td>65680.0</td>\n",
       "      <td>3.188192</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.064453</td>\n",
       "      <td>1.436820</td>\n",
       "      <td>0.087281</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>131.6</td>\n",
       "      <td>46.0</td>\n",
       "      <td>113.9</td>\n",
       "      <td>170.3</td>\n",
       "      <td>109.7</td>\n",
       "      <td>116.0</td>\n",
       "      <td>117.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MD</td>\n",
       "      <td>60230.0</td>\n",
       "      <td>3.047337</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.759651</td>\n",
       "      <td>1.326518</td>\n",
       "      <td>0.102040</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>129.7</td>\n",
       "      <td>44.0</td>\n",
       "      <td>108.5</td>\n",
       "      <td>184.5</td>\n",
       "      <td>107.3</td>\n",
       "      <td>116.7</td>\n",
       "      <td>89.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ME</td>\n",
       "      <td>48470.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.877058</td>\n",
       "      <td>0.234404</td>\n",
       "      <td>Maine</td>\n",
       "      <td>117.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>123.1</td>\n",
       "      <td>116.1</td>\n",
       "      <td>121.4</td>\n",
       "      <td>121.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MI</td>\n",
       "      <td>50780.0</td>\n",
       "      <td>2.482353</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.276471</td>\n",
       "      <td>1.129810</td>\n",
       "      <td>0.122545</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>88.9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>89.3</td>\n",
       "      <td>75.2</td>\n",
       "      <td>97.3</td>\n",
       "      <td>97.4</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MN</td>\n",
       "      <td>55890.0</td>\n",
       "      <td>2.409091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.445455</td>\n",
       "      <td>1.202271</td>\n",
       "      <td>0.147989</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>101.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>88.3</td>\n",
       "      <td>96.8</td>\n",
       "      <td>103.7</td>\n",
       "      <td>108.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MO</td>\n",
       "      <td>47820.0</td>\n",
       "      <td>2.467532</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.462748</td>\n",
       "      <td>1.209441</td>\n",
       "      <td>0.137829</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>87.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>96.6</td>\n",
       "      <td>70.6</td>\n",
       "      <td>99.6</td>\n",
       "      <td>87.3</td>\n",
       "      <td>95.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MS</td>\n",
       "      <td>40090.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>86.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.6</td>\n",
       "      <td>70.1</td>\n",
       "      <td>89.1</td>\n",
       "      <td>89.2</td>\n",
       "      <td>91.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MT</td>\n",
       "      <td>45370.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montana</td>\n",
       "      <td>106.9</td>\n",
       "      <td>34.0</td>\n",
       "      <td>105.1</td>\n",
       "      <td>111.6</td>\n",
       "      <td>83.9</td>\n",
       "      <td>125.0</td>\n",
       "      <td>98.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NC</td>\n",
       "      <td>48550.0</td>\n",
       "      <td>2.928058</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.444062</td>\n",
       "      <td>1.201691</td>\n",
       "      <td>0.101926</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>94.9</td>\n",
       "      <td>22.0</td>\n",
       "      <td>96.6</td>\n",
       "      <td>83.1</td>\n",
       "      <td>97.9</td>\n",
       "      <td>93.4</td>\n",
       "      <td>110.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ND</td>\n",
       "      <td>50430.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>98.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>108.1</td>\n",
       "      <td>90.3</td>\n",
       "      <td>93.6</td>\n",
       "      <td>104.3</td>\n",
       "      <td>111.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NE</td>\n",
       "      <td>48250.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.699206</td>\n",
       "      <td>0.221108</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>90.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>80.9</td>\n",
       "      <td>90.8</td>\n",
       "      <td>94.3</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NH</td>\n",
       "      <td>53950.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.238095</td>\n",
       "      <td>1.112697</td>\n",
       "      <td>0.420560</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>109.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>110.3</td>\n",
       "      <td>119.5</td>\n",
       "      <td>111.4</td>\n",
       "      <td>116.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NJ</td>\n",
       "      <td>59980.0</td>\n",
       "      <td>3.257812</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.287340</td>\n",
       "      <td>1.512395</td>\n",
       "      <td>0.133678</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>125.1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>109.5</td>\n",
       "      <td>163.1</td>\n",
       "      <td>101.6</td>\n",
       "      <td>111.1</td>\n",
       "      <td>101.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NM</td>\n",
       "      <td>47040.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>87.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.9</td>\n",
       "      <td>77.7</td>\n",
       "      <td>87.9</td>\n",
       "      <td>91.6</td>\n",
       "      <td>100.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NV</td>\n",
       "      <td>47210.0</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.892105</td>\n",
       "      <td>0.944513</td>\n",
       "      <td>0.211200</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>108.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>108.3</td>\n",
       "      <td>121.8</td>\n",
       "      <td>89.0</td>\n",
       "      <td>123.5</td>\n",
       "      <td>105.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NY</td>\n",
       "      <td>63970.0</td>\n",
       "      <td>3.725458</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.602834</td>\n",
       "      <td>1.613330</td>\n",
       "      <td>0.065809</td>\n",
       "      <td>New York</td>\n",
       "      <td>139.1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>114.8</td>\n",
       "      <td>204.4</td>\n",
       "      <td>108.7</td>\n",
       "      <td>116.6</td>\n",
       "      <td>104.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>OH</td>\n",
       "      <td>49430.0</td>\n",
       "      <td>2.712963</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.440204</td>\n",
       "      <td>1.200085</td>\n",
       "      <td>0.115478</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>90.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>73.6</td>\n",
       "      <td>91.8</td>\n",
       "      <td>96.7</td>\n",
       "      <td>97.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OK</td>\n",
       "      <td>45620.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.4</td>\n",
       "      <td>71.9</td>\n",
       "      <td>94.1</td>\n",
       "      <td>89.5</td>\n",
       "      <td>93.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>OR</td>\n",
       "      <td>53890.0</td>\n",
       "      <td>2.793651</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.940604</td>\n",
       "      <td>1.393056</td>\n",
       "      <td>0.175509</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>134.2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>110.3</td>\n",
       "      <td>181.8</td>\n",
       "      <td>88.0</td>\n",
       "      <td>136.7</td>\n",
       "      <td>113.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>PA</td>\n",
       "      <td>51340.0</td>\n",
       "      <td>2.539568</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.525597</td>\n",
       "      <td>1.235151</td>\n",
       "      <td>0.104764</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>101.7</td>\n",
       "      <td>32.0</td>\n",
       "      <td>106.9</td>\n",
       "      <td>100.8</td>\n",
       "      <td>106.0</td>\n",
       "      <td>109.5</td>\n",
       "      <td>91.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RI</td>\n",
       "      <td>57220.0</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.069045</td>\n",
       "      <td>0.404061</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>119.4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>106.2</td>\n",
       "      <td>129.4</td>\n",
       "      <td>123.5</td>\n",
       "      <td>124.0</td>\n",
       "      <td>109.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SC</td>\n",
       "      <td>44380.0</td>\n",
       "      <td>2.541667</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.476449</td>\n",
       "      <td>1.215092</td>\n",
       "      <td>0.248030</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>95.9</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.9</td>\n",
       "      <td>85.1</td>\n",
       "      <td>107.6</td>\n",
       "      <td>88.0</td>\n",
       "      <td>94.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SD</td>\n",
       "      <td>42920.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>99.8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>109.8</td>\n",
       "      <td>91.8</td>\n",
       "      <td>89.8</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TN</td>\n",
       "      <td>45650.0</td>\n",
       "      <td>2.545455</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.835095</td>\n",
       "      <td>1.354657</td>\n",
       "      <td>0.204222</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>88.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93.3</td>\n",
       "      <td>80.2</td>\n",
       "      <td>93.4</td>\n",
       "      <td>89.7</td>\n",
       "      <td>88.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>TX</td>\n",
       "      <td>50490.0</td>\n",
       "      <td>2.866261</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.664986</td>\n",
       "      <td>1.290343</td>\n",
       "      <td>0.071139</td>\n",
       "      <td>Texas</td>\n",
       "      <td>91.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>88.9</td>\n",
       "      <td>85.3</td>\n",
       "      <td>102.3</td>\n",
       "      <td>91.4</td>\n",
       "      <td>96.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>UT</td>\n",
       "      <td>49420.0</td>\n",
       "      <td>2.352941</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.629234</td>\n",
       "      <td>1.276414</td>\n",
       "      <td>0.218903</td>\n",
       "      <td>Utah</td>\n",
       "      <td>98.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>98.5</td>\n",
       "      <td>93.6</td>\n",
       "      <td>89.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>VA</td>\n",
       "      <td>56740.0</td>\n",
       "      <td>3.389222</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.781986</td>\n",
       "      <td>1.334910</td>\n",
       "      <td>0.073043</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>100.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>96.1</td>\n",
       "      <td>108.0</td>\n",
       "      <td>99.2</td>\n",
       "      <td>88.1</td>\n",
       "      <td>97.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>VT</td>\n",
       "      <td>51120.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>114.5</td>\n",
       "      <td>39.0</td>\n",
       "      <td>111.3</td>\n",
       "      <td>126.7</td>\n",
       "      <td>120.2</td>\n",
       "      <td>119.9</td>\n",
       "      <td>101.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>WA</td>\n",
       "      <td>62020.0</td>\n",
       "      <td>3.396396</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.869308</td>\n",
       "      <td>1.367226</td>\n",
       "      <td>0.091762</td>\n",
       "      <td>Washington</td>\n",
       "      <td>110.7</td>\n",
       "      <td>38.0</td>\n",
       "      <td>107.8</td>\n",
       "      <td>117.8</td>\n",
       "      <td>88.7</td>\n",
       "      <td>121.7</td>\n",
       "      <td>118.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>WI</td>\n",
       "      <td>48850.0</td>\n",
       "      <td>2.717949</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.102564</td>\n",
       "      <td>1.050031</td>\n",
       "      <td>0.168139</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>97.3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.7</td>\n",
       "      <td>91.4</td>\n",
       "      <td>98.9</td>\n",
       "      <td>98.1</td>\n",
       "      <td>115.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>WV</td>\n",
       "      <td>43420.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>91.1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>92.9</td>\n",
       "      <td>79.6</td>\n",
       "      <td>89.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>89.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>WY</td>\n",
       "      <td>49760.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>89.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>72.3</td>\n",
       "      <td>87.3</td>\n",
       "      <td>99.3</td>\n",
       "      <td>94.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State_Two-Letter  Annual mean wage(2)      mean  median       var  \\\n",
       "0                AK              59290.0       NaN     NaN       NaN   \n",
       "1                AL              44930.0  2.529412     2.0  0.889706   \n",
       "2                AR              42690.0  2.714286     3.0  1.470899   \n",
       "3                AZ              50930.0  2.792453     3.0  1.206096   \n",
       "4                CA              61290.0  3.969176     4.0  2.131761   \n",
       "5                CO              57690.0  2.963303     3.0  1.350493   \n",
       "6                CT              62350.0  2.933333     3.0  1.927928   \n",
       "7                DC              89800.0  3.107143     3.0  1.549589   \n",
       "8                DE              54370.0  3.470588     3.0  1.639706   \n",
       "9                FL              47750.0  2.514563     3.0  1.546354   \n",
       "10               GA              49620.0  2.589928     2.0  1.678449   \n",
       "11               HI              54930.0  2.833333     3.0  1.766667   \n",
       "12               IA              47330.0  2.666667     3.0  1.126437   \n",
       "13               ID              44890.0  2.500000     3.0  0.700000   \n",
       "14               IL              55130.0  3.095833     3.0  1.358978   \n",
       "15               IN              46770.0  2.521739     2.0  1.588406   \n",
       "16               KS              46520.0  2.444444     3.0  0.777778   \n",
       "17               KY              44020.0  2.230769     2.0  2.025641   \n",
       "18               LA              44170.0  2.000000     2.0  1.200000   \n",
       "19               MA              65680.0  3.188192     3.0  2.064453   \n",
       "20               MD              60230.0  3.047337     3.0  1.759651   \n",
       "21               ME              48470.0  2.000000     2.0  0.769231   \n",
       "22               MI              50780.0  2.482353     2.0  1.276471   \n",
       "23               MN              55890.0  2.409091     2.0  1.445455   \n",
       "24               MO              47820.0  2.467532     2.0  1.462748   \n",
       "25               MS              40090.0       NaN     NaN       NaN   \n",
       "26               MT              45370.0  3.000000     3.0       NaN   \n",
       "27               NC              48550.0  2.928058     3.0  1.444062   \n",
       "28               ND              50430.0  3.000000     3.0       NaN   \n",
       "29               NE              48250.0  2.400000     2.5  0.488889   \n",
       "30               NH              53950.0  2.714286     2.0  1.238095   \n",
       "31               NJ              59980.0  3.257812     3.0  2.287340   \n",
       "32               NM              47040.0  2.000000     2.0  1.000000   \n",
       "33               NV              47210.0  2.050000     2.0  0.892105   \n",
       "34               NY              63970.0  3.725458     4.0  2.602834   \n",
       "35               OH              49430.0  2.712963     3.0  1.440204   \n",
       "36               OK              45620.0  2.500000     3.0  1.000000   \n",
       "37               OR              53890.0  2.793651     3.0  1.940604   \n",
       "38               PA              51340.0  2.539568     2.0  1.525597   \n",
       "39               RI              57220.0  2.857143     3.0  1.142857   \n",
       "40               SC              44380.0  2.541667     2.5  1.476449   \n",
       "41               SD              42920.0  2.000000     2.0       NaN   \n",
       "42               TN              45650.0  2.545455     2.0  1.835095   \n",
       "43               TX              50490.0  2.866261     3.0  1.664986   \n",
       "44               UT              49420.0  2.352941     2.0  1.629234   \n",
       "45               VA              56740.0  3.389222     3.0  1.781986   \n",
       "46               VT              51120.0  1.000000     1.0  0.000000   \n",
       "47               WA              62020.0  3.396396     3.0  1.869308   \n",
       "48               WI              48850.0  2.717949     3.0  1.102564   \n",
       "49               WV              43420.0  2.333333     2.0  0.333333   \n",
       "50               WY              49760.0  2.500000     2.5  0.500000   \n",
       "\n",
       "         std       sem           State  costIndex  costRank  groceryCost  \\\n",
       "0        NaN       NaN          Alaska      129.9      45.0        134.2   \n",
       "1   0.943242  0.228770         Alabama       89.3      11.0         97.4   \n",
       "2   1.212806  0.229199        Arkansas       86.9       2.0         92.0   \n",
       "3   1.098224  0.150853         Arizona       97.0      24.0         96.9   \n",
       "4   1.460055  0.039091      California      151.7      49.0        121.4   \n",
       "5   1.162107  0.111310        Colorado      105.6      33.0        102.5   \n",
       "6   1.388498  0.160330     Connecticut      127.7      43.0        114.2   \n",
       "7   1.244825  0.105207             NaN        NaN       NaN          NaN   \n",
       "8   1.280510  0.310569        Delaware      108.1      35.0        113.4   \n",
       "9   1.243525  0.122528         Florida       97.9      26.0        104.0   \n",
       "10  1.295550  0.109887         Georgia       89.2       9.0         96.9   \n",
       "11  1.329160  0.542627          Hawaii      192.9      51.0        169.3   \n",
       "12  1.061337  0.193773            Iowa       90.1      13.0         95.9   \n",
       "13  0.836660  0.341565           Idaho       92.3      19.0         92.2   \n",
       "14  1.165752  0.075249        Illinois       94.5      21.0         94.2   \n",
       "15  1.260320  0.185824         Indiana       90.0      12.0         93.3   \n",
       "16  0.881917  0.293972          Kansas       89.0       8.0         91.9   \n",
       "17  1.423250  0.394739        Kentucky       90.9      16.0         89.9   \n",
       "18  1.095445  0.447214       Louisiana       93.9      20.0         99.9   \n",
       "19  1.436820  0.087281   Massachusetts      131.6      46.0        113.9   \n",
       "20  1.326518  0.102040        Maryland      129.7      44.0        108.5   \n",
       "21  0.877058  0.234404           Maine      117.5      40.0        107.0   \n",
       "22  1.129810  0.122545        Michigan       88.9       7.0         89.3   \n",
       "23  1.202271  0.147989       Minnesota      101.6      31.0        106.7   \n",
       "24  1.209441  0.137829        Missouri       87.1       4.0         96.6   \n",
       "25       NaN       NaN     Mississippi       86.1       1.0         91.6   \n",
       "26       NaN       NaN         Montana      106.9      34.0        105.1   \n",
       "27  1.201691  0.101926  North Carolina       94.9      22.0         96.6   \n",
       "28       NaN       NaN    North Dakota       98.8      28.0        108.1   \n",
       "29  0.699206  0.221108        Nebraska       90.8      14.0         95.5   \n",
       "30  1.112697  0.420560   New Hampshire      109.7      37.0        100.4   \n",
       "31  1.512395  0.133678      New Jersey      125.1      42.0        109.5   \n",
       "32  1.000000  0.447214      New Mexico       87.5       5.0        100.9   \n",
       "33  0.944513  0.211200          Nevada      108.5      36.0        108.3   \n",
       "34  1.613330  0.065809        New York      139.1      48.0        114.8   \n",
       "35  1.200085  0.115478            Ohio       90.8      15.0         98.7   \n",
       "36  1.000000  0.500000        Oklahoma       87.0       3.0         95.4   \n",
       "37  1.393056  0.175509          Oregon      134.2      47.0        110.3   \n",
       "38  1.235151  0.104764    Pennsylvania      101.7      32.0        106.9   \n",
       "39  1.069045  0.404061    Rhode Island      119.4      41.0        106.2   \n",
       "40  1.215092  0.248030  South Carolina       95.9      23.0        101.9   \n",
       "41       NaN       NaN    South Dakota       99.8      29.0        107.0   \n",
       "42  1.354657  0.204222       Tennessee       88.7       6.0         93.3   \n",
       "43  1.290343  0.071139           Texas       91.5      18.0         88.9   \n",
       "44  1.276414  0.218903            Utah       98.4      27.0         98.5   \n",
       "45  1.334910  0.073043        Virginia      100.7      30.0         96.1   \n",
       "46  0.000000  0.000000         Vermont      114.5      39.0        111.3   \n",
       "47  1.367226  0.091762      Washington      110.7      38.0        107.8   \n",
       "48  1.050031  0.168139       Wisconsin       97.3      25.0        100.7   \n",
       "49  0.577350  0.333333   West Virginia       91.1      17.0         92.9   \n",
       "50  0.707107  0.500000         Wyoming       89.3      10.0         98.7   \n",
       "\n",
       "    housingCost  utilitiesCost  transportationCost  miscCost  \n",
       "0         133.9          154.2               130.8     150.9  \n",
       "1          71.5          103.3                88.6      90.8  \n",
       "2          73.9           91.8                83.6      85.6  \n",
       "3          91.7          107.4               109.6      94.7  \n",
       "4         227.3          117.7               138.9     114.5  \n",
       "5         119.0           88.4               101.2     102.9  \n",
       "6         144.7          128.1               111.8     113.7  \n",
       "7           NaN            NaN                 NaN       NaN  \n",
       "8          98.2           96.5               107.0     101.6  \n",
       "9          95.4          102.2                96.7      96.9  \n",
       "10         73.8           92.4                97.6      98.5  \n",
       "11        318.6          172.7               148.6     116.8  \n",
       "12         79.6           95.3                95.5      97.8  \n",
       "13         87.1           82.9               106.7      97.3  \n",
       "14         87.2          100.9               100.9      99.0  \n",
       "15         77.3           97.0                93.1      94.3  \n",
       "16         73.8          103.0                92.3      98.9  \n",
       "17         77.4           97.6                92.8      89.2  \n",
       "18         86.6           89.3                98.5      98.8  \n",
       "19        170.3          109.7               116.0     117.6  \n",
       "20        184.5          107.3               116.7      89.2  \n",
       "21        123.1          116.1               121.4     121.8  \n",
       "22         75.2           97.3                97.4      93.0  \n",
       "23         88.3           96.8               103.7     108.6  \n",
       "24         70.6           99.6                87.3      95.7  \n",
       "25         70.1           89.1                89.2      91.4  \n",
       "26        111.6           83.9               125.0      98.4  \n",
       "27         83.1           97.9                93.4     110.6  \n",
       "28         90.3           93.6               104.3     111.7  \n",
       "29         80.9           90.8                94.3      99.9  \n",
       "30        110.3          119.5               111.4     116.1  \n",
       "31        163.1          101.6               111.1     101.7  \n",
       "32         77.7           87.9                91.6     100.1  \n",
       "33        121.8           89.0               123.5     105.7  \n",
       "34        204.4          108.7               116.6     104.8  \n",
       "35         73.6           91.8                96.7      97.6  \n",
       "36         71.9           94.1                89.5      93.2  \n",
       "37        181.8           88.0               136.7     113.2  \n",
       "38        100.8          106.0               109.5      91.9  \n",
       "39        129.4          123.5               124.0     109.3  \n",
       "40         85.1          107.6                88.0      94.2  \n",
       "41        109.8           91.8                89.8     103.0  \n",
       "42         80.2           93.4                89.7      88.5  \n",
       "43         85.3          102.3                91.4      96.2  \n",
       "44         93.6           89.4               108.6      96.0  \n",
       "45        108.0           99.2                88.1      97.2  \n",
       "46        126.7          120.2               119.9     101.2  \n",
       "47        117.8           88.7               121.7     118.9  \n",
       "48         91.4           98.9                98.1     115.2  \n",
       "49         79.6           89.0                93.5      89.1  \n",
       "50         72.3           87.3                99.3      94.9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gmaps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.stats as st\n",
    "from scipy.stats import chi2_contingency\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg') \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import researchpy\n",
    "from scipy.stats import chisquare\n",
    "from scipy.stats import linregress\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    " \n",
    "\n",
    "# # Google developer API key\n",
    "# from config import gkey\n",
    "\n",
    "# # Configure gmaps\n",
    "# gmaps.configure(api_key=gkey)\n",
    "\n",
    "#This is the general/common section\n",
    "path = pd.read_csv('../01._Prospective_Project_Data/1._72199_158097_compressed_indeed_job_dataset.csv/indeed_job_dataset_V3_CSV.csv')\n",
    "df = pd.DataFrame(path)\n",
    "df\n",
    "\n",
    "# df.fillna(0) \n",
    "# df\n",
    "\n",
    "path2 = pd.read_csv('../01._Prospective_Project_Data/BLS_Data/OES_Report-V2.csv')\n",
    "BLS_df = pd.DataFrame(path2)\n",
    "BLS_df\n",
    "BLS_df[\"Annual mean wage(2)\"] = BLS_df[\"Annual mean wage(2)\"].str.replace(\",\",\"\")\n",
    "BLS_df[\"Annual mean wage(2)\"] = BLS_df[\"Annual mean wage(2)\"].astype(\"float64\")\n",
    "BLS_df = BLS_df.groupby('State_Two-Letter').agg({\"Annual mean wage(2)\":\"mean\"}).reset_index()\n",
    "# # BLS_df\n",
    "# # BLS_df = pd.DataFrame(BLS_df).mean()\n",
    "BLS_df\n",
    "\n",
    "path3 = pd.read_csv('../01._Prospective_Project_Data/Consumer_Price_Data/CPI_Data_V2_No_DC.csv')\n",
    "CPI_df = pd.DataFrame(path3)\n",
    "CPI_df\n",
    "\n",
    "df_grouped= df.groupby('Location')['Salary_Index'].agg(['mean','median', 'var', 'std', 'sem']).reset_index()\n",
    "df_grouped = pd.DataFrame(df_grouped)\n",
    "df_grouped\n",
    "df_grouped\n",
    "\n",
    "df_grouped = df_grouped.rename(columns={'Location':'State_Two-Letter'})\n",
    "df_grouped\n",
    "\n",
    "merge_df = pd.merge(BLS_df, df_grouped, how='left', on='State_Two-Letter')      \n",
    "merge_df\n",
    "merge_df = pd.merge(merge_df, CPI_df, how='left', on='State_Two-Letter')      \n",
    "merge_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index_No</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Queried_Salary</th>\n",
       "      <th>&lt;80000</th>\n",
       "      <th>80000-99999</th>\n",
       "      <th>100000-119999</th>\n",
       "      <th>120000-139999</th>\n",
       "      <th>140000-159999</th>\n",
       "      <th>&gt;160000</th>\n",
       "      <th>...</th>\n",
       "      <th>spss</th>\n",
       "      <th>softwaredevelopment</th>\n",
       "      <th>shellscripting</th>\n",
       "      <th>datascience</th>\n",
       "      <th>docker</th>\n",
       "      <th>mongodb</th>\n",
       "      <th>.net</th>\n",
       "      <th>projectmanagement</th>\n",
       "      <th>businessintelligence</th>\n",
       "      <th>s3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=6a105f495c36a...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=86afd561ea8c6...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=e0aad317e6d45...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Graduate Studies Program - Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=1cfdd9e391a63...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=fec647775a21e...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5710</th>\n",
       "      <td>5710.0</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=fbe2dd71643b3...</td>\n",
       "      <td>&gt;160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5711</th>\n",
       "      <td>5711.0</td>\n",
       "      <td>Principal Data Engineer (Java, Spark, Storm, AWS)</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=70ee8b9bb5a2b...</td>\n",
       "      <td>&gt;160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5712</th>\n",
       "      <td>5712.0</td>\n",
       "      <td>Executive Director- Architect: Data Engineerin...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=2c2a7f94f6ed1...</td>\n",
       "      <td>&gt;160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5713</th>\n",
       "      <td>5713.0</td>\n",
       "      <td>Senior Manager, Data Engineering (hands on)</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=1051e100b300b...</td>\n",
       "      <td>&gt;160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5714</th>\n",
       "      <td>5714.0</td>\n",
       "      <td>Principal Visual Analytics / Big Data Engineer...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=605a2c61478f1...</td>\n",
       "      <td>&gt;160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5483 rows  90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index_No                                          Job_Title  \\\n",
       "0          0.0                                     Data Scientist   \n",
       "1          1.0                                     Data Scientist   \n",
       "2          2.0                                     Data Scientist   \n",
       "3          3.0          Graduate Studies Program - Data Scientist   \n",
       "4          4.0                                   Data Scientist I   \n",
       "...        ...                                                ...   \n",
       "5710    5710.0                               Senior Data Engineer   \n",
       "5711    5711.0  Principal Data Engineer (Java, Spark, Storm, AWS)   \n",
       "5712    5712.0  Executive Director- Architect: Data Engineerin...   \n",
       "5713    5713.0        Senior Manager, Data Engineering (hands on)   \n",
       "5714    5714.0  Principal Visual Analytics / Big Data Engineer...   \n",
       "\n",
       "                                                   Link Queried_Salary  \\\n",
       "0     https://www.indeed.com/rc/clk?jk=6a105f495c36a...         <80000   \n",
       "1     https://www.indeed.com/rc/clk?jk=86afd561ea8c6...         <80000   \n",
       "2     https://www.indeed.com/rc/clk?jk=e0aad317e6d45...         <80000   \n",
       "3     https://www.indeed.com/rc/clk?jk=1cfdd9e391a63...         <80000   \n",
       "4     https://www.indeed.com/rc/clk?jk=fec647775a21e...         <80000   \n",
       "...                                                 ...            ...   \n",
       "5710  https://www.indeed.com/rc/clk?jk=fbe2dd71643b3...        >160000   \n",
       "5711  https://www.indeed.com/rc/clk?jk=70ee8b9bb5a2b...        >160000   \n",
       "5712  https://www.indeed.com/rc/clk?jk=2c2a7f94f6ed1...        >160000   \n",
       "5713  https://www.indeed.com/rc/clk?jk=1051e100b300b...        >160000   \n",
       "5714  https://www.indeed.com/rc/clk?jk=605a2c61478f1...        >160000   \n",
       "\n",
       "      <80000  80000-99999  100000-119999  120000-139999  140000-159999  \\\n",
       "0        1.0          0.0            0.0            0.0            0.0   \n",
       "1        1.0          0.0            0.0            0.0            0.0   \n",
       "2        1.0          0.0            0.0            0.0            0.0   \n",
       "3        1.0          0.0            0.0            0.0            0.0   \n",
       "4        1.0          0.0            0.0            0.0            0.0   \n",
       "...      ...          ...            ...            ...            ...   \n",
       "5710     0.0          0.0            0.0            0.0            0.0   \n",
       "5711     0.0          0.0            0.0            0.0            0.0   \n",
       "5712     0.0          0.0            0.0            0.0            0.0   \n",
       "5713     0.0          0.0            0.0            0.0            0.0   \n",
       "5714     0.0          0.0            0.0            0.0            0.0   \n",
       "\n",
       "      >160000  ...  spss  softwaredevelopment shellscripting  datascience  \\\n",
       "0         0.0  ...     0                    0              0            0   \n",
       "1         0.0  ...     0                    0              0            0   \n",
       "2         0.0  ...     1                    0              0            0   \n",
       "3         0.0  ...     0                    0              0            0   \n",
       "4         0.0  ...     0                    0              0            1   \n",
       "...       ...  ...   ...                  ...            ...          ...   \n",
       "5710      1.0  ...     0                    1              0            0   \n",
       "5711      1.0  ...     0                    0              0            0   \n",
       "5712      1.0  ...     0                    0              0            0   \n",
       "5713      1.0  ...     0                    0              0            0   \n",
       "5714      1.0  ...     0                    1              0            0   \n",
       "\n",
       "     docker  mongodb  .net  projectmanagement businessintelligence s3  \n",
       "0         0        0     0                  0                    0  0  \n",
       "1         0        0     0                  0                    0  0  \n",
       "2         0        0     0                  0                    0  0  \n",
       "3         0        0     0                  0                    0  0  \n",
       "4         0        0     0                  0                    0  0  \n",
       "...     ...      ...   ...                ...                  ... ..  \n",
       "5710      0        0     0                  0                    0  0  \n",
       "5711      0        1     0                  0                    0  0  \n",
       "5712      0        0     0                  0                    0  1  \n",
       "5713      1        0     0                  0                    0  0  \n",
       "5714      0        0     0                  0                    0  0  \n",
       "\n",
       "[5483 rows x 90 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop observations/rows with \"0\" values for \"Number of Skills\" column \n",
    "df_cleaned = df.dropna(subset=['No_of_Skills'])\n",
    "\n",
    "# Examine df\n",
    "# df_cleaned.head()\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colin Ek\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Python</th>        <th class=\"col_heading level0 col1\" >SQL</th>        <th class=\"col_heading level0 col2\" >Machine Learning</th>        <th class=\"col_heading level0 col3\" >R</th>        <th class=\"col_heading level0 col4\" >Hadoop</th>        <th class=\"col_heading level0 col5\" >Tableau</th>        <th class=\"col_heading level0 col6\" >SAS</th>        <th class=\"col_heading level0 col7\" >Spark</th>        <th class=\"col_heading level0 col8\" >Java</th>        <th class=\"col_heading level0 col9\" >Others</th>    </tr>    <tr>        <th class=\"index_name level0\" >Salary_List</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0level0_row0\" class=\"row_heading level0 row0\" ><80000</th>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row0_col0\" class=\"data row0 col0\" >20.96%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row0_col1\" class=\"data row0 col1\" >56.33%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row0_col2\" class=\"data row0 col2\" >9.75%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row0_col3\" class=\"data row0 col3\" >21.54%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row0_col4\" class=\"data row0 col4\" >1.75%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row0_col5\" class=\"data row0 col5\" >23.58%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row0_col6\" class=\"data row0 col6\" >19.07%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row0_col7\" class=\"data row0 col7\" >1.31%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row0_col8\" class=\"data row0 col8\" >8.15%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row0_col9\" class=\"data row0 col9\" >89.52%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0level0_row1\" class=\"row_heading level0 row1\" >80000-99999</th>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row1_col0\" class=\"data row1 col0\" >46.09%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row1_col1\" class=\"data row1 col1\" >73.60%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row1_col2\" class=\"data row1 col2\" >22.48%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row1_col3\" class=\"data row1 col3\" >34.79%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row1_col4\" class=\"data row1 col4\" >10.85%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row1_col5\" class=\"data row1 col5\" >31.66%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row1_col6\" class=\"data row1 col6\" >17.45%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row1_col7\" class=\"data row1 col7\" >7.94%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row1_col8\" class=\"data row1 col8\" >15.32%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row1_col9\" class=\"data row1 col9\" >93.51%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0level0_row2\" class=\"row_heading level0 row2\" >100000-119999</th>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row2_col0\" class=\"data row2 col0\" >63.31%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row2_col1\" class=\"data row2 col1\" >67.43%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row2_col2\" class=\"data row2 col2\" >42.57%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row2_col3\" class=\"data row2 col3\" >47.65%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row2_col4\" class=\"data row2 col4\" >30.15%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row2_col5\" class=\"data row2 col5\" >26.25%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row2_col6\" class=\"data row2 col6\" >21.18%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row2_col7\" class=\"data row2 col7\" >25.51%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row2_col8\" class=\"data row2 col8\" >30.66%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row2_col9\" class=\"data row2 col9\" >95.07%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0level0_row3\" class=\"row_heading level0 row3\" >120000-139999</th>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row3_col0\" class=\"data row3 col0\" >75.24%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row3_col1\" class=\"data row3 col1\" >65.72%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row3_col2\" class=\"data row3 col2\" >54.01%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row3_col3\" class=\"data row3 col3\" >47.25%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row3_col4\" class=\"data row3 col4\" >46.62%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row3_col5\" class=\"data row3 col5\" >19.89%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row3_col6\" class=\"data row3 col6\" >14.86%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row3_col7\" class=\"data row3 col7\" >42.14%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row3_col8\" class=\"data row3 col8\" >39.94%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row3_col9\" class=\"data row3 col9\" >96.70%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0level0_row4\" class=\"row_heading level0 row4\" >140000-159999</th>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row4_col0\" class=\"data row4 col0\" >78.19%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row4_col1\" class=\"data row4 col1\" >54.76%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row4_col2\" class=\"data row4 col2\" >61.83%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row4_col3\" class=\"data row4 col3\" >43.62%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row4_col4\" class=\"data row4 col4\" >49.19%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row4_col5\" class=\"data row4 col5\" >16.01%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row4_col6\" class=\"data row4 col6\" >14.39%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row4_col7\" class=\"data row4 col7\" >46.06%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row4_col8\" class=\"data row4 col8\" >43.62%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row4_col9\" class=\"data row4 col9\" >94.55%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0level0_row5\" class=\"row_heading level0 row5\" >>160000</th>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row5_col0\" class=\"data row5 col0\" >67.89%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row5_col1\" class=\"data row5 col1\" >51.23%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row5_col2\" class=\"data row5 col2\" >56.37%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row5_col3\" class=\"data row5 col3\" >36.76%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row5_col4\" class=\"data row5 col4\" >43.63%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row5_col5\" class=\"data row5 col5\" >10.54%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row5_col6\" class=\"data row5 col6\" >12.99%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row5_col7\" class=\"data row5 col7\" >41.91%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row5_col8\" class=\"data row5 col8\" >35.29%</td>\n",
       "                        <td id=\"T_8c51ff2e_df1e_11ea_b785_c85b7661d6a0row5_col9\" class=\"data row5 col9\" >88.97%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2943edf0708>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Select Columns to keep in df copy\n",
    "df_cleaned.dtypes\n",
    "df1 = df_cleaned.drop(columns=\"Link\")\n",
    "# df1 = df1.drop(columns=\"Description\")\n",
    "df1 = df1.drop(columns=\"Index_No\")\n",
    "# df1\n",
    "\n",
    "df_sal = df1.groupby('Salary_Index')['python', 'sql','machine learning', 'r', 'hadoop', 'tableau', 'sas', 'spark', 'java', 'Others'].mean().reset_index()\n",
    "\n",
    "\n",
    "df_sal = pd.DataFrame(df_sal)\n",
    "df_sal\n",
    "\n",
    "# df_sal = df_sal.rename(columns={'python mean': 'a'})\n",
    "# df_sal\n",
    "df_sal= df_sal.set_index(['Salary_Index'])\n",
    "df_sal\n",
    "\n",
    "Salary_List = ['<80000', '80000-99999', '100000-119999', '120000-139999', '140000-159999', '>160000']\n",
    "df_sal['Salary_List'] = Salary_List\n",
    "df_sal\n",
    "df_sal = df_sal.set_index(['Salary_List'])\n",
    "df_sal \n",
    "\n",
    "df_sal = df_sal.rename(columns = {'python':'Python', 'sql':'SQL','machine learning': 'Machine Learning', \\\n",
    "                                  'r': 'R', 'hadoop': 'Hadoop', 'tableau': 'Tableau', \\\n",
    "                                  'sas':'SAS', 'spark':'Spark', 'java':'Java'})\n",
    "\n",
    "\n",
    "df_sal=df_sal.style.format(\"{:.2%}\")\n",
    "df_sal\n",
    "\n",
    "# df_sal.columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make DataFrame with just Salary_Index of 6, top income bracket\n",
    "df1_6 = df1[df1['Salary_Index']==6]\n",
    "len(df1_6['Salary_Index'])\n",
    "# df1_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind = df1_6.loc[:,['Queried_Salary', 'Company_Industry']]\n",
    "df_ind \n",
    "\n",
    "df_ind = df_ind.replace('', np.NaN)\n",
    "df_ind\n",
    "\n",
    "df_ind=df_ind.replace({'Insurance' : 'Other'})\n",
    "df_ind=df_ind.replace({'Health Care' : 'Other'})\n",
    "df_ind=df_ind.replace({'Media, News and Publishing' : 'Other'})\n",
    "df_ind=df_ind.replace({'Telecommunications' : 'Other'})\n",
    "df_ind=df_ind.replace({'Industrial Manufacturing' : 'Other'})\n",
    "df_ind=df_ind.replace({'Pharmaceuticals' : 'Other'})\n",
    "df_ind=df_ind.replace({'Retail' : 'Other'})\n",
    "df_ind=df_ind.replace({'Aerospace and Defense' : 'Other'})\n",
    "df_ind=df_ind.replace({'Auto' : 'Other'})\n",
    "df_ind=df_ind.replace({'Consumer Goods and Services' : 'Other'})\n",
    "df_ind=df_ind.replace({'Real Estate' : 'Other'})\n",
    "df_ind=df_ind.replace({'Construction' : 'Other'})\n",
    "df_ind=df_ind.replace({'Energy and Utilities' : 'Other'})\n",
    "df_ind=df_ind.replace({'Restaurants, Travel and LeisureConsulting and Business Services' : 'Other'})\n",
    "df_ind=df_ind.replace({'Transport and Freight' : 'Other'})\n",
    "# df_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Consulting and Business Services</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Internet and Software</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Banks and Financial Services</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Human Resources and Staffing</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computers and Electronics</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Industry\n",
       "Consulting and Business Services        80\n",
       "Internet and Software                   50\n",
       "Other                                   43\n",
       "Banks and Financial Services            41\n",
       "Human Resources and Staffing            30\n",
       "Computers and Electronics               10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind = df_ind['Company_Industry'].value_counts()\n",
    "df_ind\n",
    "df_ind_sum = pd.DataFrame ({\"Industry\": df_ind})\n",
    "df_ind_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ind.plot(kind = 'pie', autopct = '%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top skills by industry\n",
    "df1['Company_Industry'].value_counts()\n",
    "# Top five industries are: \n",
    "# Consulting and Business Services                                   712\n",
    "# Internet and Software                                              620\n",
    "# Banks and Financial Services                                       455\n",
    "# Health Care                                                        306\n",
    "# Insurance                                                          214\n",
    "\n",
    "df_ind2 = df1.loc[:,['Queried_Salary', 'Company_Industry']]\n",
    "len(df_ind2 )\n",
    "\n",
    "df_ind2 = df_ind2.replace('', np.NaN)\n",
    "len(df_ind2)\n",
    "sum(df_ind2['Company_Industry'].value_counts())\n",
    "# 3,675 + 1,809 blanks = 5,484 total\n",
    "\n",
    "# # df_ind2=df_ind2.replace({'Health Care' : 'Other'})\n",
    "# # df_ind2=df_ind2.replace({'Insurance' : 'Other'})\n",
    "\n",
    "df_ind2=df_ind2.replace({'Industrial Manufacturing' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Aerospace and Defense' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Retail' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Education and Schools' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Computers and Electronics' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Consumer Goods and Services' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Media, News and Publishing' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Human Resources and Staffing' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Telecommunications' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Government' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Pharmaceuticals' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Energy and Utilities' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Restaurants, Travel and Leisure' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Restaurants, Travel and LeisureConsulting and Business Services' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Auto' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Transport and Freight' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'InsuranceHealth Care' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Real Estate' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Organization' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Agriculture and Extraction' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Food and Beverages' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Construction' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'RetailConsumer Goods and Services' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Real EstateReal Estate' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Industrial ManufacturingConsumer Goods and Services' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Industrial ManufacturingConstruction' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Food and BeveragesConsulting and Business Services' : 'Other'})\n",
    "df_ind2=df_ind2.replace({'Industrial ManufacturingAgriculture and Extraction' : 'Other'})\n",
    "# sum(df_ind2['Company_Industry'].value_counts())\n",
    "# 3,675 is count, none lost in process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consulting and Business Services</th>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Internet and Software</th>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Banks and Financial Services</th>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health Care</th>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insurance</th>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Industry\n",
       "Other                                 1368\n",
       "Consulting and Business Services       712\n",
       "Internet and Software                  620\n",
       "Banks and Financial Services           455\n",
       "Health Care                            306\n",
       "Insurance                              214"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind2 = df_ind2['Company_Industry'].value_counts()\n",
    "df_ind2\n",
    "df_ind2_sum = pd.DataFrame ({\"Industry\": df_ind2})\n",
    "df_ind2_sum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ind2.plot(kind = 'pie', autopct = '%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Dataset for just Industry = Consulting and Business Services\n",
    "df1_CBS = df1[df1['Company_Industry']=='Consulting and Business Services']\n",
    "df1_CBS\n",
    "\n",
    "CBS_sum_Py = sum(df1_CBS['python'])\n",
    "CBS_sum_Py\n",
    "CBS_sum_SQL = sum(df1_CBS['sql'])\n",
    "CBS_sum_ML = sum(df1_CBS['machine learning'])\n",
    "CBS_sum_R = sum(df1_CBS['r'])\n",
    "CBS_sum_Had = sum(df1_CBS['hadoop'])\n",
    "CBS_sum_Tab = sum(df1_CBS['tableau'])\n",
    "CBS_sum_SAS = sum(df1_CBS['sas'])\n",
    "CBS_sum_Spark = sum(df1_CBS['spark'])\n",
    "CBS_sum_Java = sum(df1_CBS['java'])\n",
    "CBS_sum_Others = sum(df1_CBS['Others'])\n",
    "\n",
    "# Make Dataset for just Industry = Consulting and Business Services\n",
    "df1_CBS = df1[df1['Company_Industry']=='Consulting and Business Services']\n",
    "df1_CBS\n",
    "CBS_sum_Total = len(df1_CBS)\n",
    "\n",
    "CBS_sum_Py = sum(df1_CBS['python'])\n",
    "CBS_sum_Py\n",
    "CBS_sum_SQL = sum(df1_CBS['sql'])\n",
    "CBS_sum_ML = sum(df1_CBS['machine learning'])\n",
    "CBS_sum_R = sum(df1_CBS['r'])\n",
    "CBS_sum_Had = sum(df1_CBS['hadoop'])\n",
    "CBS_sum_Tab = sum(df1_CBS['tableau'])\n",
    "CBS_sum_SAS = sum(df1_CBS['sas'])\n",
    "CBS_sum_Spark = sum(df1_CBS['spark'])\n",
    "CBS_sum_Java = sum(df1_CBS['java'])\n",
    "CBS_sum_Others = sum(df1_CBS['Others'])\n",
    "\n",
    "# Make Dataset for just Industry = Internet and Software\n",
    "df1_IS = df1[df1['Company_Industry']=='Internet and Software']\n",
    "df1_IS\n",
    "IS_sum_Total = len(df1_IS)\n",
    "\n",
    "IS_sum_Py = sum(df1_IS['python'])\n",
    "IS_sum_Py\n",
    "IS_sum_SQL = sum(df1_IS['sql'])\n",
    "IS_sum_ML = sum(df1_IS['machine learning'])\n",
    "IS_sum_R = sum(df1_IS['r'])\n",
    "IS_sum_Had = sum(df1_IS['hadoop'])\n",
    "IS_sum_Tab = sum(df1_IS['tableau'])\n",
    "IS_sum_SAS = sum(df1_IS['sas'])\n",
    "IS_sum_Spark = sum(df1_IS['spark'])\n",
    "IS_sum_Java = sum(df1_IS['java'])\n",
    "IS_sum_Others = sum(df1_IS['Others'])\n",
    "\n",
    "# Make Dataset for just Industry = Banks and Financial Services\n",
    "df1_BFS = df1[df1['Company_Industry']=='Banks and Financial Services']\n",
    "df1_BFS\n",
    "BFS_sum_Total = len(df1_BFS)\n",
    "\n",
    "BFS_sum_Py = sum(df1_BFS['python'])\n",
    "BFS_sum_Py\n",
    "BFS_sum_SQL = sum(df1_BFS['sql'])\n",
    "BFS_sum_ML = sum(df1_BFS['machine learning'])\n",
    "BFS_sum_R = sum(df1_BFS['r'])\n",
    "BFS_sum_Had = sum(df1_BFS['hadoop'])\n",
    "BFS_sum_Tab = sum(df1_BFS['tableau'])\n",
    "BFS_sum_SAS = sum(df1_BFS['sas'])\n",
    "BFS_sum_Spark = sum(df1_BFS['spark'])\n",
    "BFS_sum_Java = sum(df1_BFS['java'])\n",
    "BFS_sum_Others = sum(df1_BFS['Others'])\n",
    "\n",
    "# Make Dataset for just Industry = Health Care\n",
    "df1_HC = df1[df1['Company_Industry']== 'Health Care']\n",
    "df1_HC\n",
    "HC_sum_Total = len(df1_HC)\n",
    "\n",
    "HC_sum_Py = sum(df1_HC['python'])\n",
    "HC_sum_Py\n",
    "HC_sum_SQL = sum(df1_HC['sql'])\n",
    "HC_sum_ML = sum(df1_HC['machine learning'])\n",
    "HC_sum_R = sum(df1_HC['r'])\n",
    "HC_sum_Had = sum(df1_HC['hadoop'])\n",
    "HC_sum_Tab = sum(df1_HC['tableau'])\n",
    "HC_sum_SAS = sum(df1_HC['sas'])\n",
    "HC_sum_Spark = sum(df1_HC['spark'])\n",
    "HC_sum_Java = sum(df1_HC['java'])\n",
    "HC_sum_Others = sum(df1_HC['Others'])\n",
    "\n",
    "# Make Dataset for just Industry = Insurance\n",
    "df1_I = df1[df1['Company_Industry']== 'Insurance']\n",
    "df1_I\n",
    "I_sum_Total = len(df1_I)\n",
    "\n",
    "I_sum_Py = sum(df1_I['python'])\n",
    "I_sum_Py\n",
    "I_sum_SQL = sum(df1_I['sql'])\n",
    "I_sum_ML = sum(df1_I['machine learning'])\n",
    "I_sum_R = sum(df1_I['r'])\n",
    "I_sum_Had = sum(df1_I['hadoop'])\n",
    "I_sum_Tab = sum(df1_I['tableau'])\n",
    "I_sum_SAS = sum(df1_I['sas'])\n",
    "I_sum_Spark = sum(df1_I['spark'])\n",
    "I_sum_Java = sum(df1_I['java'])\n",
    "I_sum_Others = sum(df1_I['Others'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill</th>\n",
       "      <th>Consulting and Business Services</th>\n",
       "      <th>Internet and Software</th>\n",
       "      <th>Banks and Financial Services</th>\n",
       "      <th>Health Care</th>\n",
       "      <th>Insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>426.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "      <td>377.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>340.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r</td>\n",
       "      <td>275.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hadoop</td>\n",
       "      <td>270.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tableau</td>\n",
       "      <td>200.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sas</td>\n",
       "      <td>121.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spark</td>\n",
       "      <td>235.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>java</td>\n",
       "      <td>182.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Others</td>\n",
       "      <td>658.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Total</td>\n",
       "      <td>712.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Skill  Consulting and Business Services  Internet and Software  \\\n",
       "0             python                             426.0                  432.0   \n",
       "1                sql                             377.0                  411.0   \n",
       "2   machine learning                             340.0                  291.0   \n",
       "3                  r                             275.0                  266.0   \n",
       "4             hadoop                             270.0                  242.0   \n",
       "5            tableau                             200.0                  105.0   \n",
       "6                sas                             121.0                   82.0   \n",
       "7              spark                             235.0                  212.0   \n",
       "8               java                             182.0                  215.0   \n",
       "9             Others                             658.0                  583.0   \n",
       "10             Total                             712.0                  620.0   \n",
       "\n",
       "    Banks and Financial Services  Health Care  Insurance  \n",
       "0                          264.0        126.0      124.0  \n",
       "1                          310.0        204.0      143.0  \n",
       "2                          187.0         86.0       85.0  \n",
       "3                          171.0        112.0      103.0  \n",
       "4                          165.0         56.0       93.0  \n",
       "5                          105.0         82.0       49.0  \n",
       "6                           96.0         92.0       59.0  \n",
       "7                          160.0         51.0       35.0  \n",
       "8                          163.0         63.0       71.0  \n",
       "9                          436.0        290.0      194.0  \n",
       "10                         455.0        306.0      214.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Skill= ['python', 'sql','machine learning', 'r', 'hadoop', 'tableau', 'sas', 'spark', 'java', 'Others', 'Total']\n",
    "CBS = [CBS_sum_Py, CBS_sum_SQL, CBS_sum_ML, CBS_sum_R, CBS_sum_Had, CBS_sum_Tab, CBS_sum_SAS, CBS_sum_Spark, CBS_sum_Java, CBS_sum_Others, CBS_sum_Total]\n",
    "IS = [IS_sum_Py, IS_sum_SQL, IS_sum_ML, IS_sum_R, IS_sum_Had, IS_sum_Tab, IS_sum_SAS, IS_sum_Spark, IS_sum_Java, IS_sum_Others, IS_sum_Total]\n",
    "BFS = [BFS_sum_Py, BFS_sum_SQL, BFS_sum_ML, BFS_sum_R, BFS_sum_Had, BFS_sum_Tab, BFS_sum_SAS, BFS_sum_Spark, BFS_sum_Java, BFS_sum_Others, BFS_sum_Total]\n",
    "HC = [HC_sum_Py, HC_sum_SQL, HC_sum_ML, HC_sum_R, HC_sum_Had, HC_sum_Tab, HC_sum_SAS, HC_sum_Spark, HC_sum_Java, HC_sum_Others, HC_sum_Total]\n",
    "I = [I_sum_Py, I_sum_SQL, I_sum_ML, I_sum_R, I_sum_Had, I_sum_Tab, I_sum_SAS, I_sum_Spark, I_sum_Java, I_sum_Others, I_sum_Total]\n",
    "\n",
    "industry_sum = pd.DataFrame({\n",
    "    'Skill':Skill,\n",
    "    'Consulting and Business Services': CBS,\n",
    "    'Internet and Software': IS,\n",
    "    'Banks and Financial Services': BFS,\n",
    "    'Health Care': HC,\n",
    "    'Insurance': I\n",
    "})\n",
    "industry_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Dataset for just Industry = Consulting and Business Services\n",
    "df1_CBS = df1[df1['Company_Industry']=='Consulting and Business Services']\n",
    "df1_CBS\n",
    "CBS_sum_Total = len(df1_CBS)\n",
    "\n",
    "CBS_sum_Py_p = sum(df1_CBS['python'])/CBS_sum_Total\n",
    "CBS_sum_Py_p\n",
    "CBS_sum_SQL_p = sum(df1_CBS['sql'])/CBS_sum_Total\n",
    "CBS_sum_ML_p = sum(df1_CBS['machine learning'])/CBS_sum_Total\n",
    "CBS_sum_R_p = sum(df1_CBS['r'])/CBS_sum_Total\n",
    "CBS_sum_Had_p = sum(df1_CBS['hadoop'])/CBS_sum_Total\n",
    "CBS_sum_Tab_p = sum(df1_CBS['tableau'])/CBS_sum_Total\n",
    "CBS_sum_SAS_p = sum(df1_CBS['sas'])/CBS_sum_Total\n",
    "CBS_sum_Spark_p = sum(df1_CBS['spark'])/CBS_sum_Total\n",
    "CBS_sum_Java_p = sum(df1_CBS['java'])/CBS_sum_Total\n",
    "CBS_sum_Others_p = sum(df1_CBS['Others'])/CBS_sum_Total\n",
    "\n",
    "# Make Dataset for just Industry = Internet and Software\n",
    "df1_IS = df1[df1['Company_Industry']=='Internet and Software']\n",
    "df1_IS\n",
    "IS_sum_Total = len(df1_IS)\n",
    "\n",
    "IS_sum_Py_p = sum(df1_IS['python'])/IS_sum_Total\n",
    "IS_sum_Py_p\n",
    "IS_sum_SQL_p = sum(df1_IS['sql'])/IS_sum_Total\n",
    "IS_sum_ML_p = sum(df1_IS['machine learning'])/IS_sum_Total\n",
    "IS_sum_R_p = sum(df1_IS['r'])/IS_sum_Total\n",
    "IS_sum_Had_p = sum(df1_IS['hadoop'])/IS_sum_Total\n",
    "IS_sum_Tab_p = sum(df1_IS['tableau'])/IS_sum_Total\n",
    "IS_sum_SAS_p = sum(df1_IS['sas'])/IS_sum_Total\n",
    "IS_sum_Spark_p = sum(df1_IS['spark'])/IS_sum_Total\n",
    "IS_sum_Java_p = sum(df1_IS['java'])/IS_sum_Total\n",
    "IS_sum_Others_p = sum(df1_IS['Others'])/IS_sum_Total\n",
    "\n",
    "# Make Dataset for just Industry = Banks and Financial Services\n",
    "df1_BFS = df1[df1['Company_Industry']=='Banks and Financial Services']\n",
    "df1_BFS\n",
    "BFS_sum_Total = len(df1_BFS)\n",
    "\n",
    "BFS_sum_Py_p = sum(df1_BFS['python'])/BFS_sum_Total\n",
    "BFS_sum_Py_p\n",
    "BFS_sum_SQL_p = sum(df1_BFS['sql'])/BFS_sum_Total\n",
    "BFS_sum_ML_p = sum(df1_BFS['machine learning'])/BFS_sum_Total\n",
    "BFS_sum_R_p = sum(df1_BFS['r'])/BFS_sum_Total\n",
    "BFS_sum_Had_p = sum(df1_BFS['hadoop'])/BFS_sum_Total\n",
    "BFS_sum_Tab_p = sum(df1_BFS['tableau'])/BFS_sum_Total\n",
    "BFS_sum_SAS_p = sum(df1_BFS['sas'])/BFS_sum_Total\n",
    "BFS_sum_Spark_p = sum(df1_BFS['spark'])/BFS_sum_Total\n",
    "BFS_sum_Java_p = sum(df1_BFS['java'])/BFS_sum_Total\n",
    "BFS_sum_Others_p = sum(df1_BFS['Others'])/BFS_sum_Total\n",
    "\n",
    "# Make Dataset for just Industry = Health Care\n",
    "df1_HC = df1[df1['Company_Industry']== 'Health Care']\n",
    "df1_HC\n",
    "HC_sum_Total = len(df1_HC)\n",
    "\n",
    "HC_sum_Py_p = sum(df1_HC['python'])/HC_sum_Total\n",
    "HC_sum_Py_p\n",
    "HC_sum_SQL_p = sum(df1_HC['sql'])/HC_sum_Total\n",
    "HC_sum_ML_p = sum(df1_HC['machine learning'])/HC_sum_Total\n",
    "HC_sum_R_p = sum(df1_HC['r'])/HC_sum_Total\n",
    "HC_sum_Had_p = sum(df1_HC['hadoop'])/HC_sum_Total\n",
    "HC_sum_Tab_p = sum(df1_HC['tableau'])/HC_sum_Total\n",
    "HC_sum_SAS_p = sum(df1_HC['sas'])/HC_sum_Total\n",
    "HC_sum_Spark_p = sum(df1_HC['spark'])/HC_sum_Total\n",
    "HC_sum_Java_p = sum(df1_HC['java'])/HC_sum_Total\n",
    "HC_sum_Others_p = sum(df1_HC['Others'])/HC_sum_Total\n",
    "\n",
    "# Make Dataset for just Industry = Insurance\n",
    "df1_I = df1[df1['Company_Industry']== 'Insurance']\n",
    "df1_I\n",
    "I_sum_Total = len(df1_I)\n",
    "\n",
    "I_sum_Py_p = sum(df1_I['python'])/I_sum_Total\n",
    "I_sum_Py_p\n",
    "I_sum_SQL_p = sum(df1_I['sql'])/I_sum_Total\n",
    "I_sum_ML_p = sum(df1_I['machine learning'])/I_sum_Total\n",
    "I_sum_R_p = sum(df1_I['r'])/I_sum_Total\n",
    "I_sum_Had_p = sum(df1_I['hadoop'])/I_sum_Total\n",
    "I_sum_Tab_p = sum(df1_I['tableau'])/I_sum_Total\n",
    "I_sum_SAS_p = sum(df1_I['sas'])/I_sum_Total\n",
    "I_sum_Spark_p = sum(df1_I['spark'])/I_sum_Total\n",
    "I_sum_Java_p = sum(df1_I['java'])/I_sum_Total\n",
    "I_sum_Others_p = sum(df1_I['Others'])/I_sum_Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill</th>\n",
       "      <th>Consulting and Business Services</th>\n",
       "      <th>Internet and Software</th>\n",
       "      <th>Banks and Financial Services</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>59.83%</td>\n",
       "      <td>69.68%</td>\n",
       "      <td>58.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "      <td>52.95%</td>\n",
       "      <td>66.29%</td>\n",
       "      <td>68.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>47.75%</td>\n",
       "      <td>46.94%</td>\n",
       "      <td>41.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r</td>\n",
       "      <td>38.62%</td>\n",
       "      <td>42.90%</td>\n",
       "      <td>37.58%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hadoop</td>\n",
       "      <td>37.92%</td>\n",
       "      <td>39.03%</td>\n",
       "      <td>36.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tableau</td>\n",
       "      <td>28.09%</td>\n",
       "      <td>16.94%</td>\n",
       "      <td>23.08%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sas</td>\n",
       "      <td>16.99%</td>\n",
       "      <td>13.23%</td>\n",
       "      <td>21.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spark</td>\n",
       "      <td>33.01%</td>\n",
       "      <td>34.19%</td>\n",
       "      <td>35.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>java</td>\n",
       "      <td>25.56%</td>\n",
       "      <td>34.68%</td>\n",
       "      <td>35.82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Others</td>\n",
       "      <td>92.42%</td>\n",
       "      <td>94.03%</td>\n",
       "      <td>95.82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Total</td>\n",
       "      <td>712</td>\n",
       "      <td>620</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Skill Consulting and Business Services Internet and Software  \\\n",
       "0             python                           59.83%                69.68%   \n",
       "1                sql                           52.95%                66.29%   \n",
       "2   machine learning                           47.75%                46.94%   \n",
       "3                  r                           38.62%                42.90%   \n",
       "4             hadoop                           37.92%                39.03%   \n",
       "5            tableau                           28.09%                16.94%   \n",
       "6                sas                           16.99%                13.23%   \n",
       "7              spark                           33.01%                34.19%   \n",
       "8               java                           25.56%                34.68%   \n",
       "9             Others                           92.42%                94.03%   \n",
       "10             Total                              712                   620   \n",
       "\n",
       "   Banks and Financial Services  \n",
       "0                        58.02%  \n",
       "1                        68.13%  \n",
       "2                        41.10%  \n",
       "3                        37.58%  \n",
       "4                        36.26%  \n",
       "5                        23.08%  \n",
       "6                        21.10%  \n",
       "7                        35.16%  \n",
       "8                        35.82%  \n",
       "9                        95.82%  \n",
       "10                          455  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### Proportions, not Percentages. With Others and Total\n",
    "\n",
    "\n",
    "Skill= ['python', 'sql','machine learning', 'r', 'hadoop', 'tableau', 'sas', 'spark', 'java', 'Others', 'Total']\n",
    "CBS = [\"{:.2%}\".format(CBS_sum_Py_p), \n",
    "       \"{:.2%}\".format(CBS_sum_SQL_p), \n",
    "       \"{:.2%}\".format(CBS_sum_ML_p), \n",
    "       \"{:.2%}\".format(CBS_sum_R_p), \n",
    "       \"{:.2%}\".format(CBS_sum_Had_p), \n",
    "       \"{:.2%}\".format(CBS_sum_Tab_p), \n",
    "       \"{:.2%}\".format(CBS_sum_SAS_p), \n",
    "       \"{:.2%}\".format(CBS_sum_Spark_p), \n",
    "       \"{:.2%}\".format(CBS_sum_Java_p), \n",
    "       \"{:.2%}\".format(CBS_sum_Others_p), \n",
    "       CBS_sum_Total]\n",
    "IS = [\"{:.2%}\".format(IS_sum_Py_p), \n",
    "      \"{:.2%}\".format(IS_sum_SQL_p), \n",
    "      \"{:.2%}\".format(IS_sum_ML_p), \n",
    "      \"{:.2%}\".format(IS_sum_R_p), \n",
    "      \"{:.2%}\".format(IS_sum_Had_p), \n",
    "      \"{:.2%}\".format(IS_sum_Tab_p), \n",
    "      \"{:.2%}\".format(IS_sum_SAS_p), \n",
    "      \"{:.2%}\".format(IS_sum_Spark_p), \n",
    "      \"{:.2%}\".format(IS_sum_Java_p), \n",
    "      \"{:.2%}\".format(IS_sum_Others_p), \n",
    "      IS_sum_Total]\n",
    "BFS = [\"{:.2%}\".format(BFS_sum_Py_p), \n",
    "       \"{:.2%}\".format(BFS_sum_SQL_p), \n",
    "       \"{:.2%}\".format(BFS_sum_ML_p), \n",
    "       \"{:.2%}\".format(BFS_sum_R_p), \n",
    "       \"{:.2%}\".format(BFS_sum_Had_p), \n",
    "       \"{:.2%}\".format(BFS_sum_Tab_p), \n",
    "       \"{:.2%}\".format(BFS_sum_SAS_p), \n",
    "       \"{:.2%}\".format(BFS_sum_Spark_p), \n",
    "       \"{:.2%}\".format(BFS_sum_Java_p), \n",
    "       \"{:.2%}\".format(BFS_sum_Others_p), \n",
    "       BFS_sum_Total]\n",
    "HC = [\"{:.2%}\".format(HC_sum_Py_p), \n",
    "      \"{:.2%}\".format(HC_sum_SQL_p), \n",
    "      \"{:.2%}\".format(HC_sum_ML_p), \n",
    "      \"{:.2%}\".format(HC_sum_R_p), \n",
    "      \"{:.2%}\".format(HC_sum_Had_p), \n",
    "      \"{:.2%}\".format(HC_sum_Tab_p), \n",
    "      \"{:.2%}\".format(HC_sum_SAS_p), \n",
    "      \"{:.2%}\".format(HC_sum_Spark_p), \n",
    "      \"{:.2%}\".format(HC_sum_Java_p), \n",
    "      \"{:.2%}\".format(HC_sum_Others_p), \n",
    "      HC_sum_Total]\n",
    "I = [\"{:.2%}\".format(I_sum_Py_p),\n",
    "     \"{:.2%}\".format(I_sum_SQL_p),\n",
    "     \"{:.2%}\".format(I_sum_ML_p),\n",
    "     \"{:.2%}\".format(I_sum_R_p),\n",
    "     \"{:.2%}\".format(I_sum_Had_p),\n",
    "     \"{:.2%}\".format(I_sum_Tab_p),\n",
    "     \"{:.2%}\".format(I_sum_SAS_p),\n",
    "     \"{:.2%}\".format(I_sum_Spark_p),\n",
    "     \"{:.2%}\".format(I_sum_Java_p),\n",
    "     \"{:.2%}\".format(I_sum_Others_p),\n",
    "     I_sum_Total]\n",
    "\n",
    "industry_sum_p = pd.DataFrame({\n",
    "    'Skill':Skill,\n",
    "    'Consulting and Business Services': CBS,\n",
    "    'Internet and Software': IS,\n",
    "    'Banks and Financial Services': BFS,\n",
    "})\n",
    "industry_sum_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill</th>\n",
       "      <th>Consulting and Business Services</th>\n",
       "      <th>Internet and Software</th>\n",
       "      <th>Banks and Financial Services</th>\n",
       "      <th>Health Care</th>\n",
       "      <th>Insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>0.598315</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.580220</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.579439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "      <td>0.529494</td>\n",
       "      <td>0.662903</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.668224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>0.477528</td>\n",
       "      <td>0.469355</td>\n",
       "      <td>0.410989</td>\n",
       "      <td>0.281046</td>\n",
       "      <td>0.397196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r</td>\n",
       "      <td>0.386236</td>\n",
       "      <td>0.429032</td>\n",
       "      <td>0.375824</td>\n",
       "      <td>0.366013</td>\n",
       "      <td>0.481308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hadoop</td>\n",
       "      <td>0.379213</td>\n",
       "      <td>0.390323</td>\n",
       "      <td>0.362637</td>\n",
       "      <td>0.183007</td>\n",
       "      <td>0.434579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tableau</td>\n",
       "      <td>0.280899</td>\n",
       "      <td>0.169355</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.267974</td>\n",
       "      <td>0.228972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sas</td>\n",
       "      <td>0.169944</td>\n",
       "      <td>0.132258</td>\n",
       "      <td>0.210989</td>\n",
       "      <td>0.300654</td>\n",
       "      <td>0.275701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spark</td>\n",
       "      <td>0.330056</td>\n",
       "      <td>0.341935</td>\n",
       "      <td>0.351648</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.163551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>java</td>\n",
       "      <td>0.255618</td>\n",
       "      <td>0.346774</td>\n",
       "      <td>0.358242</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.331776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Others</td>\n",
       "      <td>0.924157</td>\n",
       "      <td>0.940323</td>\n",
       "      <td>0.958242</td>\n",
       "      <td>0.947712</td>\n",
       "      <td>0.906542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Skill  Consulting and Business Services  Internet and Software  \\\n",
       "0            python                          0.598315               0.696774   \n",
       "1               sql                          0.529494               0.662903   \n",
       "2  machine learning                          0.477528               0.469355   \n",
       "3                 r                          0.386236               0.429032   \n",
       "4            hadoop                          0.379213               0.390323   \n",
       "5           tableau                          0.280899               0.169355   \n",
       "6               sas                          0.169944               0.132258   \n",
       "7             spark                          0.330056               0.341935   \n",
       "8              java                          0.255618               0.346774   \n",
       "9            Others                          0.924157               0.940323   \n",
       "\n",
       "   Banks and Financial Services  Health Care  Insurance  \n",
       "0                      0.580220     0.411765   0.579439  \n",
       "1                      0.681319     0.666667   0.668224  \n",
       "2                      0.410989     0.281046   0.397196  \n",
       "3                      0.375824     0.366013   0.481308  \n",
       "4                      0.362637     0.183007   0.434579  \n",
       "5                      0.230769     0.267974   0.228972  \n",
       "6                      0.210989     0.300654   0.275701  \n",
       "7                      0.351648     0.166667   0.163551  \n",
       "8                      0.358242     0.205882   0.331776  \n",
       "9                      0.958242     0.947712   0.906542  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### Proportions, not Percentages. With Others\n",
    "\n",
    "Skill= ['python', 'sql','machine learning', 'r', 'hadoop', 'tableau', 'sas', 'spark', 'java', 'Others']\n",
    "CBS = [CBS_sum_Py_p, \n",
    "       CBS_sum_SQL_p, \n",
    "       CBS_sum_ML_p, \n",
    "       CBS_sum_R_p, \n",
    "       CBS_sum_Had_p, \n",
    "       CBS_sum_Tab_p, \n",
    "       CBS_sum_SAS_p, \n",
    "       CBS_sum_Spark_p, \n",
    "       CBS_sum_Java_p, \n",
    "       CBS_sum_Others_p]\n",
    "IS = [IS_sum_Py_p, \n",
    "      IS_sum_SQL_p, \n",
    "      IS_sum_ML_p, \n",
    "      IS_sum_R_p, \n",
    "      IS_sum_Had_p, \n",
    "      IS_sum_Tab_p, \n",
    "      IS_sum_SAS_p, \n",
    "      IS_sum_Spark_p, \n",
    "      IS_sum_Java_p, \n",
    "      IS_sum_Others_p]\n",
    "BFS = [BFS_sum_Py_p, \n",
    "       BFS_sum_SQL_p, \n",
    "       BFS_sum_ML_p, \n",
    "       BFS_sum_R_p, \n",
    "       BFS_sum_Had_p, \n",
    "       BFS_sum_Tab_p, \n",
    "       BFS_sum_SAS_p, \n",
    "       BFS_sum_Spark_p, \n",
    "       BFS_sum_Java_p, \n",
    "       BFS_sum_Others_p]\n",
    "HC = [HC_sum_Py_p, \n",
    "      HC_sum_SQL_p, \n",
    "      HC_sum_ML_p, \n",
    "      HC_sum_R_p, \n",
    "      HC_sum_Had_p, \n",
    "      HC_sum_Tab_p, \n",
    "      HC_sum_SAS_p, \n",
    "      HC_sum_Spark_p, \n",
    "      HC_sum_Java_p, \n",
    "      HC_sum_Others_p]\n",
    "I = [I_sum_Py_p,\n",
    "     I_sum_SQL_p,\n",
    "     I_sum_ML_p,\n",
    "     I_sum_R_p,\n",
    "     I_sum_Had_p,\n",
    "     I_sum_Tab_p,\n",
    "     I_sum_SAS_p,\n",
    "     I_sum_Spark_p,\n",
    "     I_sum_Java_p,\n",
    "     I_sum_Others_p]\n",
    "\n",
    "industry_sum_no_p = pd.DataFrame({\n",
    "    'Skill':Skill,\n",
    "    'Consulting and Business Services': CBS,\n",
    "    'Internet and Software': IS,\n",
    "    'Banks and Financial Services': BFS,\n",
    "    'Health Care': HC,\n",
    "    'Insurance': I\n",
    "})\n",
    "industry_sum_no_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.clf()\n",
    "CBSbar = industry_sum_no_p.loc[:, ['Skill', 'Consulting and Business Services']]\n",
    "CBSbar = CBSbar.set_index(['Skill'])\n",
    "CBSbar \n",
    "\n",
    "x_axis = CBSbar['Consulting and Business Services']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Consulting and Business Services\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "ISbar = industry_sum_no_p.loc[:, ['Skill', 'Internet and Software']]\n",
    "ISbar = ISbar.set_index(['Skill'])\n",
    "ISbar \n",
    "\n",
    "x_axis = ISbar['Internet and Software']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Internet and Software\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "BFSbar = industry_sum_no_p.loc[:, ['Skill', 'Banks and Financial Services']]\n",
    "BFSbar = BFSbar.set_index(['Skill'])\n",
    "BFSbar \n",
    "\n",
    "x_axis = BFSbar['Banks and Financial Services']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Banks and Financial Services\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCbar = industry_sum_no_p.loc[:, ['Skill', 'Health Care']]\n",
    "HCbar = HCbar.set_index(['Skill'])\n",
    "HCbar \n",
    "\n",
    "x_axis = HCbar['Health Care']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Health Care\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ibar = industry_sum_no_p.loc[:, ['Skill', 'Insurance']]\n",
    "Ibar = Ibar.set_index(['Skill'])\n",
    "Ibar \n",
    "\n",
    "x_axis = Ibar['Insurance']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Insurance\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### No Others\n",
    "Skill= ['python', 'sql','machine learning', 'r', 'hadoop', 'tableau', 'sas', 'spark', 'java']\n",
    "CBS = [CBS_sum_Py_p, \n",
    "       CBS_sum_SQL_p, \n",
    "       CBS_sum_ML_p, \n",
    "       CBS_sum_R_p, \n",
    "       CBS_sum_Had_p, \n",
    "       CBS_sum_Tab_p, \n",
    "       CBS_sum_SAS_p, \n",
    "       CBS_sum_Spark_p, \n",
    "       CBS_sum_Java_p]\n",
    "IS = [IS_sum_Py_p, \n",
    "      IS_sum_SQL_p, \n",
    "      IS_sum_ML_p, \n",
    "      IS_sum_R_p, \n",
    "      IS_sum_Had_p, \n",
    "      IS_sum_Tab_p, \n",
    "      IS_sum_SAS_p, \n",
    "      IS_sum_Spark_p, \n",
    "      IS_sum_Java_p]\n",
    "BFS = [BFS_sum_Py_p, \n",
    "       BFS_sum_SQL_p, \n",
    "       BFS_sum_ML_p, \n",
    "       BFS_sum_R_p, \n",
    "       BFS_sum_Had_p, \n",
    "       BFS_sum_Tab_p, \n",
    "       BFS_sum_SAS_p, \n",
    "       BFS_sum_Spark_p, \n",
    "       BFS_sum_Java_p]\n",
    "HC = [HC_sum_Py_p, \n",
    "      HC_sum_SQL_p, \n",
    "      HC_sum_ML_p, \n",
    "      HC_sum_R_p, \n",
    "      HC_sum_Had_p, \n",
    "      HC_sum_Tab_p, \n",
    "      HC_sum_SAS_p, \n",
    "      HC_sum_Spark_p, \n",
    "      HC_sum_Java_p]\n",
    "I = [I_sum_Py_p,\n",
    "     I_sum_SQL_p,\n",
    "     I_sum_ML_p,\n",
    "     I_sum_R_p,\n",
    "     I_sum_Had_p,\n",
    "     I_sum_Tab_p,\n",
    "     I_sum_SAS_p,\n",
    "     I_sum_Spark_p,\n",
    "     I_sum_Java_p]\n",
    "\n",
    "industry_sum_no_p_no_o = pd.DataFrame({\n",
    "    'Skill':Skill,\n",
    "    'Consulting and Business Services': CBS,\n",
    "    'Internet and Software': IS,\n",
    "    'Banks and Financial Services': BFS,\n",
    "    'Health Care': HC,\n",
    "    'Insurance': I\n",
    "})\n",
    "industry_sum_no_p_no_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CBSbar = industry_sum_no_p_no_o.loc[:, ['Skill', 'Consulting and Business Services']]\n",
    "CBSbar = CBSbar.set_index(['Skill'])\n",
    "CBSbar \n",
    "\n",
    "x_axis = CBSbar['Consulting and Business Services']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Consulting and Business Services\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")\n",
    "\n",
    "# Save Plot\n",
    "plt.savefig('../04._Output/CBSbar_no_others.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISbar = industry_sum_no_p_no_o.loc[:, ['Skill', 'Internet and Software']]\n",
    "ISbar = ISbar.set_index(['Skill'])\n",
    "ISbar \n",
    "\n",
    "x_axis = ISbar['Internet and Software']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Internet and Software\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")\n",
    "\n",
    "# Save Plot\n",
    "plt.savefig('../04._Output/ISbar_no_others.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BFSbar = industry_sum_no_p_no_o.loc[:, ['Skill', 'Banks and Financial Services']]\n",
    "BFSbar = BFSbar.set_index(['Skill'])\n",
    "BFSbar \n",
    "\n",
    "x_axis = BFSbar['Banks and Financial Services']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Banks and Financial Services\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")\n",
    "\n",
    "\n",
    "# Save Plot\n",
    "plt.savefig('../04._Output/BFSbar_no_others.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCbar = industry_sum_no_p_no_o.loc[:, ['Skill', 'Health Care']]\n",
    "HCbar = HCbar.set_index(['Skill'])\n",
    "HCbar \n",
    "\n",
    "x_axis = HCbar['Health Care']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Health Care\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")\n",
    "\n",
    "# Save Plot\n",
    "plt.savefig('../04._Output/HCbar_no_others.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ibar = industry_sum_no_p_no_o.loc[:, ['Skill', 'Insurance']]\n",
    "Ibar = Ibar.set_index(['Skill'])\n",
    "Ibar \n",
    "\n",
    "x_axis = Ibar['Insurance']\n",
    "x_axis.plot(kind=\"bar\",  figsize=(6,3), align=\"center\", width=0.5)\n",
    "\n",
    "# Set a title and labels for the chart\n",
    "plt.title(\"Top Skills for Industry: Insurance\")\n",
    "plt.xlabel(\"Skill\")\n",
    "plt.ylabel(\"Presence of Skill in Job Description\\n (Percentage)\")\n",
    "\n",
    "# Save Plot\n",
    "plt.savefig('../04._Output/Ibar_no_others.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cram = df1.loc[:,['>160000', \\\n",
    "                     'python']]\n",
    "df_cram\n",
    "# , \n",
    "def cramers_V(var1,var2):\n",
    "  # Cross table building\n",
    "  crosstab =np.array(pd.crosstab(var1,var2, rownames=None, colnames=None)) \n",
    "  # Keeping of the test statistic of the Chi2 test\n",
    "  stat = chi2_contingency(crosstab)[0] \n",
    "  obs = np.sum(crosstab) # Number of observations\n",
    "  # Take the minimum value between the columns and the rows of the cross table\n",
    "  mini = min(crosstab.shape)-1 \n",
    "  return (stat/(obs*mini))\n",
    "\n",
    "rows= []\n",
    "\n",
    "for var1 in df_cram:\n",
    "  col = []\n",
    "  for var2 in df_cram :\n",
    "    cramers =cramers_V(df_cram[var1], df_cram[var2]) # Cramer's V test\n",
    "    col.append(round(cramers,2)) # Keeping of the rounded value of the Cramer's V  \n",
    "  rows.append(col)\n",
    "  \n",
    "# cramers_results = np.array(rows)\n",
    "# df_cram_sum = pd.DataFrame(cramers_results, columns = df_cram.columns, index =df_cram.columns)\n",
    "# df_cram_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cram_1 = df1.loc[:,['<80000', '80000-99999','100000-119999',\\\n",
    "                     '120000-139999','140000-159999','>160000', \\\n",
    "                     'python', 'sql', 'machine learning', 'r', \\\n",
    "                      'hadoop', 'spark', 'java', 'tableau', \\\n",
    "                       'datamining', 'hive', 'sas', 'bigdata',\\\n",
    "                       'aws', 'scala', 'nosql', 'c/c++'\n",
    "                      ]]\n",
    "df_cram_1\n",
    "\n",
    "def cramers_V(var1,var2):\n",
    "  # Cross table building\n",
    "  crosstab =np.array(pd.crosstab(var1,var2, rownames=None, colnames=None)) \n",
    "  # Keeping of the test statistic of the Chi2 test\n",
    "  stat = chi2_contingency(crosstab)[0] \n",
    "  obs = np.sum(crosstab) # Number of observations\n",
    "  # Take the minimum value between the columns and the rows of the cross table\n",
    "  mini = min(crosstab.shape)-1 \n",
    "  return (stat/(obs*mini))\n",
    "\n",
    "rows= []\n",
    "\n",
    "for var1 in df_cram_1:\n",
    "  col = []\n",
    "  for var2 in df_cram_1 :\n",
    "    cramers =cramers_V(df_cram_1[var1], df_cram_1[var2]) # Cramer's V test\n",
    "    col.append(round(cramers,2)) # Keeping of the rounded value of the Cramer's V  \n",
    "  rows.append(col)\n",
    "  \n",
    "cramers_results_1 = np.array(rows)\n",
    "df_cram_sum_1 = pd.DataFrame(cramers_results_1, columns = df_cram_1.columns, \\\n",
    "                           index =df_cram_1.columns)\n",
    "df_cram_sum_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(df_cram_sum_1, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "  ax = sns.heatmap(df_cram_sum_1, mask=mask,vmin=0., vmax=1, square=True)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### Regressions\n",
    "# def lin_reg_plot(x_values,y_values, text_coordinates):\n",
    "#     (slope, intercept, rvalue, pvalue, stderr) = linregress(x_values, y_values)\n",
    "#     regress_values = x_values * slope + intercept  \n",
    "#     line_eq = 'y = ' + str(round(slope,2)) + 'x + ' + str(round(intercept,2))\n",
    "\n",
    "#     # New Scatter plot with regression line\n",
    "#     plt.scatter(x_values,y_values,edgecolors='black')\n",
    "#     plt.plot(x_values,regress_values,'r-')\n",
    "#     plt.annotate(line_eq,text_coordinates,fontsize=14,color=\"red\")\n",
    "    \n",
    "#     # Add R-squared annotation\n",
    "#     print(f'The r-squared is: {rvalue}')\n",
    "#     print(line_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_values = df_cram_1['python']\n",
    "# y_values = df_cram_1['>160000']\n",
    "\n",
    "# lin_reg_plot(x_values,y_values, (.2, .2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1[[\n",
    "    'Internet and Software', \\\n",
    "    'Banks and Financial Services', \\\n",
    "    'Health Care', \\\n",
    "    'Insurance',\n",
    "    'CA', \\\n",
    "    'NY', \\\n",
    "    'MA', \\\n",
    "    'VA', \\\n",
    "    'DC', \\\n",
    "    'Consulting and Business Services', \\\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'r', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'java', \\\n",
    "    'tableau', \\\n",
    "    'datamining', \\\n",
    "    'hive', 'sas', \\\n",
    "    'bigdata',\\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'nosql',  \\\n",
    "    'c/c++',  \\\n",
    "    'naturallanguageprocessing', \\\n",
    "    'oracle', \\\n",
    "    'datawarehouse', \\\n",
    "    'linux', \\\n",
    "    'ai', \\\n",
    "    'microsoftsqlserver', \\\n",
    "    'tensorflow', \\\n",
    "    'kafka', \\\n",
    "    'dataanalysis', \\\n",
    "    'azure', \\\n",
    "    'matlab', \\\n",
    "    'microsoftoffice', \\\n",
    "    'scripting', \\\n",
    "    'pig', \\\n",
    "    'git', \\\n",
    "    'microsoftpowerpoint', \\\n",
    "    'excel', \\\n",
    "    'designexperience', \\\n",
    "    'javascript', \\\n",
    "    'hbase', \\\n",
    "    'cassandra', \\\n",
    "    'postgresql', \\\n",
    "    'mysql', \\\n",
    "    'perl', \\\n",
    "    'spss', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'shellscripting', \\\n",
    "    'datascience', \\\n",
    "    'docker', \\\n",
    "    'mongodb', \\\n",
    "    '.net', \\\n",
    "    'projectmanagement', \\\n",
    "    'businessintelligence', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['Salary_Index']\n",
    " \n",
    "# with sklearn\n",
    "# regr = linear_model.LinearRegression()\n",
    "# regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "X = sm.add_constant(X) # adding a constant\n",
    "# X = sm.has_constant(True) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '>160000', 'Consulting and Business Services' - Short\n",
    "X = df1[[\n",
    "    'Consulting and Business Services', \\\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'tableau', \\\n",
    "    'datamining', \\\n",
    "    'bigdata',\\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'c/c++',  \\\n",
    "    'linux', \\\n",
    "    'tensorflow', \\\n",
    "    'kafka', \\\n",
    "    'azure', \\\n",
    "    'pig', \\\n",
    "    'git', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'docker', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['>160000']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "# X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Sal_Ind_Cat4-5-6', 'Consulting and Business Services' - Short\n",
    "X = df1[[\n",
    "    'CA', \\\n",
    "    'NY', \\\n",
    "    'MA', \\\n",
    "    'VA', \\\n",
    "    'DC', \\\n",
    "    'Consulting and Business Services', \\\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'tableau', \\\n",
    "    'datamining', \\\n",
    "    'bigdata',\\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'c/c++',  \\\n",
    "    'linux', \\\n",
    "    'tensorflow', \\\n",
    "    'kafka', \\\n",
    "    'azure', \\\n",
    "    'pig', \\\n",
    "    'git', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'docker', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['Sal_Ind_Cat4-5-6']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Sal_Ind_Cat4-5-6', 'Consulting and Business Services' - Short\n",
    "X = df1[[\n",
    "    'python'\n",
    "       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['Salary_Index']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Sal_Ind_Cat4-5-6',     \n",
    "# 'Consulting and Business Services', \\\n",
    "# 'Internet and Software', \\\n",
    "#     'Banks and Financial Services', \\\n",
    "#     'Health Care', \\\n",
    "#     'Insurance', \n",
    "# - Short\n",
    "\n",
    "X = df1[[\n",
    "    'Consulting and Business Services', \\\n",
    "    'Internet and Software', \\\n",
    "    'Banks and Financial Services', \\\n",
    "    'Health Care', \\\n",
    "    'Insurance',\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'tableau', \\\n",
    "    'datamining', \\\n",
    "    'bigdata',\\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'c/c++',  \\\n",
    "    'linux', \\\n",
    "    'tensorflow', \\\n",
    "    'kafka', \\\n",
    "    'azure', \\\n",
    "    'pig', \\\n",
    "    'git', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'docker', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['Sal_Ind_Cat4-5-6']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 'Sal_Ind_Cat4-5-6',     \n",
    "# 'Consulting and Business Services', \\\n",
    "# 'Internet and Software', \\\n",
    "#     'Banks and Financial Services', \\\n",
    "#     'Health Care', \\\n",
    "#     'Insurance', \n",
    "# - Short\n",
    "\n",
    "X = df1[[\n",
    "    'Consulting and Business Services', \\\n",
    "    'Internet and Software', \\\n",
    "    'Banks and Financial Services', \\\n",
    "    'Insurance',\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'tableau', \\\n",
    "    'datamining', \\\n",
    "    'bigdata',\\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'c/c++',  \\\n",
    "    'linux', \\\n",
    "    'azure', \\\n",
    "    'pig', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'docker', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['Sal_Ind_Cat4-5-6']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Sal_Ind_Cat4-5-6',     \n",
    "# 'Consulting and Business Services', \\\n",
    "# 'Internet and Software', \\\n",
    "#     'Banks and Financial Services', \\\n",
    "#     'Health Care', \\\n",
    "#     'Insurance', \n",
    "# - Long\n",
    "\n",
    "X = df1[[\n",
    "    'Consulting and Business Services', \\\n",
    "    'Internet and Software', \\\n",
    "    'Banks and Financial Services', \\\n",
    "    'Health Care', \\\n",
    "    'Insurance',\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'r', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'java', \\\n",
    "    'tableau', \\\n",
    "    'datamining', \\\n",
    "    'hive', 'sas', \\\n",
    "    'bigdata',\\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'nosql',  \\\n",
    "    'c/c++',  \\\n",
    "    'naturallanguageprocessing', \\\n",
    "    'oracle', \\\n",
    "    'datawarehouse', \\\n",
    "    'linux', \\\n",
    "    'ai', \\\n",
    "    'microsoftsqlserver', \\\n",
    "    'tensorflow', \\\n",
    "    'kafka', \\\n",
    "    'dataanalysis', \\\n",
    "    'azure', \\\n",
    "    'matlab', \\\n",
    "    'microsoftoffice', \\\n",
    "    'scripting', \\\n",
    "    'pig', \\\n",
    "    'git', \\\n",
    "    'microsoftpowerpoint', \\\n",
    "    'excel', \\\n",
    "    'designexperience', \\\n",
    "    'javascript', \\\n",
    "    'hbase', \\\n",
    "    'cassandra', \\\n",
    "    'postgresql', \\\n",
    "    'mysql', \\\n",
    "    'perl', \\\n",
    "    'spss', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'shellscripting', \\\n",
    "    'datascience', \\\n",
    "    'docker', \\\n",
    "    'mongodb', \\\n",
    "    '.net', \\\n",
    "    'projectmanagement', \\\n",
    "    'businessintelligence', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['Sal_Ind_Cat4-5-6']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Sal_Ind_Cat4-5-6',     \n",
    "# 'Consulting and Business Services', \\\n",
    "# 'Internet and Software', \\\n",
    "#     'Banks and Financial Services', \\\n",
    "#     'Health Care', \\\n",
    "#     'Insurance', \n",
    "# - Long\n",
    "\n",
    "X = df1[[\n",
    "    'Consulting and Business Services', \\\n",
    "    'Internet and Software', \\\n",
    "    'Banks and Financial Services', \\\n",
    "    'Health Care', \\\n",
    "    'Insurance',\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'r', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'java', \\\n",
    "    'tableau', \\\n",
    "    'datamining', \\\n",
    "    'hive', 'sas', \\\n",
    "    'bigdata',\\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'nosql',  \\\n",
    "    'c/c++',  \\\n",
    "    'naturallanguageprocessing', \\\n",
    "    'oracle', \\\n",
    "    'datawarehouse', \\\n",
    "    'linux', \\\n",
    "    'ai', \\\n",
    "    'microsoftsqlserver', \\\n",
    "    'tensorflow', \\\n",
    "    'kafka', \\\n",
    "    'dataanalysis', \\\n",
    "    'azure', \\\n",
    "    'matlab', \\\n",
    "    'microsoftoffice', \\\n",
    "    'scripting', \\\n",
    "    'pig', \\\n",
    "    'git', \\\n",
    "    'microsoftpowerpoint', \\\n",
    "    'excel', \\\n",
    "    'designexperience', \\\n",
    "    'javascript', \\\n",
    "    'hbase', \\\n",
    "    'cassandra', \\\n",
    "    'postgresql', \\\n",
    "    'mysql', \\\n",
    "    'perl', \\\n",
    "    'spss', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'shellscripting', \\\n",
    "    'datascience', \\\n",
    "    'docker', \\\n",
    "    'mongodb', \\\n",
    "    '.net', \\\n",
    "    'projectmanagement', \\\n",
    "    'businessintelligence', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['Sal_Ind_Cat4-5-6']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Sal_Ind_Cat4-5-6',     \n",
    "# 'Consulting and Business Services', \\\n",
    "# 'Internet and Software', \\\n",
    "#     'Banks and Financial Services', \\\n",
    "#     'Health Care', \\\n",
    "#     'Insurance', \n",
    "# - Long\n",
    "\n",
    "X = df1[[\n",
    "    'Consulting and Business Services', \\\n",
    "    'Internet and Software', \\\n",
    "    'Banks and Financial Services', \\\n",
    "    'Health Care', \\\n",
    "    'Insurance',\n",
    "    'CA',\\\n",
    "    'NY', \\\n",
    "    'VA', \\\n",
    "    'MA', \\\n",
    "    'DC', \\\n",
    "    'WA', \\\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'java', \\\n",
    "    'datamining', \\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'nosql',  \\\n",
    "    'naturallanguageprocessing', \\\n",
    "    'oracle', \\\n",
    "    'datawarehouse', \\\n",
    "    'ai', \\\n",
    "    'microsoftsqlserver', \\\n",
    "    'kafka', \\\n",
    "    'dataanalysis', \\\n",
    "    'azure', \\\n",
    "    'matlab', \\\n",
    "    'microsoftoffice', \\\n",
    "    'pig', \\\n",
    "    'microsoftpowerpoint', \\\n",
    "    'designexperience', \\\n",
    "    'cassandra', \\\n",
    "    'perl', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'projectmanagement', \\\n",
    "    'businessintelligence', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "\n",
    "# here we have 2 variables for multiple regression. \n",
    "# If you just want to use one variable for simple linear regression, \n",
    "# then use X = df['Interest_Rate'] for example.Alternatively, you \n",
    "# may add additional variables within the brackets\n",
    "Y = df1['Salary_Index']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "\n",
    "# # with statsmodels\n",
    "X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print_model = model.summary()\n",
    "print(print_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1[[\n",
    "    'Consulting and Business Services', \\\n",
    "    'Internet and Software', \\\n",
    "    'Banks and Financial Services', \\\n",
    "    'Health Care', \\\n",
    "    'Insurance',\n",
    "    'python', \\\n",
    "    'sql', \\\n",
    "    'machine learning', \\\n",
    "    'hadoop', \\\n",
    "    'spark', \\\n",
    "    'java', \\\n",
    "    'datamining', \\\n",
    "    'aws',  \\\n",
    "    'scala',  \\\n",
    "    'nosql',  \\\n",
    "    'naturallanguageprocessing', \\\n",
    "    'oracle', \\\n",
    "    'datawarehouse', \\\n",
    "    'ai', \\\n",
    "    'microsoftsqlserver', \\\n",
    "    'kafka', \\\n",
    "    'dataanalysis', \\\n",
    "    'azure', \\\n",
    "    'matlab', \\\n",
    "    'microsoftoffice', \\\n",
    "    'pig', \\\n",
    "    'microsoftpowerpoint', \\\n",
    "    'designexperience', \\\n",
    "    'cassandra', \\\n",
    "    'perl', \\\n",
    "    'softwaredevelopment', \\\n",
    "    'projectmanagement', \\\n",
    "    'businessintelligence', \\\n",
    "    's3'       \n",
    "    ]] \n",
    "Y = df1['Salary_Index']\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression \n",
    "# lin = LinearRegression() \n",
    "  \n",
    "# lin.fit(X, Y) \n",
    "\n",
    "# regr = linear_model.LinearRegression()\n",
    "# regr.fit(X, Y)\n",
    "\n",
    "# return(r2)\n",
    "\n",
    "model = LinearRegression().fit(X, Y)\n",
    "\n",
    "\n",
    "r_sq = model.score(X, Y)\n",
    "print('coefficient of determination:', r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures \n",
    "  \n",
    "# poly = PolynomialFeatures(degree = 34) \n",
    "# X_poly = poly.fit_transform(X) \n",
    "  \n",
    "# poly.fit(X_poly, y) \n",
    "# lin2 = LinearRegression() \n",
    "# lin2.fit(X_poly, Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cramers_V(var1,var2):\n",
    "#   # Cross table building\n",
    "#   crosstab =np.array(pd.crosstab(var1,var2, rownames=None, colnames=None)) \n",
    "#   # Keeping of the test statistic of the Chi2 test\n",
    "#   stat = chi2_contingency(crosstab)[0] \n",
    "#   obs = np.sum(crosstab) # Number of observations\n",
    "#   # Take the minimum value between the columns and the rows of the cross table\n",
    "#   mini = min(crosstab.shape)-1 \n",
    "#   return (stat/(obs*mini))\n",
    "\n",
    "# rows= []\n",
    "\n",
    "# for var1 in data_encoded:\n",
    "#   col = []\n",
    "#   for var2 in data_encoded :\n",
    "#     cramers =cramers_V(data_encoded[var1], data_encoded[var2]) # Cramer's V test\n",
    "#     col.append(round(cramers,2)) # Keeping of the rounded value of the Cramer's V  \n",
    "#   rows.append(col)\n",
    "  \n",
    "# cramers_results = np.array(rows)\n",
    "# df = pd.DataFrame(cramers_results, columns = data_encoded.columns, index =data_encoded.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cramers_v(x, y):\n",
    "#     confusion_matrix = pd.crosstab(x,y)\n",
    "#     chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "#     n = confusion_matrix.sum().sum()\n",
    "#     phi2 = chi2/n\n",
    "#     r,k = confusion_matrix.shape\n",
    "#     phi2corr = max(0, phi2-((k-1)*(r-1))/(n-1))\n",
    "#     rcorr = r-((r-1)**2)/(n-1)\n",
    "#     kcorr = k-((k-1)**2)/(n-1)\n",
    "#     return np.sqrt(phi2corr/min((kcorr-1),(rcorr-1)))\n",
    "\n",
    "# def correlation_ratio(categories, measurements):\n",
    "#     fcat, _ = pd.factorize(categories)\n",
    "#     cat_num = np.max(fcat)+1\n",
    "#     y_avg_array = np.zeros(cat_num)\n",
    "#     n_array = np.zeros(cat_num)\n",
    "#     for i in range(0,cat_num):\n",
    "#         cat_measures = measurements[np.argwhere(fcat == i).flatten()]\n",
    "#         n_array[i] = len(cat_measures)\n",
    "#         y_avg_array[i] = np.average(cat_measures)\n",
    "#     y_total_avg = np.sum(np.multiply(y_avg_array,n_array))/np.sum(n_array)\n",
    "#     numerator = np.sum(np.multiply(n_array,np.power(np.subtract(y_avg_array,y_total_avg),2)))\n",
    "#     denominator = np.sum(np.power(np.subtract(measurements,y_total_avg),2))\n",
    "#     if numerator == 0:\n",
    "#         eta = 0.0\n",
    "#     else:\n",
    "#         eta = np.sqrt(numerator/denominator)\n",
    "#     return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock_Market = {'Year': [2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016],\n",
    "#                 'Month': [12, 11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1],\n",
    "#                 'Interest_Rate': [2.75,2.5,2.5,2.5,2.5,2.5,2.5,2.25,2.25,2.25,2,2,2,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75],\n",
    "#                 'Unemployment_Rate': [5.3,5.3,5.3,5.3,5.4,5.6,5.5,5.5,5.5,5.6,5.7,5.9,6,5.9,5.8,6.1,6.2,6.1,6.1,6.1,5.9,6.2,6.2,6.1],\n",
    "#                 'Stock_Index_Price': [1464,1394,1357,1293,1256,1254,1234,1195,1159,1167,1130,1075,1047,965,943,958,971,949,884,866,876,822,704,719]        \n",
    "#                 }\n",
    "\n",
    "# df = pd.DataFrame(Stock_Market,columns=['Year','Month','Interest_Rate','Unemployment_Rate','Stock_Index_Price'])\n",
    "\n",
    "# X = df[['Interest_Rate','Unemployment_Rate']] # here we have 2 variables for multiple regression. If you just want to use one variable for simple linear regression, then use X = df['Interest_Rate'] for example.Alternatively, you may add additional variables within the brackets\n",
    "# Y = df['Stock_Index_Price']\n",
    " \n",
    "# # with sklearn\n",
    "# regr = linear_model.LinearRegression()\n",
    "# regr.fit(X, Y)\n",
    "\n",
    "# print('Intercept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "# # prediction with sklearn\n",
    "# New_Interest_Rate = 2.75\n",
    "# New_Unemployment_Rate = 5.3\n",
    "# print ('Predicted Stock Index Price: \\n', regr.predict([[New_Interest_Rate ,New_Unemployment_Rate]]))\n",
    "\n",
    "# # with statsmodels\n",
    "# X = sm.add_constant(X) # adding a constant\n",
    " \n",
    "# model = sm.OLS(Y, X).fit()\n",
    "# predictions = model.predict(X) \n",
    " \n",
    "# print_model = model.summary()\n",
    "# print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ mcnemar test\n",
    "# dfx = pd.DataFrame(np.random.randint(2, size= (90, 2)),\n",
    "#                   columns= ['time1', 'time2'])\n",
    "\n",
    "# crosstab, res = researchpy.crosstab(dfx['time1'], dfx['time2'], test= \"mcnemar\")\n",
    "\n",
    "# crosstab\n",
    "# res\n",
    "\n",
    "#############\n",
    "# crosstab1, res1 = researchpy.crosstab(df_cram_1['python'],df_cram_1['>160000'],  test= \"mcnemar\")\n",
    "\n",
    "# crosstab1\n",
    "# res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# replacement_list = ['Insurance',\n",
    "# 'Health Care',\n",
    "# 'Media, News and Publishing',\n",
    "# 'Telecommunications',\n",
    "# 'Industrial Manufacturing',\n",
    "# 'Pharmaceuticals',\n",
    "# 'Retail',\n",
    "# 'Aerospace and Defense',\n",
    "# 'Auto',\n",
    "# 'Consumer Goods and Services',\n",
    "# 'Real Estate',\n",
    "# 'Construction',\n",
    "# 'Energy and Utilities',\n",
    "# 'Restaurants, Travel and LeisureConsulting and Business Services',\n",
    "# 'Transport and Freight']\n",
    "\n",
    "# for i in replacement_list:\n",
    "#     df_ind1=df_ind.replace({i : 'Other'})\n",
    "# df_ind1\n",
    "\n",
    "# for index, row in df_ind1.iterrows():\n",
    "#     row['1'] = \"I am working!\"\n",
    "\n",
    "\n",
    "# for i, row in df_ind.iterrows():\n",
    "#     df_ind1=df_ind.loc[i,'price_new']  = i \n",
    "\n",
    "# for i in replacement_list:\n",
    "#     df_ind1=df_ind.replace(i : 'Other')\n",
    "# df_ind1\n",
    "\n",
    "#######\n",
    "# Salary_Index = df.iloc[:,4]\n",
    "# No_of_Skills = df.iloc[:,7]\n",
    "# correlation = st.pearsonr(Salary_Index,No_of_Skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_v1 = merge_df.to_csv(r'../04._Output/output_data_v1.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
